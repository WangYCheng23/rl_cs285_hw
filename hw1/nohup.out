########################
logging outputs to  /home/WangC/rl_cs285_hw/hw1/cs285/scripts/../../data/q2_dagger_ant_Ant-v2_08-07-2022_10-27-55
########################
Using GPU id 0
Loading expert policy from... cs285/policies/experts/Ant.pkl
obs (1, 111) (1, 111)
Done restoring expert policy...


********** Iteration 0 ************

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 913.6671142578125
Eval_StdReturn : 14.336787223815918
Eval_MaxReturn : 931.099853515625
Eval_MinReturn : 893.0099487304688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 4713.6533203125
Train_StdReturn : 12.196533203125
Train_MaxReturn : 4725.849609375
Train_MinReturn : 4701.45654296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 0
TimeSinceStart : 7.65027928352356
Training Loss : 0.0015643473016098142
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.3995971679688
Eval_StdReturn : 8.722440719604492
Eval_MaxReturn : 958.9190673828125
Eval_MinReturn : 935.5365600585938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 906.5269775390625
Train_StdReturn : 0.0
Train_MaxReturn : 906.5269775390625
Train_MinReturn : 906.5269775390625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 1000
TimeSinceStart : 16.181862115859985
Training Loss : 0.000866029120516032
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 2 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.4676513671875
Eval_StdReturn : 25.7247371673584
Eval_MaxReturn : 968.74267578125
Eval_MinReturn : 909.2031860351562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 929.1317138671875
Train_StdReturn : 0.0
Train_MaxReturn : 929.1317138671875
Train_MinReturn : 929.1317138671875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 2000
TimeSinceStart : 24.245176553726196
Training Loss : 0.000552093842998147
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 3 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.5694580078125
Eval_StdReturn : 6.037341594696045
Eval_MaxReturn : 959.0236206054688
Eval_MinReturn : 940.2843017578125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.07861328125
Train_StdReturn : 0.0
Train_MaxReturn : 943.07861328125
Train_MinReturn : 943.07861328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 3000
TimeSinceStart : 32.80007266998291
Training Loss : 0.0004935483448207378
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 4 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.0224609375
Eval_StdReturn : 17.332378387451172
Eval_MaxReturn : 957.0150146484375
Eval_MinReturn : 910.2568359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.6091918945312
Train_StdReturn : 0.0
Train_MaxReturn : 946.6091918945312
Train_MinReturn : 946.6091918945312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 4000
TimeSinceStart : 41.59912610054016
Training Loss : 0.00039401958929374814
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 5 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.9241943359375
Eval_StdReturn : 7.697230339050293
Eval_MaxReturn : 964.2908325195312
Eval_MinReturn : 941.0925903320312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 922.21044921875
Train_StdReturn : 0.0
Train_MaxReturn : 922.21044921875
Train_MinReturn : 922.21044921875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 5000
TimeSinceStart : 49.83951163291931
Training Loss : 0.0004962211241945624
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 6 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.41015625
Eval_StdReturn : 8.496716499328613
Eval_MaxReturn : 964.5772705078125
Eval_MinReturn : 938.2743530273438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 966.62646484375
Train_StdReturn : 0.0
Train_MaxReturn : 966.62646484375
Train_MinReturn : 966.62646484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 6000
TimeSinceStart : 58.32870149612427
Training Loss : 0.0006357876700349152
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 7 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 957.76171875
Eval_StdReturn : 8.02420425415039
Eval_MaxReturn : 970.44189453125
Eval_MinReturn : 949.3623046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.859130859375
Train_StdReturn : 0.0
Train_MaxReturn : 941.859130859375
Train_MinReturn : 941.859130859375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 7000
TimeSinceStart : 66.57202053070068
Training Loss : 0.0006408258923329413
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 8 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.4683837890625
Eval_StdReturn : 4.497711181640625
Eval_MaxReturn : 950.12353515625
Eval_MinReturn : 937.9149169921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.8726806640625
Train_StdReturn : 0.0
Train_MaxReturn : 951.8726806640625
Train_MinReturn : 951.8726806640625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 8000
TimeSinceStart : 75.06365489959717
Training Loss : 0.0006816847599111497
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 9 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.0260620117188
Eval_StdReturn : 14.358057975769043
Eval_MaxReturn : 967.1561279296875
Eval_MinReturn : 932.302001953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 960.450927734375
Train_StdReturn : 0.0
Train_MaxReturn : 960.450927734375
Train_MinReturn : 960.450927734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 9000
TimeSinceStart : 83.31175351142883
Training Loss : 0.00043419806752353907
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 10 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.7796020507812
Eval_StdReturn : 10.467598915100098
Eval_MaxReturn : 968.1992797851562
Eval_MinReturn : 938.7100830078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.9449462890625
Train_StdReturn : 0.0
Train_MaxReturn : 948.9449462890625
Train_MinReturn : 948.9449462890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 10000
TimeSinceStart : 91.44932651519775
Training Loss : 0.0004985214327462018
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.6771240234375
Eval_StdReturn : 17.427881240844727
Eval_MaxReturn : 972.3129272460938
Eval_MinReturn : 924.8876953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.8155517578125
Train_StdReturn : 0.0
Train_MaxReturn : 952.8155517578125
Train_MinReturn : 952.8155517578125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 11000
TimeSinceStart : 99.82170343399048
Training Loss : 0.00023942939878907055
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 12 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 953.4114990234375
Eval_StdReturn : 11.996475219726562
Eval_MaxReturn : 975.2072143554688
Eval_MinReturn : 939.1220092773438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 957.2693481445312
Train_StdReturn : 0.0
Train_MaxReturn : 957.2693481445312
Train_MinReturn : 957.2693481445312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 12000
TimeSinceStart : 108.44190430641174
Training Loss : 0.0009162682108581066
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 13 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.0126953125
Eval_StdReturn : 14.71762752532959
Eval_MaxReturn : 967.9452514648438
Eval_MinReturn : 929.2024536132812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.5839233398438
Train_StdReturn : 0.0
Train_MaxReturn : 934.5839233398438
Train_MinReturn : 934.5839233398438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 13000
TimeSinceStart : 116.84240627288818
Training Loss : 0.0005260153557173908
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 14 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 953.9674072265625
Eval_StdReturn : 9.49530029296875
Eval_MaxReturn : 968.149658203125
Eval_MinReturn : 938.6097412109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.337890625
Train_StdReturn : 0.0
Train_MaxReturn : 946.337890625
Train_MinReturn : 946.337890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 14000
TimeSinceStart : 125.29578733444214
Training Loss : 0.00016172113828361034
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 15 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.5188598632812
Eval_StdReturn : 10.193721771240234
Eval_MaxReturn : 953.96533203125
Eval_MinReturn : 925.6412963867188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.2136840820312
Train_StdReturn : 0.0
Train_MaxReturn : 943.2136840820312
Train_MinReturn : 943.2136840820312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 15000
TimeSinceStart : 132.9758336544037
Training Loss : 0.0001779792655725032
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 16 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.0950317382812
Eval_StdReturn : 17.701194763183594
Eval_MaxReturn : 966.021240234375
Eval_MinReturn : 911.982666015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.8804931640625
Train_StdReturn : 0.0
Train_MaxReturn : 938.8804931640625
Train_MinReturn : 938.8804931640625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 16000
TimeSinceStart : 140.75100684165955
Training Loss : 0.00015760432870592922
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 17 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 953.20849609375
Eval_StdReturn : 6.939212799072266
Eval_MaxReturn : 962.4920654296875
Eval_MinReturn : 941.6148681640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 930.989501953125
Train_StdReturn : 0.0
Train_MaxReturn : 930.989501953125
Train_MinReturn : 930.989501953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 17000
TimeSinceStart : 148.80623078346252
Training Loss : 0.00046427143388427794
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 18 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.01904296875
Eval_StdReturn : 6.572108268737793
Eval_MaxReturn : 948.1812744140625
Eval_MinReturn : 928.3588256835938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 957.9382934570312
Train_StdReturn : 0.0
Train_MaxReturn : 957.9382934570312
Train_MinReturn : 957.9382934570312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 18000
TimeSinceStart : 157.02835297584534
Training Loss : 0.00020211489754728973
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 19 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.3109130859375
Eval_StdReturn : 12.144312858581543
Eval_MaxReturn : 954.886474609375
Eval_MinReturn : 925.1378173828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.4550170898438
Train_StdReturn : 0.0
Train_MaxReturn : 936.4550170898438
Train_MinReturn : 936.4550170898438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 19000
TimeSinceStart : 165.5088758468628
Training Loss : 0.0002547987678553909
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 20 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.7330322265625
Eval_StdReturn : 9.499154090881348
Eval_MaxReturn : 958.864013671875
Eval_MinReturn : 936.4699096679688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.8182373046875
Train_StdReturn : 0.0
Train_MaxReturn : 952.8182373046875
Train_MinReturn : 952.8182373046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 20000
TimeSinceStart : 173.83832502365112
Training Loss : 0.00029067619470879436
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 21 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.9177856445312
Eval_StdReturn : 15.965889930725098
Eval_MaxReturn : 962.728271484375
Eval_MinReturn : 926.0389404296875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.8101806640625
Train_StdReturn : 0.0
Train_MaxReturn : 954.8101806640625
Train_MinReturn : 954.8101806640625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 21000
TimeSinceStart : 182.45037651062012
Training Loss : 0.0002789397840388119
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 22 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 933.95263671875
Eval_StdReturn : 11.0128755569458
Eval_MaxReturn : 955.2847290039062
Eval_MinReturn : 923.7628173828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.639404296875
Train_StdReturn : 0.0
Train_MaxReturn : 940.639404296875
Train_MinReturn : 940.639404296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 22000
TimeSinceStart : 191.01985454559326
Training Loss : 0.0003047451318707317
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 23 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.0767822265625
Eval_StdReturn : 5.810103416442871
Eval_MaxReturn : 947.0023193359375
Eval_MinReturn : 932.1104125976562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 921.39208984375
Train_StdReturn : 0.0
Train_MaxReturn : 921.39208984375
Train_MinReturn : 921.39208984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 23000
TimeSinceStart : 199.22487449645996
Training Loss : 0.0003765893925447017
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 24 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.0755004882812
Eval_StdReturn : 13.153473854064941
Eval_MaxReturn : 968.4232177734375
Eval_MinReturn : 932.5357666015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.974365234375
Train_StdReturn : 0.0
Train_MaxReturn : 955.974365234375
Train_MinReturn : 955.974365234375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 24000
TimeSinceStart : 207.46119594573975
Training Loss : 0.0002835561172105372
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 25 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 935.0399169921875
Eval_StdReturn : 12.866851806640625
Eval_MaxReturn : 956.01904296875
Eval_MinReturn : 918.4204711914062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.809814453125
Train_StdReturn : 0.0
Train_MaxReturn : 944.809814453125
Train_MinReturn : 944.809814453125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 25000
TimeSinceStart : 215.63712811470032
Training Loss : 0.0005216528079472482
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 26 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.8658447265625
Eval_StdReturn : 9.705694198608398
Eval_MaxReturn : 961.9395751953125
Eval_MinReturn : 932.79833984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.3870849609375
Train_StdReturn : 0.0
Train_MaxReturn : 946.3870849609375
Train_MinReturn : 946.3870849609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 26000
TimeSinceStart : 224.37963247299194
Training Loss : 0.0004867923562414944
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 27 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.7889404296875
Eval_StdReturn : 14.750779151916504
Eval_MaxReturn : 955.29931640625
Eval_MinReturn : 915.1537475585938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.7344970703125
Train_StdReturn : 0.0
Train_MaxReturn : 940.7344970703125
Train_MinReturn : 940.7344970703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 27000
TimeSinceStart : 232.98832845687866
Training Loss : 0.0003849471395369619
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 28 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.7213134765625
Eval_StdReturn : 7.667628288269043
Eval_MaxReturn : 951.1981201171875
Eval_MinReturn : 931.6110229492188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 907.47021484375
Train_StdReturn : 0.0
Train_MaxReturn : 907.47021484375
Train_MinReturn : 907.47021484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 28000
TimeSinceStart : 241.64959454536438
Training Loss : 0.0003554504655767232
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 29 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.0048828125
Eval_StdReturn : 6.870392799377441
Eval_MaxReturn : 950.6177978515625
Eval_MinReturn : 931.1616821289062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.83544921875
Train_StdReturn : 0.0
Train_MaxReturn : 952.83544921875
Train_MinReturn : 952.83544921875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 29000
TimeSinceStart : 250.21607446670532
Training Loss : 0.00020464256522245705
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 30 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 933.2991943359375
Eval_StdReturn : 7.776274681091309
Eval_MaxReturn : 944.1746826171875
Eval_MinReturn : 924.389892578125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.3751220703125
Train_StdReturn : 0.0
Train_MaxReturn : 950.3751220703125
Train_MinReturn : 950.3751220703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 30000
TimeSinceStart : 258.8709990978241
Training Loss : 0.000400032993638888
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 31 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.4713134765625
Eval_StdReturn : 9.516749382019043
Eval_MaxReturn : 950.3202514648438
Eval_MinReturn : 923.8114013671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.736083984375
Train_StdReturn : 0.0
Train_MaxReturn : 938.736083984375
Train_MinReturn : 938.736083984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 31000
TimeSinceStart : 267.6135334968567
Training Loss : 8.301690104417503e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 32 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.9464111328125
Eval_StdReturn : 7.217662334442139
Eval_MaxReturn : 957.2698364257812
Eval_MinReturn : 935.8930053710938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.2816772460938
Train_StdReturn : 0.0
Train_MaxReturn : 936.2816772460938
Train_MinReturn : 936.2816772460938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 32000
TimeSinceStart : 276.19950914382935
Training Loss : 0.00022177484061103314
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 33 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.31787109375
Eval_StdReturn : 4.2528157234191895
Eval_MaxReturn : 943.029296875
Eval_MinReturn : 930.869384765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 963.2234497070312
Train_StdReturn : 0.0
Train_MaxReturn : 963.2234497070312
Train_MinReturn : 963.2234497070312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 33000
TimeSinceStart : 284.7434504032135
Training Loss : 0.0002562151930760592
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 34 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.6458129882812
Eval_StdReturn : 7.556497097015381
Eval_MaxReturn : 962.2117919921875
Eval_MinReturn : 943.5953369140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 916.4853515625
Train_StdReturn : 0.0
Train_MaxReturn : 916.4853515625
Train_MinReturn : 916.4853515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 34000
TimeSinceStart : 292.53600692749023
Training Loss : 0.00023357778263743967
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 35 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.4566650390625
Eval_StdReturn : 3.2619566917419434
Eval_MaxReturn : 953.2677001953125
Eval_MinReturn : 943.3663330078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 926.8418579101562
Train_StdReturn : 0.0
Train_MaxReturn : 926.8418579101562
Train_MinReturn : 926.8418579101562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 35000
TimeSinceStart : 300.45216131210327
Training Loss : 0.00028880403260700405
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 36 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.1556396484375
Eval_StdReturn : 12.48650074005127
Eval_MaxReturn : 962.9447631835938
Eval_MinReturn : 931.486572265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.0228271484375
Train_StdReturn : 0.0
Train_MaxReturn : 942.0228271484375
Train_MinReturn : 942.0228271484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 36000
TimeSinceStart : 309.22244334220886
Training Loss : 0.00019312824588268995
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 37 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 933.7996826171875
Eval_StdReturn : 5.202693939208984
Eval_MaxReturn : 942.0982055664062
Eval_MinReturn : 926.4749755859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 931.3763427734375
Train_StdReturn : 0.0
Train_MaxReturn : 931.3763427734375
Train_MinReturn : 931.3763427734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 37000
TimeSinceStart : 317.8709990978241
Training Loss : 0.00025683880085125566
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 38 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.1600341796875
Eval_StdReturn : 9.166961669921875
Eval_MaxReturn : 956.251953125
Eval_MinReturn : 933.999267578125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 932.8363037109375
Train_StdReturn : 0.0
Train_MaxReturn : 932.8363037109375
Train_MinReturn : 932.8363037109375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 38000
TimeSinceStart : 326.36697340011597
Training Loss : 0.0002554380043875426
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 39 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.7380981445312
Eval_StdReturn : 5.45559024810791
Eval_MaxReturn : 953.8121948242188
Eval_MinReturn : 939.2232055664062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.0624389648438
Train_StdReturn : 0.0
Train_MaxReturn : 942.0624389648438
Train_MinReturn : 942.0624389648438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 39000
TimeSinceStart : 335.18086886405945
Training Loss : 0.0002430812455713749
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 40 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.5388793945312
Eval_StdReturn : 16.767719268798828
Eval_MaxReturn : 969.6055908203125
Eval_MinReturn : 928.004638671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.1341552734375
Train_StdReturn : 0.0
Train_MaxReturn : 941.1341552734375
Train_MinReturn : 941.1341552734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 40000
TimeSinceStart : 344.43801641464233
Training Loss : 0.0005059311515651643
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 41 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.9515380859375
Eval_StdReturn : 4.167971134185791
Eval_MaxReturn : 951.0433349609375
Eval_MinReturn : 940.5537109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.2112426757812
Train_StdReturn : 0.0
Train_MaxReturn : 939.2112426757812
Train_MinReturn : 939.2112426757812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 41000
TimeSinceStart : 353.06156492233276
Training Loss : 0.00042546598706394434
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 42 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.6246337890625
Eval_StdReturn : 7.303849697113037
Eval_MaxReturn : 959.902587890625
Eval_MinReturn : 939.494140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.14501953125
Train_StdReturn : 0.0
Train_MaxReturn : 958.14501953125
Train_MinReturn : 958.14501953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 42000
TimeSinceStart : 361.94204807281494
Training Loss : 0.00044140024692751467
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 43 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.6253662109375
Eval_StdReturn : 14.253213882446289
Eval_MaxReturn : 962.7928466796875
Eval_MinReturn : 921.2169799804688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 957.2830810546875
Train_StdReturn : 0.0
Train_MaxReturn : 957.2830810546875
Train_MinReturn : 957.2830810546875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 43000
TimeSinceStart : 370.7140715122223
Training Loss : 0.00015415644156746566
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 44 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 955.40966796875
Eval_StdReturn : 9.051140785217285
Eval_MaxReturn : 967.35693359375
Eval_MinReturn : 945.96728515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.561767578125
Train_StdReturn : 0.0
Train_MaxReturn : 953.561767578125
Train_MinReturn : 953.561767578125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 44000
TimeSinceStart : 379.5024654865265
Training Loss : 0.00016085586685221642
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 45 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 953.0111083984375
Eval_StdReturn : 8.406637191772461
Eval_MaxReturn : 963.0419921875
Eval_MinReturn : 940.1136474609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.3544921875
Train_StdReturn : 0.0
Train_MaxReturn : 943.3544921875
Train_MinReturn : 943.3544921875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 45000
TimeSinceStart : 388.10939860343933
Training Loss : 4.098776480532251e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 46 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.9221801757812
Eval_StdReturn : 7.42704439163208
Eval_MaxReturn : 956.4371337890625
Eval_MinReturn : 933.4868774414062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.5799560546875
Train_StdReturn : 0.0
Train_MaxReturn : 951.5799560546875
Train_MinReturn : 951.5799560546875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 46000
TimeSinceStart : 396.49181389808655
Training Loss : 0.00010201832628808916
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 47 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.5699462890625
Eval_StdReturn : 8.649524688720703
Eval_MaxReturn : 958.5100708007812
Eval_MinReturn : 939.31005859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.2073974609375
Train_StdReturn : 0.0
Train_MaxReturn : 946.2073974609375
Train_MinReturn : 946.2073974609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 47000
TimeSinceStart : 405.33613681793213
Training Loss : 0.00024150720855686814
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 48 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.73779296875
Eval_StdReturn : 8.001334190368652
Eval_MaxReturn : 950.1410522460938
Eval_MinReturn : 929.17138671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.9088134765625
Train_StdReturn : 0.0
Train_MaxReturn : 955.9088134765625
Train_MinReturn : 955.9088134765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 48000
TimeSinceStart : 413.7381589412689
Training Loss : 0.0004656522360164672
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 49 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.5953369140625
Eval_StdReturn : 10.991414070129395
Eval_MaxReturn : 956.0546875
Eval_MinReturn : 926.8034057617188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.2156982421875
Train_StdReturn : 0.0
Train_MaxReturn : 950.2156982421875
Train_MinReturn : 950.2156982421875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 49000
TimeSinceStart : 422.61331963539124
Training Loss : 0.0005690761026926339
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 50 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.4070434570312
Eval_StdReturn : 17.336668014526367
Eval_MaxReturn : 971.09716796875
Eval_MinReturn : 917.369873046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.0526733398438
Train_StdReturn : 0.0
Train_MaxReturn : 947.0526733398438
Train_MinReturn : 947.0526733398438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 50000
TimeSinceStart : 431.67650508880615
Training Loss : 0.00015494966646656394
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 51 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 953.1463012695312
Eval_StdReturn : 12.31486701965332
Eval_MaxReturn : 971.9158325195312
Eval_MinReturn : 938.5512084960938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.8871459960938
Train_StdReturn : 0.0
Train_MaxReturn : 943.8871459960938
Train_MinReturn : 943.8871459960938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 51000
TimeSinceStart : 440.5652642250061
Training Loss : 0.0003525335341691971
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 52 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 952.3029174804688
Eval_StdReturn : 16.243118286132812
Eval_MaxReturn : 970.809814453125
Eval_MinReturn : 928.4097900390625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.38916015625
Train_StdReturn : 0.0
Train_MaxReturn : 947.38916015625
Train_MinReturn : 947.38916015625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 52000
TimeSinceStart : 449.31129145622253
Training Loss : 0.00029546520090661943
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 53 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.26318359375
Eval_StdReturn : 7.720533847808838
Eval_MaxReturn : 949.607666015625
Eval_MinReturn : 928.529296875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 931.5916748046875
Train_StdReturn : 0.0
Train_MaxReturn : 931.5916748046875
Train_MinReturn : 931.5916748046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 53000
TimeSinceStart : 457.9749960899353
Training Loss : 0.00026772695127874613
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 54 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 954.8212890625
Eval_StdReturn : 7.687862873077393
Eval_MaxReturn : 963.90771484375
Eval_MinReturn : 942.828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 960.3386840820312
Train_StdReturn : 0.0
Train_MaxReturn : 960.3386840820312
Train_MinReturn : 960.3386840820312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 54000
TimeSinceStart : 466.86864161491394
Training Loss : 0.00033283219090662897
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 55 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.8963012695312
Eval_StdReturn : 7.067010402679443
Eval_MaxReturn : 957.4840087890625
Eval_MinReturn : 936.786376953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.2937622070312
Train_StdReturn : 0.0
Train_MaxReturn : 958.2937622070312
Train_MinReturn : 958.2937622070312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 55000
TimeSinceStart : 474.9362051486969
Training Loss : 0.000499770394526422
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 56 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.0283203125
Eval_StdReturn : 10.410677909851074
Eval_MaxReturn : 955.661376953125
Eval_MinReturn : 925.2166748046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.0482788085938
Train_StdReturn : 0.0
Train_MaxReturn : 943.0482788085938
Train_MinReturn : 943.0482788085938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 56000
TimeSinceStart : 483.6971354484558
Training Loss : 0.00026973700732924044
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 57 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.0845947265625
Eval_StdReturn : 13.714722633361816
Eval_MaxReturn : 958.45458984375
Eval_MinReturn : 922.121337890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 930.2069702148438
Train_StdReturn : 0.0
Train_MaxReturn : 930.2069702148438
Train_MinReturn : 930.2069702148438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 57000
TimeSinceStart : 492.22459053993225
Training Loss : 0.00044208168401382864
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 58 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 933.2288818359375
Eval_StdReturn : 9.139251708984375
Eval_MaxReturn : 943.6260986328125
Eval_MinReturn : 916.080810546875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.152099609375
Train_StdReturn : 0.0
Train_MaxReturn : 938.152099609375
Train_MinReturn : 938.152099609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 58000
TimeSinceStart : 500.9560148715973
Training Loss : 0.00020256808784324676
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 59 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.5792236328125
Eval_StdReturn : 8.323431015014648
Eval_MaxReturn : 948.932861328125
Eval_MinReturn : 924.9029541015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 961.5147094726562
Train_StdReturn : 0.0
Train_MaxReturn : 961.5147094726562
Train_MinReturn : 961.5147094726562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 59000
TimeSinceStart : 510.0504744052887
Training Loss : 0.0003424824681133032
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 60 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 955.0245971679688
Eval_StdReturn : 11.37244987487793
Eval_MaxReturn : 966.6964111328125
Eval_MinReturn : 934.0934448242188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.2353515625
Train_StdReturn : 0.0
Train_MaxReturn : 935.2353515625
Train_MinReturn : 935.2353515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 60000
TimeSinceStart : 519.0160050392151
Training Loss : 0.00014550644846167415
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 61 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.33251953125
Eval_StdReturn : 11.00810718536377
Eval_MaxReturn : 964.065185546875
Eval_MinReturn : 932.996337890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.5643310546875
Train_StdReturn : 0.0
Train_MaxReturn : 945.5643310546875
Train_MinReturn : 945.5643310546875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 61000
TimeSinceStart : 527.7297894954681
Training Loss : 0.0003030010557267815
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 62 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.0769653320312
Eval_StdReturn : 6.912288665771484
Eval_MaxReturn : 954.056640625
Eval_MinReturn : 933.412109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.1392211914062
Train_StdReturn : 0.0
Train_MaxReturn : 933.1392211914062
Train_MinReturn : 933.1392211914062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 62000
TimeSinceStart : 536.5785024166107
Training Loss : 0.00069983652792871
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 63 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.0997314453125
Eval_StdReturn : 9.83772087097168
Eval_MaxReturn : 960.913330078125
Eval_MinReturn : 931.5264282226562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.4596557617188
Train_StdReturn : 0.0
Train_MaxReturn : 956.4596557617188
Train_MinReturn : 956.4596557617188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 63000
TimeSinceStart : 545.7274134159088
Training Loss : 0.0002654682903084904
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 64 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.0227661132812
Eval_StdReturn : 11.853857040405273
Eval_MaxReturn : 964.686279296875
Eval_MinReturn : 929.96044921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.9865112304688
Train_StdReturn : 0.0
Train_MaxReturn : 955.9865112304688
Train_MinReturn : 955.9865112304688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 64000
TimeSinceStart : 554.8084783554077
Training Loss : 7.616604852955788e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 65 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.53125
Eval_StdReturn : 12.272445678710938
Eval_MaxReturn : 956.0919189453125
Eval_MinReturn : 922.4186401367188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.7964477539062
Train_StdReturn : 0.0
Train_MaxReturn : 936.7964477539062
Train_MinReturn : 936.7964477539062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 65000
TimeSinceStart : 563.7515978813171
Training Loss : 0.0005382939125411212
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 66 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 956.0433349609375
Eval_StdReturn : 7.899320125579834
Eval_MaxReturn : 964.51318359375
Eval_MinReturn : 944.19140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 957.3897705078125
Train_StdReturn : 0.0
Train_MaxReturn : 957.3897705078125
Train_MinReturn : 957.3897705078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 66000
TimeSinceStart : 572.6550390720367
Training Loss : 0.00041252642404288054
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 67 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.2838745117188
Eval_StdReturn : 9.873939514160156
Eval_MaxReturn : 953.1436767578125
Eval_MinReturn : 925.1978149414062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 961.4898071289062
Train_StdReturn : 0.0
Train_MaxReturn : 961.4898071289062
Train_MinReturn : 961.4898071289062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 67000
TimeSinceStart : 581.8084285259247
Training Loss : 0.00032461161026731133
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 68 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.7686767578125
Eval_StdReturn : 8.613690376281738
Eval_MaxReturn : 959.8651123046875
Eval_MinReturn : 940.049560546875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 963.82275390625
Train_StdReturn : 0.0
Train_MaxReturn : 963.82275390625
Train_MinReturn : 963.82275390625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 68000
TimeSinceStart : 591.106636762619
Training Loss : 7.14892812538892e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 69 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.4102783203125
Eval_StdReturn : 6.767284393310547
Eval_MaxReturn : 959.992431640625
Eval_MinReturn : 939.1029052734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.7186279296875
Train_StdReturn : 0.0
Train_MaxReturn : 954.7186279296875
Train_MinReturn : 954.7186279296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 69000
TimeSinceStart : 600.2867755889893
Training Loss : 0.0002869475865736604
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 70 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.4677734375
Eval_StdReturn : 15.362171173095703
Eval_MaxReturn : 968.4166259765625
Eval_MinReturn : 927.2916870117188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.6229248046875
Train_StdReturn : 0.0
Train_MaxReturn : 946.6229248046875
Train_MinReturn : 946.6229248046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 70000
TimeSinceStart : 609.4116106033325
Training Loss : 0.0004913228913210332
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 71 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.6044921875
Eval_StdReturn : 9.854670524597168
Eval_MaxReturn : 956.9241943359375
Eval_MinReturn : 930.8750610351562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.0296020507812
Train_StdReturn : 0.0
Train_MaxReturn : 939.0296020507812
Train_MinReturn : 939.0296020507812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 71000
TimeSinceStart : 618.5087745189667
Training Loss : 0.0005279791075736284
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 72 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.4983520507812
Eval_StdReturn : 7.506748199462891
Eval_MaxReturn : 957.6332397460938
Eval_MinReturn : 936.622802734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 959.38818359375
Train_StdReturn : 0.0
Train_MaxReturn : 959.38818359375
Train_MinReturn : 959.38818359375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 72000
TimeSinceStart : 627.5739362239838
Training Loss : 0.0004851043049711734
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 73 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.8851318359375
Eval_StdReturn : 11.583044052124023
Eval_MaxReturn : 956.7127685546875
Eval_MinReturn : 924.708984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 957.9671020507812
Train_StdReturn : 0.0
Train_MaxReturn : 957.9671020507812
Train_MinReturn : 957.9671020507812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 73000
TimeSinceStart : 637.1282513141632
Training Loss : 0.0002891799667850137
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 74 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.875
Eval_StdReturn : 9.006552696228027
Eval_MaxReturn : 960.4171142578125
Eval_MinReturn : 938.543212890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.286376953125
Train_StdReturn : 0.0
Train_MaxReturn : 941.286376953125
Train_MinReturn : 941.286376953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 74000
TimeSinceStart : 646.2823066711426
Training Loss : 0.0002016909420490265
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 75 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.2390747070312
Eval_StdReturn : 11.719527244567871
Eval_MaxReturn : 953.4857177734375
Eval_MinReturn : 923.2479248046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.3323974609375
Train_StdReturn : 0.0
Train_MaxReturn : 955.3323974609375
Train_MinReturn : 955.3323974609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 75000
TimeSinceStart : 655.6635625362396
Training Loss : 0.0003677428176160902
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 76 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.01171875
Eval_StdReturn : 11.22425651550293
Eval_MaxReturn : 950.6394653320312
Eval_MinReturn : 918.4935302734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.108154296875
Train_StdReturn : 0.0
Train_MaxReturn : 936.108154296875
Train_MinReturn : 936.108154296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 76000
TimeSinceStart : 664.185777425766
Training Loss : 0.0001753814722178504
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 77 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 935.3284301757812
Eval_StdReturn : 7.303956985473633
Eval_MaxReturn : 941.8171997070312
Eval_MinReturn : 921.4349365234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.84716796875
Train_StdReturn : 0.0
Train_MaxReturn : 942.84716796875
Train_MinReturn : 942.84716796875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 77000
TimeSinceStart : 673.6819503307343
Training Loss : 0.0002079349651467055
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 78 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.3283081054688
Eval_StdReturn : 9.552865982055664
Eval_MaxReturn : 955.5277099609375
Eval_MinReturn : 932.5374755859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 967.198486328125
Train_StdReturn : 0.0
Train_MaxReturn : 967.198486328125
Train_MinReturn : 967.198486328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 78000
TimeSinceStart : 682.9026215076447
Training Loss : 0.0005289996042847633
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 79 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.8482666015625
Eval_StdReturn : 9.653948783874512
Eval_MaxReturn : 957.884033203125
Eval_MinReturn : 931.1649169921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.55029296875
Train_StdReturn : 0.0
Train_MaxReturn : 958.55029296875
Train_MinReturn : 958.55029296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 79000
TimeSinceStart : 692.0782806873322
Training Loss : 0.000804356939624995
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 80 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.9334106445312
Eval_StdReturn : 9.984642028808594
Eval_MaxReturn : 959.4027099609375
Eval_MinReturn : 929.600341796875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 960.0051879882812
Train_StdReturn : 0.0
Train_MaxReturn : 960.0051879882812
Train_MinReturn : 960.0051879882812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 80000
TimeSinceStart : 701.4107339382172
Training Loss : 0.00017367592954542488
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 81 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.1954345703125
Eval_StdReturn : 9.32754898071289
Eval_MaxReturn : 946.6713256835938
Eval_MinReturn : 920.0339965820312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 928.2532958984375
Train_StdReturn : 0.0
Train_MaxReturn : 928.2532958984375
Train_MinReturn : 928.2532958984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 81000
TimeSinceStart : 710.707554101944
Training Loss : 0.00019915822485927492
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 82 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.6593627929688
Eval_StdReturn : 6.310546875
Eval_MaxReturn : 953.2383422851562
Eval_MinReturn : 933.691650390625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.45458984375
Train_StdReturn : 0.0
Train_MaxReturn : 958.45458984375
Train_MinReturn : 958.45458984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 82000
TimeSinceStart : 719.8314867019653
Training Loss : 0.0001283814199268818
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 83 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 953.7897338867188
Eval_StdReturn : 5.546184062957764
Eval_MaxReturn : 963.8677978515625
Eval_MinReturn : 947.779541015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.7874755859375
Train_StdReturn : 0.0
Train_MaxReturn : 950.7874755859375
Train_MinReturn : 950.7874755859375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 83000
TimeSinceStart : 729.3707468509674
Training Loss : 0.000258339277934283
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 84 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.76025390625
Eval_StdReturn : 7.7805256843566895
Eval_MaxReturn : 959.416015625
Eval_MinReturn : 936.4406127929688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 930.505859375
Train_StdReturn : 0.0
Train_MaxReturn : 930.505859375
Train_MinReturn : 930.505859375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 84000
TimeSinceStart : 738.8359336853027
Training Loss : 0.00020137059618718922
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 85 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.6901245117188
Eval_StdReturn : 12.508944511413574
Eval_MaxReturn : 970.3665771484375
Eval_MinReturn : 935.565185546875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.2662353515625
Train_StdReturn : 0.0
Train_MaxReturn : 954.2662353515625
Train_MinReturn : 954.2662353515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 85000
TimeSinceStart : 747.960616350174
Training Loss : 0.0004854471771977842
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 86 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.9439697265625
Eval_StdReturn : 10.670729637145996
Eval_MaxReturn : 966.28173828125
Eval_MinReturn : 936.7545166015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.772216796875
Train_StdReturn : 0.0
Train_MaxReturn : 950.772216796875
Train_MinReturn : 950.772216796875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 86000
TimeSinceStart : 757.1808686256409
Training Loss : 0.00027532779495231807
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 87 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.4501953125
Eval_StdReturn : 14.688741683959961
Eval_MaxReturn : 966.90185546875
Eval_MinReturn : 929.8804931640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.0682373046875
Train_StdReturn : 0.0
Train_MaxReturn : 933.0682373046875
Train_MinReturn : 933.0682373046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 87000
TimeSinceStart : 766.7207310199738
Training Loss : 0.0002319637278560549
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 88 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.8536987304688
Eval_StdReturn : 5.912563800811768
Eval_MaxReturn : 955.3506469726562
Eval_MinReturn : 938.9410400390625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.0513916015625
Train_StdReturn : 0.0
Train_MaxReturn : 936.0513916015625
Train_MinReturn : 936.0513916015625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 88000
TimeSinceStart : 775.96959400177
Training Loss : 0.00021710841974709183
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 89 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.3069458007812
Eval_StdReturn : 5.413056373596191
Eval_MaxReturn : 960.9658203125
Eval_MinReturn : 945.5963134765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.741455078125
Train_StdReturn : 0.0
Train_MaxReturn : 948.741455078125
Train_MinReturn : 948.741455078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 89000
TimeSinceStart : 784.4494125843048
Training Loss : 0.00013971513544674963
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 90 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.9005737304688
Eval_StdReturn : 4.657543659210205
Eval_MaxReturn : 944.8572998046875
Eval_MinReturn : 931.662353515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 960.7640991210938
Train_StdReturn : 0.0
Train_MaxReturn : 960.7640991210938
Train_MinReturn : 960.7640991210938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 90000
TimeSinceStart : 793.1956555843353
Training Loss : 0.00011118249676655978
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 91 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.5182495117188
Eval_StdReturn : 10.1492338180542
Eval_MaxReturn : 957.8990478515625
Eval_MinReturn : 927.881591796875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 957.3780517578125
Train_StdReturn : 0.0
Train_MaxReturn : 957.3780517578125
Train_MinReturn : 957.3780517578125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 91000
TimeSinceStart : 802.0049605369568
Training Loss : 0.00031766112078912556
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 92 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.9151611328125
Eval_StdReturn : 7.679234981536865
Eval_MaxReturn : 960.571533203125
Eval_MinReturn : 938.7761840820312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.2670288085938
Train_StdReturn : 0.0
Train_MaxReturn : 955.2670288085938
Train_MinReturn : 955.2670288085938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 92000
TimeSinceStart : 811.0408799648285
Training Loss : 0.0004460478958208114
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 93 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.4324951171875
Eval_StdReturn : 6.616281986236572
Eval_MaxReturn : 956.3568115234375
Eval_MinReturn : 937.2063598632812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.0098876953125
Train_StdReturn : 0.0
Train_MaxReturn : 937.0098876953125
Train_MinReturn : 937.0098876953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 93000
TimeSinceStart : 820.5568332672119
Training Loss : 0.00030171446269378066
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 94 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.4899291992188
Eval_StdReturn : 15.945768356323242
Eval_MaxReturn : 971.6014404296875
Eval_MinReturn : 924.858154296875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.61083984375
Train_StdReturn : 0.0
Train_MaxReturn : 937.61083984375
Train_MinReturn : 937.61083984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 94000
TimeSinceStart : 830.1909499168396
Training Loss : 0.00034287889138795435
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 95 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 932.6427001953125
Eval_StdReturn : 9.142300605773926
Eval_MaxReturn : 945.4075927734375
Eval_MinReturn : 923.726806640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.868896484375
Train_StdReturn : 0.0
Train_MaxReturn : 947.868896484375
Train_MinReturn : 947.868896484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 95000
TimeSinceStart : 839.782116651535
Training Loss : 0.0006322449189610779
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 96 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 931.4871826171875
Eval_StdReturn : 17.793506622314453
Eval_MaxReturn : 953.362548828125
Eval_MinReturn : 912.4716186523438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.55078125
Train_StdReturn : 0.0
Train_MaxReturn : 950.55078125
Train_MinReturn : 950.55078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 96000
TimeSinceStart : 849.1112639904022
Training Loss : 0.0016700043343007565
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 97 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.6795043945312
Eval_StdReturn : 10.627347946166992
Eval_MaxReturn : 947.8419189453125
Eval_MinReturn : 918.6300048828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 912.8414306640625
Train_StdReturn : 0.0
Train_MaxReturn : 912.8414306640625
Train_MinReturn : 912.8414306640625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 97000
TimeSinceStart : 857.9100704193115
Training Loss : 8.316625462612137e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 98 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.5716552734375
Eval_StdReturn : 6.442704677581787
Eval_MaxReturn : 961.797119140625
Eval_MinReturn : 942.7171630859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 931.323974609375
Train_StdReturn : 0.0
Train_MaxReturn : 931.323974609375
Train_MinReturn : 931.323974609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 98000
TimeSinceStart : 867.5889406204224
Training Loss : 0.00019413155678194016
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 99 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.6832885742188
Eval_StdReturn : 8.458878517150879
Eval_MaxReturn : 948.3992919921875
Eval_MinReturn : 924.7893676757812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.913330078125
Train_StdReturn : 0.0
Train_MaxReturn : 934.913330078125
Train_MinReturn : 934.913330078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 99000
TimeSinceStart : 877.0056307315826
Training Loss : 0.0005385010736063123
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 100 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 933.1029052734375
Eval_StdReturn : 9.570913314819336
Eval_MaxReturn : 947.0169067382812
Eval_MinReturn : 917.949462890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 932.4295654296875
Train_StdReturn : 0.0
Train_MaxReturn : 932.4295654296875
Train_MinReturn : 932.4295654296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 100000
TimeSinceStart : 886.7074656486511
Training Loss : 0.0002004138077609241
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 101 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.1904296875
Eval_StdReturn : 12.817203521728516
Eval_MaxReturn : 965.0156860351562
Eval_MinReturn : 929.7424926757812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.4462890625
Train_StdReturn : 0.0
Train_MaxReturn : 950.4462890625
Train_MinReturn : 950.4462890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 101000
TimeSinceStart : 896.1984055042267
Training Loss : 0.00012400312698446214
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 102 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.4459228515625
Eval_StdReturn : 11.070743560791016
Eval_MaxReturn : 960.174560546875
Eval_MinReturn : 929.6409301757812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 930.9932861328125
Train_StdReturn : 0.0
Train_MaxReturn : 930.9932861328125
Train_MinReturn : 930.9932861328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 102000
TimeSinceStart : 905.7538990974426
Training Loss : 3.450655276537873e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 103 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.0343017578125
Eval_StdReturn : 13.35897159576416
Eval_MaxReturn : 958.6485595703125
Eval_MinReturn : 919.278564453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 929.5589599609375
Train_StdReturn : 0.0
Train_MaxReturn : 929.5589599609375
Train_MinReturn : 929.5589599609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 103000
TimeSinceStart : 915.4839124679565
Training Loss : 6.624154048040509e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 104 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 952.16015625
Eval_StdReturn : 11.086338996887207
Eval_MaxReturn : 961.4208984375
Eval_MinReturn : 934.605224609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 923.2101440429688
Train_StdReturn : 0.0
Train_MaxReturn : 923.2101440429688
Train_MinReturn : 923.2101440429688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 104000
TimeSinceStart : 924.980012178421
Training Loss : 0.00012281033559702337
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 105 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.4337158203125
Eval_StdReturn : 7.487551689147949
Eval_MaxReturn : 953.2427978515625
Eval_MinReturn : 931.5083618164062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 965.95751953125
Train_StdReturn : 0.0
Train_MaxReturn : 965.95751953125
Train_MinReturn : 965.95751953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 105000
TimeSinceStart : 934.6269154548645
Training Loss : 0.0006318488740362227
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 106 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.0437622070312
Eval_StdReturn : 7.871435642242432
Eval_MaxReturn : 955.2337646484375
Eval_MinReturn : 934.5244140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 960.43359375
Train_StdReturn : 0.0
Train_MaxReturn : 960.43359375
Train_MinReturn : 960.43359375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 106000
TimeSinceStart : 944.2246668338776
Training Loss : 0.00024247542023658752
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 107 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 933.7943115234375
Eval_StdReturn : 7.850121974945068
Eval_MaxReturn : 943.778076171875
Eval_MinReturn : 924.137939453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.8353881835938
Train_StdReturn : 0.0
Train_MaxReturn : 950.8353881835938
Train_MinReturn : 950.8353881835938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 107000
TimeSinceStart : 952.9770574569702
Training Loss : 0.0004404328647069633
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 108 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.8232421875
Eval_StdReturn : 3.2121050357818604
Eval_MaxReturn : 949.4566040039062
Eval_MinReturn : 940.837646484375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.5762329101562
Train_StdReturn : 0.0
Train_MaxReturn : 948.5762329101562
Train_MinReturn : 948.5762329101562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 108000
TimeSinceStart : 962.0289032459259
Training Loss : 0.00018422074208501726
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 109 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.67529296875
Eval_StdReturn : 10.146577835083008
Eval_MaxReturn : 955.3109130859375
Eval_MinReturn : 925.84912109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.6602783203125
Train_StdReturn : 0.0
Train_MaxReturn : 950.6602783203125
Train_MinReturn : 950.6602783203125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 109000
TimeSinceStart : 971.6181545257568
Training Loss : 0.00023224517644848675
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 110 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.2139892578125
Eval_StdReturn : 6.2393798828125
Eval_MaxReturn : 955.52880859375
Eval_MinReturn : 941.3644409179688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 928.6727294921875
Train_StdReturn : 0.0
Train_MaxReturn : 928.6727294921875
Train_MinReturn : 928.6727294921875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 110000
TimeSinceStart : 981.2020230293274
Training Loss : 0.0002183382021030411
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 111 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.7044677734375
Eval_StdReturn : 8.838775634765625
Eval_MaxReturn : 952.91455078125
Eval_MinReturn : 928.0053100585938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.3079833984375
Train_StdReturn : 0.0
Train_MaxReturn : 940.3079833984375
Train_MinReturn : 940.3079833984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 111000
TimeSinceStart : 990.0881404876709
Training Loss : 0.0002470170729793608
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 112 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.49267578125
Eval_StdReturn : 6.974227428436279
Eval_MaxReturn : 956.39892578125
Eval_MinReturn : 937.9503173828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 924.1102294921875
Train_StdReturn : 0.0
Train_MaxReturn : 924.1102294921875
Train_MinReturn : 924.1102294921875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 112000
TimeSinceStart : 998.9970691204071
Training Loss : 0.0003192937292624265
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 113 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 935.8643798828125
Eval_StdReturn : 7.825379371643066
Eval_MaxReturn : 947.91552734375
Eval_MinReturn : 925.7122192382812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.4053955078125
Train_StdReturn : 0.0
Train_MaxReturn : 943.4053955078125
Train_MinReturn : 943.4053955078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 113000
TimeSinceStart : 1008.3504679203033
Training Loss : 4.219976472086273e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 114 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.8204345703125
Eval_StdReturn : 9.514966011047363
Eval_MaxReturn : 959.3903198242188
Eval_MinReturn : 935.95947265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.3167114257812
Train_StdReturn : 0.0
Train_MaxReturn : 951.3167114257812
Train_MinReturn : 951.3167114257812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 114000
TimeSinceStart : 1018.249890089035
Training Loss : 0.0002410394954495132
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 115 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.6788940429688
Eval_StdReturn : 12.29100513458252
Eval_MaxReturn : 961.5985107421875
Eval_MinReturn : 927.0106201171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.01171875
Train_StdReturn : 0.0
Train_MaxReturn : 941.01171875
Train_MinReturn : 941.01171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 115000
TimeSinceStart : 1027.6849081516266
Training Loss : 0.00016567246348131448
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 116 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.0987548828125
Eval_StdReturn : 14.613836288452148
Eval_MaxReturn : 960.8767700195312
Eval_MinReturn : 919.9771728515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 963.685302734375
Train_StdReturn : 0.0
Train_MaxReturn : 963.685302734375
Train_MinReturn : 963.685302734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 116000
TimeSinceStart : 1037.2958798408508
Training Loss : 0.0002768410195130855
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 117 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 953.7054443359375
Eval_StdReturn : 5.698959827423096
Eval_MaxReturn : 960.611328125
Eval_MinReturn : 943.607421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 922.6417236328125
Train_StdReturn : 0.0
Train_MaxReturn : 922.6417236328125
Train_MinReturn : 922.6417236328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 117000
TimeSinceStart : 1047.0275673866272
Training Loss : 0.00017544662114232779
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 118 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 952.8903198242188
Eval_StdReturn : 16.089832305908203
Eval_MaxReturn : 974.0323486328125
Eval_MinReturn : 934.4520874023438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.7042846679688
Train_StdReturn : 0.0
Train_MaxReturn : 955.7042846679688
Train_MinReturn : 955.7042846679688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 118000
TimeSinceStart : 1056.5950870513916
Training Loss : 6.10884526395239e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 119 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 928.7005615234375
Eval_StdReturn : 7.9122843742370605
Eval_MaxReturn : 938.1036376953125
Eval_MinReturn : 918.66650390625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.72802734375
Train_StdReturn : 0.0
Train_MaxReturn : 953.72802734375
Train_MinReturn : 953.72802734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 119000
TimeSinceStart : 1065.94140458107
Training Loss : 0.00012264800898265094
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 120 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.5626220703125
Eval_StdReturn : 4.371517181396484
Eval_MaxReturn : 954.4598999023438
Eval_MinReturn : 942.3809204101562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 926.252197265625
Train_StdReturn : 0.0
Train_MaxReturn : 926.252197265625
Train_MinReturn : 926.252197265625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 120000
TimeSinceStart : 1075.7549452781677
Training Loss : 0.0003365426673553884
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 121 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.0704956054688
Eval_StdReturn : 8.430147171020508
Eval_MaxReturn : 954.0585327148438
Eval_MinReturn : 930.00244140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 965.2559814453125
Train_StdReturn : 0.0
Train_MaxReturn : 965.2559814453125
Train_MinReturn : 965.2559814453125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 121000
TimeSinceStart : 1085.7409100532532
Training Loss : 0.00032377871684730053
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 122 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.4513549804688
Eval_StdReturn : 18.591875076293945
Eval_MaxReturn : 960.89794921875
Eval_MinReturn : 910.77294921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 957.7183227539062
Train_StdReturn : 0.0
Train_MaxReturn : 957.7183227539062
Train_MinReturn : 957.7183227539062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 122000
TimeSinceStart : 1095.8329508304596
Training Loss : 0.00029959887615405023
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 123 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.3966064453125
Eval_StdReturn : 6.452080249786377
Eval_MaxReturn : 956.8790283203125
Eval_MinReturn : 940.88916015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.370361328125
Train_StdReturn : 0.0
Train_MaxReturn : 956.370361328125
Train_MinReturn : 956.370361328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 123000
TimeSinceStart : 1105.8969459533691
Training Loss : 0.00020825749379582703
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 124 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.9264526367188
Eval_StdReturn : 16.490243911743164
Eval_MaxReturn : 965.994384765625
Eval_MinReturn : 920.243896484375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 924.5599975585938
Train_StdReturn : 0.0
Train_MaxReturn : 924.5599975585938
Train_MinReturn : 924.5599975585938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 124000
TimeSinceStart : 1115.73389005661
Training Loss : 0.00020205703913234174
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 125 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.7547607421875
Eval_StdReturn : 15.023534774780273
Eval_MaxReturn : 966.2471923828125
Eval_MinReturn : 922.8609619140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.9583740234375
Train_StdReturn : 0.0
Train_MaxReturn : 939.9583740234375
Train_MinReturn : 939.9583740234375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 125000
TimeSinceStart : 1125.1340913772583
Training Loss : 0.00028224155539646745
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 126 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.1768798828125
Eval_StdReturn : 7.586929798126221
Eval_MaxReturn : 955.4840087890625
Eval_MinReturn : 938.8616943359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.5791625976562
Train_StdReturn : 0.0
Train_MaxReturn : 940.5791625976562
Train_MinReturn : 940.5791625976562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 126000
TimeSinceStart : 1135.1050209999084
Training Loss : 0.00038536955253221095
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 127 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 952.7091674804688
Eval_StdReturn : 3.189845085144043
Eval_MaxReturn : 958.0054931640625
Eval_MinReturn : 949.4158935546875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.1478881835938
Train_StdReturn : 0.0
Train_MaxReturn : 948.1478881835938
Train_MinReturn : 948.1478881835938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 127000
TimeSinceStart : 1145.0152297019958
Training Loss : 0.0006327358423732221
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 128 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.0152587890625
Eval_StdReturn : 8.214375495910645
Eval_MaxReturn : 958.0938720703125
Eval_MinReturn : 936.6655883789062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.381591796875
Train_StdReturn : 0.0
Train_MaxReturn : 933.381591796875
Train_MinReturn : 933.381591796875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 128000
TimeSinceStart : 1155.0187640190125
Training Loss : 6.140097684692591e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 129 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.6842041015625
Eval_StdReturn : 11.755585670471191
Eval_MaxReturn : 966.7099609375
Eval_MinReturn : 936.4192504882812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.377685546875
Train_StdReturn : 0.0
Train_MaxReturn : 953.377685546875
Train_MinReturn : 953.377685546875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 129000
TimeSinceStart : 1164.930372953415
Training Loss : 0.00023447597050108016
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 130 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.2906494140625
Eval_StdReturn : 11.08068561553955
Eval_MaxReturn : 959.0816040039062
Eval_MinReturn : 926.87744140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.3043212890625
Train_StdReturn : 0.0
Train_MaxReturn : 943.3043212890625
Train_MinReturn : 943.3043212890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 130000
TimeSinceStart : 1174.8284673690796
Training Loss : 0.0002557128027547151
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 131 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.6844482421875
Eval_StdReturn : 5.3786211013793945
Eval_MaxReturn : 954.0827026367188
Eval_MinReturn : 937.105712890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.0194702148438
Train_StdReturn : 0.0
Train_MaxReturn : 952.0194702148438
Train_MinReturn : 952.0194702148438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 131000
TimeSinceStart : 1184.6564106941223
Training Loss : 0.0004997948417440057
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 132 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.0822143554688
Eval_StdReturn : 10.786881446838379
Eval_MaxReturn : 956.6031494140625
Eval_MinReturn : 924.9751586914062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.8443603515625
Train_StdReturn : 0.0
Train_MaxReturn : 944.8443603515625
Train_MinReturn : 944.8443603515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 132000
TimeSinceStart : 1194.654667377472
Training Loss : 0.0001910766732180491
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 133 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 952.7063598632812
Eval_StdReturn : 6.736414909362793
Eval_MaxReturn : 961.3550415039062
Eval_MinReturn : 942.6063842773438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.7484741210938
Train_StdReturn : 0.0
Train_MaxReturn : 943.7484741210938
Train_MinReturn : 943.7484741210938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 133000
TimeSinceStart : 1204.4421336650848
Training Loss : 0.0002501866838429123
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 134 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.4635620117188
Eval_StdReturn : 9.257375717163086
Eval_MaxReturn : 962.5830078125
Eval_MinReturn : 937.718505859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.02685546875
Train_StdReturn : 0.0
Train_MaxReturn : 948.02685546875
Train_MinReturn : 948.02685546875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 134000
TimeSinceStart : 1214.3398957252502
Training Loss : 0.0002203961048508063
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 135 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.998046875
Eval_StdReturn : 6.0887556076049805
Eval_MaxReturn : 948.3310546875
Eval_MinReturn : 932.214599609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.286376953125
Train_StdReturn : 0.0
Train_MaxReturn : 952.286376953125
Train_MinReturn : 952.286376953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 135000
TimeSinceStart : 1224.4108097553253
Training Loss : 0.0004633529460988939
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 136 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.5344848632812
Eval_StdReturn : 13.564485549926758
Eval_MaxReturn : 962.4275512695312
Eval_MinReturn : 932.7504272460938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.4224853515625
Train_StdReturn : 0.0
Train_MaxReturn : 948.4224853515625
Train_MinReturn : 948.4224853515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 136000
TimeSinceStart : 1234.49946475029
Training Loss : 0.0007615086506120861
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 137 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.2664794921875
Eval_StdReturn : 12.336526870727539
Eval_MaxReturn : 963.3611450195312
Eval_MinReturn : 927.9638671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.9299926757812
Train_StdReturn : 0.0
Train_MaxReturn : 936.9299926757812
Train_MinReturn : 936.9299926757812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 137000
TimeSinceStart : 1244.6527755260468
Training Loss : 8.060445543378592e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 138 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.740234375
Eval_StdReturn : 12.805429458618164
Eval_MaxReturn : 956.2299194335938
Eval_MinReturn : 920.11328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 924.7852172851562
Train_StdReturn : 0.0
Train_MaxReturn : 924.7852172851562
Train_MinReturn : 924.7852172851562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 138000
TimeSinceStart : 1254.9026300907135
Training Loss : 0.0002837986685335636
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 139 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.9508056640625
Eval_StdReturn : 10.665130615234375
Eval_MaxReturn : 961.7049560546875
Eval_MinReturn : 931.2921752929688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.5504760742188
Train_StdReturn : 0.0
Train_MaxReturn : 946.5504760742188
Train_MinReturn : 946.5504760742188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 139000
TimeSinceStart : 1264.5273990631104
Training Loss : 0.00018349119636695832
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 140 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.9812622070312
Eval_StdReturn : 9.543060302734375
Eval_MaxReturn : 954.996337890625
Eval_MinReturn : 933.2593383789062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 923.142578125
Train_StdReturn : 0.0
Train_MaxReturn : 923.142578125
Train_MinReturn : 923.142578125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 140000
TimeSinceStart : 1274.390645980835
Training Loss : 0.00048207686631940305
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 141 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 934.3587036132812
Eval_StdReturn : 9.277835845947266
Eval_MaxReturn : 949.0989379882812
Eval_MinReturn : 921.5588989257812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.9472045898438
Train_StdReturn : 0.0
Train_MaxReturn : 953.9472045898438
Train_MinReturn : 953.9472045898438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 141000
TimeSinceStart : 1284.3513016700745
Training Loss : 0.00033248058753088117
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 142 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.8487548828125
Eval_StdReturn : 10.119758605957031
Eval_MaxReturn : 964.94970703125
Eval_MinReturn : 935.097412109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.7344970703125
Train_StdReturn : 0.0
Train_MaxReturn : 950.7344970703125
Train_MinReturn : 950.7344970703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 142000
TimeSinceStart : 1294.5216736793518
Training Loss : 0.0002851242898032069
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 143 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.4366455078125
Eval_StdReturn : 10.368782997131348
Eval_MaxReturn : 956.603515625
Eval_MinReturn : 926.4903564453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.3199462890625
Train_StdReturn : 0.0
Train_MaxReturn : 955.3199462890625
Train_MinReturn : 955.3199462890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 143000
TimeSinceStart : 1304.7343533039093
Training Loss : 9.837711695581675e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 144 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.6605224609375
Eval_StdReturn : 13.665325164794922
Eval_MaxReturn : 971.1085205078125
Eval_MinReturn : 933.9139404296875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 962.327880859375
Train_StdReturn : 0.0
Train_MaxReturn : 962.327880859375
Train_MinReturn : 962.327880859375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 144000
TimeSinceStart : 1315.001920223236
Training Loss : 0.00027089673676528037
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 145 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 932.5309448242188
Eval_StdReturn : 9.299756050109863
Eval_MaxReturn : 946.57861328125
Eval_MinReturn : 921.7405395507812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.4280395507812
Train_StdReturn : 0.0
Train_MaxReturn : 949.4280395507812
Train_MinReturn : 949.4280395507812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 145000
TimeSinceStart : 1325.3475978374481
Training Loss : 0.00014360752538777888
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 146 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.8766479492188
Eval_StdReturn : 14.061454772949219
Eval_MaxReturn : 967.8604736328125
Eval_MinReturn : 925.283203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 927.6629028320312
Train_StdReturn : 0.0
Train_MaxReturn : 927.6629028320312
Train_MinReturn : 927.6629028320312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 146000
TimeSinceStart : 1335.374115228653
Training Loss : 0.0002461046969983727
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 147 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.8154296875
Eval_StdReturn : 5.880417823791504
Eval_MaxReturn : 956.98779296875
Eval_MinReturn : 940.7357788085938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.5586547851562
Train_StdReturn : 0.0
Train_MaxReturn : 940.5586547851562
Train_MinReturn : 940.5586547851562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 147000
TimeSinceStart : 1345.64377784729
Training Loss : 0.00029197067487984896
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 148 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.7135620117188
Eval_StdReturn : 13.22702407836914
Eval_MaxReturn : 959.4266357421875
Eval_MinReturn : 919.989990234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.04248046875
Train_StdReturn : 0.0
Train_MaxReturn : 941.04248046875
Train_MinReturn : 941.04248046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 148000
TimeSinceStart : 1356.21165060997
Training Loss : 0.0005117841647006571
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 149 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 953.0045166015625
Eval_StdReturn : 8.725234985351562
Eval_MaxReturn : 964.758056640625
Eval_MinReturn : 938.9869384765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 928.14404296875
Train_StdReturn : 0.0
Train_MaxReturn : 928.14404296875
Train_MinReturn : 928.14404296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 149000
TimeSinceStart : 1366.6708943843842
Training Loss : 6.319083331618458e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 150 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.2018432617188
Eval_StdReturn : 5.386128902435303
Eval_MaxReturn : 945.643310546875
Eval_MinReturn : 930.973876953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.2041015625
Train_StdReturn : 0.0
Train_MaxReturn : 958.2041015625
Train_MinReturn : 958.2041015625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 150000
TimeSinceStart : 1377.0224313735962
Training Loss : 3.9643193304073066e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 151 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.9459838867188
Eval_StdReturn : 8.772951126098633
Eval_MaxReturn : 953.325927734375
Eval_MinReturn : 928.17041015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 930.207275390625
Train_StdReturn : 0.0
Train_MaxReturn : 930.207275390625
Train_MinReturn : 930.207275390625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 151000
TimeSinceStart : 1387.6304111480713
Training Loss : 0.000126373372040689
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 152 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.4231567382812
Eval_StdReturn : 6.809007167816162
Eval_MaxReturn : 961.4764404296875
Eval_MinReturn : 940.473388671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.3995361328125
Train_StdReturn : 0.0
Train_MaxReturn : 948.3995361328125
Train_MinReturn : 948.3995361328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 152000
TimeSinceStart : 1397.7628283500671
Training Loss : 0.00025303717120550573
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 153 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 953.6316528320312
Eval_StdReturn : 3.8986544609069824
Eval_MaxReturn : 958.2904052734375
Eval_MinReturn : 946.9050903320312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.0912475585938
Train_StdReturn : 0.0
Train_MaxReturn : 946.0912475585938
Train_MinReturn : 946.0912475585938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 153000
TimeSinceStart : 1408.0325438976288
Training Loss : 0.00027985035558231175
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 154 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 932.87451171875
Eval_StdReturn : 8.557038307189941
Eval_MaxReturn : 949.4005126953125
Eval_MinReturn : 925.19091796875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.4537963867188
Train_StdReturn : 0.0
Train_MaxReturn : 953.4537963867188
Train_MinReturn : 953.4537963867188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 154000
TimeSinceStart : 1418.4575598239899
Training Loss : 0.00037558242911472917
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 155 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.5515747070312
Eval_StdReturn : 8.88171100616455
Eval_MaxReturn : 959.2137451171875
Eval_MinReturn : 934.0567626953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.447509765625
Train_StdReturn : 0.0
Train_MaxReturn : 940.447509765625
Train_MinReturn : 940.447509765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 155000
TimeSinceStart : 1428.9582734107971
Training Loss : 0.0002833080943673849
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 156 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.9703369140625
Eval_StdReturn : 11.060480117797852
Eval_MaxReturn : 972.2915649414062
Eval_MinReturn : 941.6307373046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 922.53125
Train_StdReturn : 0.0
Train_MaxReturn : 922.53125
Train_MinReturn : 922.53125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 156000
TimeSinceStart : 1439.3673055171967
Training Loss : 8.907738811103627e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 157 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 953.9246215820312
Eval_StdReturn : 5.850293159484863
Eval_MaxReturn : 962.3316650390625
Eval_MinReturn : 946.0875244140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.794677734375
Train_StdReturn : 0.0
Train_MaxReturn : 950.794677734375
Train_MinReturn : 950.794677734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 157000
TimeSinceStart : 1449.4442358016968
Training Loss : 0.0009479023283347487
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 158 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.3323364257812
Eval_StdReturn : 15.179393768310547
Eval_MaxReturn : 972.3554077148438
Eval_MinReturn : 925.0205078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 969.25146484375
Train_StdReturn : 0.0
Train_MaxReturn : 969.25146484375
Train_MinReturn : 969.25146484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 158000
TimeSinceStart : 1460.1904599666595
Training Loss : 4.642074782168493e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 159 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.4150390625
Eval_StdReturn : 4.083666801452637
Eval_MaxReturn : 948.7681274414062
Eval_MinReturn : 936.21533203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.9833984375
Train_StdReturn : 0.0
Train_MaxReturn : 938.9833984375
Train_MinReturn : 938.9833984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 159000
TimeSinceStart : 1470.6373364925385
Training Loss : 0.00042686605593189597
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 160 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 933.4605712890625
Eval_StdReturn : 7.867021083831787
Eval_MaxReturn : 941.7308349609375
Eval_MinReturn : 922.3704833984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.3496704101562
Train_StdReturn : 0.0
Train_MaxReturn : 953.3496704101562
Train_MinReturn : 953.3496704101562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 160000
TimeSinceStart : 1480.6979990005493
Training Loss : 0.00013552349992096424
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 161 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 955.4747314453125
Eval_StdReturn : 2.5795722007751465
Eval_MaxReturn : 958.5084228515625
Eval_MinReturn : 952.404052734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.7806396484375
Train_StdReturn : 0.0
Train_MaxReturn : 940.7806396484375
Train_MinReturn : 940.7806396484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 161000
TimeSinceStart : 1491.1318247318268
Training Loss : 0.0002587854105513543
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 162 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.8050537109375
Eval_StdReturn : 13.875716209411621
Eval_MaxReturn : 963.8169555664062
Eval_MinReturn : 929.6451416015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.1065673828125
Train_StdReturn : 0.0
Train_MaxReturn : 936.1065673828125
Train_MinReturn : 936.1065673828125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 162000
TimeSinceStart : 1501.810849905014
Training Loss : 0.000523201422765851
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 163 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.36376953125
Eval_StdReturn : 13.226875305175781
Eval_MaxReturn : 962.00244140625
Eval_MinReturn : 925.374755859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.5853881835938
Train_StdReturn : 0.0
Train_MaxReturn : 933.5853881835938
Train_MinReturn : 933.5853881835938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 163000
TimeSinceStart : 1512.5661027431488
Training Loss : 0.00047472765436396003
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 164 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 935.2571411132812
Eval_StdReturn : 7.760020732879639
Eval_MaxReturn : 943.2658081054688
Eval_MinReturn : 920.4913330078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 961.1263427734375
Train_StdReturn : 0.0
Train_MaxReturn : 961.1263427734375
Train_MinReturn : 961.1263427734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 164000
TimeSinceStart : 1523.2031652927399
Training Loss : 0.0003637094050645828
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 165 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 930.3404541015625
Eval_StdReturn : 5.79024600982666
Eval_MaxReturn : 938.9139404296875
Eval_MinReturn : 923.2767333984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.01611328125
Train_StdReturn : 0.0
Train_MaxReturn : 936.01611328125
Train_MinReturn : 936.01611328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 165000
TimeSinceStart : 1533.9138615131378
Training Loss : 0.0003587209212128073
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 166 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.84619140625
Eval_StdReturn : 11.588693618774414
Eval_MaxReturn : 954.1416015625
Eval_MinReturn : 923.44384765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.7724609375
Train_StdReturn : 0.0
Train_MaxReturn : 946.7724609375
Train_MinReturn : 946.7724609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 166000
TimeSinceStart : 1544.509000301361
Training Loss : 0.00010909692355198786
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 167 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.5010986328125
Eval_StdReturn : 11.640390396118164
Eval_MaxReturn : 956.1328125
Eval_MinReturn : 924.684814453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.218017578125
Train_StdReturn : 0.0
Train_MaxReturn : 945.218017578125
Train_MinReturn : 945.218017578125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 167000
TimeSinceStart : 1555.2681221961975
Training Loss : 0.00033144932240247726
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 168 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.6580810546875
Eval_StdReturn : 4.354775428771973
Eval_MaxReturn : 955.4853515625
Eval_MinReturn : 942.1380615234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.7041015625
Train_StdReturn : 0.0
Train_MaxReturn : 950.7041015625
Train_MinReturn : 950.7041015625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 168000
TimeSinceStart : 1566.1054074764252
Training Loss : 0.0004833709972444922
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 169 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.2361450195312
Eval_StdReturn : 7.838140487670898
Eval_MaxReturn : 957.6268310546875
Eval_MinReturn : 936.011474609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.2747802734375
Train_StdReturn : 0.0
Train_MaxReturn : 956.2747802734375
Train_MinReturn : 956.2747802734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 169000
TimeSinceStart : 1577.5853562355042
Training Loss : 0.00024124450283125043
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 170 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.4768676757812
Eval_StdReturn : 4.067304611206055
Eval_MaxReturn : 954.1834716796875
Eval_MinReturn : 942.4693603515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 931.86328125
Train_StdReturn : 0.0
Train_MaxReturn : 931.86328125
Train_MinReturn : 931.86328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 170000
TimeSinceStart : 1588.1721692085266
Training Loss : 0.00011316360905766487
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 171 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.2371826171875
Eval_StdReturn : 11.503427505493164
Eval_MaxReturn : 955.1881103515625
Eval_MinReturn : 923.660400390625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.80224609375
Train_StdReturn : 0.0
Train_MaxReturn : 933.80224609375
Train_MinReturn : 933.80224609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 171000
TimeSinceStart : 1599.0073807239532
Training Loss : 0.00017203984316438437
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 172 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.0533447265625
Eval_StdReturn : 10.183815002441406
Eval_MaxReturn : 962.3214111328125
Eval_MinReturn : 933.6026611328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.7814331054688
Train_StdReturn : 0.0
Train_MaxReturn : 949.7814331054688
Train_MinReturn : 949.7814331054688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 172000
TimeSinceStart : 1609.77894115448
Training Loss : 0.00018278506468050182
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 173 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.4859619140625
Eval_StdReturn : 8.839567184448242
Eval_MaxReturn : 956.192626953125
Eval_MinReturn : 932.144287109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.677001953125
Train_StdReturn : 0.0
Train_MaxReturn : 939.677001953125
Train_MinReturn : 939.677001953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 173000
TimeSinceStart : 1620.7273831367493
Training Loss : 0.0002092145150527358
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 174 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.3157958984375
Eval_StdReturn : 9.417718887329102
Eval_MaxReturn : 953.8749389648438
Eval_MinReturn : 932.820068359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 968.5525512695312
Train_StdReturn : 0.0
Train_MaxReturn : 968.5525512695312
Train_MinReturn : 968.5525512695312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 174000
TimeSinceStart : 1631.555317401886
Training Loss : 0.00028494131402112544
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 175 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.1276245117188
Eval_StdReturn : 11.969085693359375
Eval_MaxReturn : 957.6002807617188
Eval_MinReturn : 926.2198486328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.57275390625
Train_StdReturn : 0.0
Train_MaxReturn : 934.57275390625
Train_MinReturn : 934.57275390625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 175000
TimeSinceStart : 1642.2172009944916
Training Loss : 0.000213633815292269
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 176 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.7257080078125
Eval_StdReturn : 11.217836380004883
Eval_MaxReturn : 965.9046630859375
Eval_MinReturn : 933.5653076171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.0285034179688
Train_StdReturn : 0.0
Train_MaxReturn : 956.0285034179688
Train_MinReturn : 956.0285034179688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 176000
TimeSinceStart : 1653.0662248134613
Training Loss : 0.0006082638283260167
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 177 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.8297729492188
Eval_StdReturn : 18.861431121826172
Eval_MaxReturn : 954.210693359375
Eval_MinReturn : 907.058837890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.0496826171875
Train_StdReturn : 0.0
Train_MaxReturn : 953.0496826171875
Train_MinReturn : 953.0496826171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 177000
TimeSinceStart : 1663.8708384037018
Training Loss : 0.0004832693957723677
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 178 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.4568481445312
Eval_StdReturn : 8.871423721313477
Eval_MaxReturn : 953.435791015625
Eval_MinReturn : 926.5184326171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.2538452148438
Train_StdReturn : 0.0
Train_MaxReturn : 936.2538452148438
Train_MinReturn : 936.2538452148438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 178000
TimeSinceStart : 1673.9758806228638
Training Loss : 0.00010625341383274645
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 179 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.9895629882812
Eval_StdReturn : 11.872730255126953
Eval_MaxReturn : 955.8643798828125
Eval_MinReturn : 924.8515014648438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.4497680664062
Train_StdReturn : 0.0
Train_MaxReturn : 946.4497680664062
Train_MinReturn : 946.4497680664062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 179000
TimeSinceStart : 1684.2321186065674
Training Loss : 0.00022156554041430354
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 180 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.0794677734375
Eval_StdReturn : 11.675908088684082
Eval_MaxReturn : 968.9425048828125
Eval_MinReturn : 936.9171142578125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.7708740234375
Train_StdReturn : 0.0
Train_MaxReturn : 938.7708740234375
Train_MinReturn : 938.7708740234375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 180000
TimeSinceStart : 1695.396295785904
Training Loss : 0.0002645447675604373
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 181 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.2191162109375
Eval_StdReturn : 8.016626358032227
Eval_MaxReturn : 950.4777221679688
Eval_MinReturn : 928.0259399414062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.7421875
Train_StdReturn : 0.0
Train_MaxReturn : 936.7421875
Train_MinReturn : 936.7421875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 181000
TimeSinceStart : 1706.4836113452911
Training Loss : 6.363652209984139e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 182 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.2548828125
Eval_StdReturn : 10.52552604675293
Eval_MaxReturn : 967.4876708984375
Eval_MinReturn : 936.201904296875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.1434326171875
Train_StdReturn : 0.0
Train_MaxReturn : 941.1434326171875
Train_MinReturn : 941.1434326171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 182000
TimeSinceStart : 1717.5514042377472
Training Loss : 0.00019263669673819095
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 183 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 933.5054931640625
Eval_StdReturn : 9.66459846496582
Eval_MaxReturn : 944.8671875
Eval_MinReturn : 918.5323486328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.8848876953125
Train_StdReturn : 0.0
Train_MaxReturn : 942.8848876953125
Train_MinReturn : 942.8848876953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 183000
TimeSinceStart : 1727.79345703125
Training Loss : 0.0003274285700172186
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 184 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.3834838867188
Eval_StdReturn : 7.067716598510742
Eval_MaxReturn : 945.2084350585938
Eval_MinReturn : 925.8778076171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 926.7755126953125
Train_StdReturn : 0.0
Train_MaxReturn : 926.7755126953125
Train_MinReturn : 926.7755126953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 184000
TimeSinceStart : 1738.0319645404816
Training Loss : 0.0002658526645973325
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 185 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.9931640625
Eval_StdReturn : 10.720925331115723
Eval_MaxReturn : 955.775390625
Eval_MinReturn : 923.2844848632812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.85791015625
Train_StdReturn : 0.0
Train_MaxReturn : 936.85791015625
Train_MinReturn : 936.85791015625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 185000
TimeSinceStart : 1748.5370364189148
Training Loss : 0.00025487496168352664
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 186 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 922.9276123046875
Eval_StdReturn : 15.979759216308594
Eval_MaxReturn : 951.1431884765625
Eval_MinReturn : 905.90283203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.8958129882812
Train_StdReturn : 0.0
Train_MaxReturn : 936.8958129882812
Train_MinReturn : 936.8958129882812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 186000
TimeSinceStart : 1759.5258045196533
Training Loss : 0.0008705530199222267
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 187 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 956.18994140625
Eval_StdReturn : 7.843389511108398
Eval_MaxReturn : 969.0482177734375
Eval_MinReturn : 947.9385986328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.2490234375
Train_StdReturn : 0.0
Train_MaxReturn : 934.2490234375
Train_MinReturn : 934.2490234375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 187000
TimeSinceStart : 1770.5132443904877
Training Loss : 0.00032127363374456763
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 188 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.0413208007812
Eval_StdReturn : 8.931352615356445
Eval_MaxReturn : 956.2286376953125
Eval_MinReturn : 932.1802978515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 927.619140625
Train_StdReturn : 0.0
Train_MaxReturn : 927.619140625
Train_MinReturn : 927.619140625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 188000
TimeSinceStart : 1781.5940833091736
Training Loss : 0.00028662942349910736
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 189 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.4581909179688
Eval_StdReturn : 16.730775833129883
Eval_MaxReturn : 967.5054931640625
Eval_MinReturn : 925.7869262695312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.1781005859375
Train_StdReturn : 0.0
Train_MaxReturn : 955.1781005859375
Train_MinReturn : 955.1781005859375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 189000
TimeSinceStart : 1792.8023943901062
Training Loss : 4.49534782092087e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 190 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.6434326171875
Eval_StdReturn : 8.278458595275879
Eval_MaxReturn : 957.6080322265625
Eval_MinReturn : 934.1127319335938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 931.1541748046875
Train_StdReturn : 0.0
Train_MaxReturn : 931.1541748046875
Train_MinReturn : 931.1541748046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 190000
TimeSinceStart : 1803.975004196167
Training Loss : 4.699136843555607e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 191 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.86767578125
Eval_StdReturn : 11.160168647766113
Eval_MaxReturn : 956.2281494140625
Eval_MinReturn : 927.884765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.3732299804688
Train_StdReturn : 0.0
Train_MaxReturn : 952.3732299804688
Train_MinReturn : 952.3732299804688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 191000
TimeSinceStart : 1815.3271327018738
Training Loss : 4.0971161070046946e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 192 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.2195434570312
Eval_StdReturn : 8.010517120361328
Eval_MaxReturn : 954.25146484375
Eval_MinReturn : 930.3338623046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.6326904296875
Train_StdReturn : 0.0
Train_MaxReturn : 958.6326904296875
Train_MinReturn : 958.6326904296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 192000
TimeSinceStart : 1826.6846196651459
Training Loss : 0.0003446699120104313
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 193 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.9248046875
Eval_StdReturn : 11.730794906616211
Eval_MaxReturn : 956.6322021484375
Eval_MinReturn : 922.3982543945312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.8419189453125
Train_StdReturn : 0.0
Train_MaxReturn : 943.8419189453125
Train_MinReturn : 943.8419189453125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 193000
TimeSinceStart : 1837.782547712326
Training Loss : 0.0004245997406542301
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 194 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.8468017578125
Eval_StdReturn : 8.270548820495605
Eval_MaxReturn : 951.219482421875
Eval_MinReturn : 925.1392822265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.3939819335938
Train_StdReturn : 0.0
Train_MaxReturn : 949.3939819335938
Train_MinReturn : 949.3939819335938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 194000
TimeSinceStart : 1849.1353685855865
Training Loss : 0.00015051456284709275
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 195 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.5513916015625
Eval_StdReturn : 9.099237442016602
Eval_MaxReturn : 954.6067504882812
Eval_MinReturn : 925.8785400390625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.2679443359375
Train_StdReturn : 0.0
Train_MaxReturn : 956.2679443359375
Train_MinReturn : 956.2679443359375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 195000
TimeSinceStart : 1860.2798562049866
Training Loss : 0.00018172056297771633
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 196 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.7263793945312
Eval_StdReturn : 13.758280754089355
Eval_MaxReturn : 960.6553344726562
Eval_MinReturn : 923.425048828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 932.8173217773438
Train_StdReturn : 0.0
Train_MaxReturn : 932.8173217773438
Train_MinReturn : 932.8173217773438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 196000
TimeSinceStart : 1871.5297122001648
Training Loss : 0.0001310291700065136
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 197 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 934.1422119140625
Eval_StdReturn : 12.577118873596191
Eval_MaxReturn : 953.499755859375
Eval_MinReturn : 916.8348999023438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.68701171875
Train_StdReturn : 0.0
Train_MaxReturn : 950.68701171875
Train_MinReturn : 950.68701171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 197000
TimeSinceStart : 1882.7073864936829
Training Loss : 5.3229541663313285e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 198 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.4313354492188
Eval_StdReturn : 7.117129802703857
Eval_MaxReturn : 952.14306640625
Eval_MinReturn : 932.2880249023438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.837890625
Train_StdReturn : 0.0
Train_MaxReturn : 935.837890625
Train_MinReturn : 935.837890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 198000
TimeSinceStart : 1893.6048002243042
Training Loss : 0.00028627950814552605
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 199 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 932.6531372070312
Eval_StdReturn : 16.811166763305664
Eval_MaxReturn : 963.1424560546875
Eval_MinReturn : 912.7193603515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 929.9795532226562
Train_StdReturn : 0.0
Train_MaxReturn : 929.9795532226562
Train_MinReturn : 929.9795532226562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 199000
TimeSinceStart : 1904.8261847496033
Training Loss : 0.000537172076292336
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 200 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 954.5504760742188
Eval_StdReturn : 9.830910682678223
Eval_MaxReturn : 967.594970703125
Eval_MinReturn : 945.281494140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 962.984375
Train_StdReturn : 0.0
Train_MaxReturn : 962.984375
Train_MinReturn : 962.984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 200000
TimeSinceStart : 1916.4369966983795
Training Loss : 0.00027081029838882387
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 201 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.3718872070312
Eval_StdReturn : 7.52915620803833
Eval_MaxReturn : 949.7386474609375
Eval_MinReturn : 932.1610107421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 967.9959106445312
Train_StdReturn : 0.0
Train_MaxReturn : 967.9959106445312
Train_MinReturn : 967.9959106445312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 201000
TimeSinceStart : 1927.7979547977448
Training Loss : 0.00011550615454325452
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 202 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.8966064453125
Eval_StdReturn : 6.392037391662598
Eval_MaxReturn : 953.6778564453125
Eval_MinReturn : 935.490478515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.31787109375
Train_StdReturn : 0.0
Train_MaxReturn : 944.31787109375
Train_MinReturn : 944.31787109375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 202000
TimeSinceStart : 1939.045414686203
Training Loss : 0.00023780095216352493
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 203 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.29638671875
Eval_StdReturn : 11.187273979187012
Eval_MaxReturn : 967.9579467773438
Eval_MinReturn : 933.814208984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 960.8756103515625
Train_StdReturn : 0.0
Train_MaxReturn : 960.8756103515625
Train_MinReturn : 960.8756103515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 203000
TimeSinceStart : 1950.3391337394714
Training Loss : 0.0011716976296156645
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 204 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.5494995117188
Eval_StdReturn : 8.970064163208008
Eval_MaxReturn : 957.431884765625
Eval_MinReturn : 931.4005126953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.24560546875
Train_StdReturn : 0.0
Train_MaxReturn : 942.24560546875
Train_MinReturn : 942.24560546875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 204000
TimeSinceStart : 1961.6193039417267
Training Loss : 0.0003204647800885141
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 205 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.5529174804688
Eval_StdReturn : 7.617293357849121
Eval_MaxReturn : 957.6302490234375
Eval_MinReturn : 936.645751953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.8837890625
Train_StdReturn : 0.0
Train_MaxReturn : 956.8837890625
Train_MinReturn : 956.8837890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 205000
TimeSinceStart : 1973.0042324066162
Training Loss : 0.0005788654671050608
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 206 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.6749267578125
Eval_StdReturn : 5.655167579650879
Eval_MaxReturn : 955.9924926757812
Eval_MinReturn : 940.758056640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.8720703125
Train_StdReturn : 0.0
Train_MaxReturn : 943.8720703125
Train_MinReturn : 943.8720703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 206000
TimeSinceStart : 1984.5070798397064
Training Loss : 0.00019269256154075265
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 207 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 933.34423828125
Eval_StdReturn : 8.386143684387207
Eval_MaxReturn : 943.4430541992188
Eval_MinReturn : 918.48095703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.423095703125
Train_StdReturn : 0.0
Train_MaxReturn : 949.423095703125
Train_MinReturn : 949.423095703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 207000
TimeSinceStart : 1996.0714275836945
Training Loss : 0.0004857172607444227
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 208 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.1813354492188
Eval_StdReturn : 8.249842643737793
Eval_MaxReturn : 952.5107421875
Eval_MinReturn : 933.0967407226562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 923.0460205078125
Train_StdReturn : 0.0
Train_MaxReturn : 923.0460205078125
Train_MinReturn : 923.0460205078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 208000
TimeSinceStart : 2007.7480909824371
Training Loss : 0.00031854596454650164
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 209 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 932.8922119140625
Eval_StdReturn : 7.74307918548584
Eval_MaxReturn : 942.1668701171875
Eval_MinReturn : 922.9969482421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.248779296875
Train_StdReturn : 0.0
Train_MaxReturn : 937.248779296875
Train_MinReturn : 937.248779296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 209000
TimeSinceStart : 2019.0034153461456
Training Loss : 0.00031007471261546016
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 210 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 956.2716674804688
Eval_StdReturn : 8.052912712097168
Eval_MaxReturn : 961.751708984375
Eval_MinReturn : 940.3043212890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.1904296875
Train_StdReturn : 0.0
Train_MaxReturn : 935.1904296875
Train_MinReturn : 935.1904296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 210000
TimeSinceStart : 2030.6254930496216
Training Loss : 0.0002953310322482139
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 211 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.3933715820312
Eval_StdReturn : 6.194983005523682
Eval_MaxReturn : 955.0330810546875
Eval_MinReturn : 938.4110717773438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 932.83203125
Train_StdReturn : 0.0
Train_MaxReturn : 932.83203125
Train_MinReturn : 932.83203125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 211000
TimeSinceStart : 2042.1811137199402
Training Loss : 0.00010648227907950059
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 212 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.8971557617188
Eval_StdReturn : 4.638124942779541
Eval_MaxReturn : 943.50634765625
Eval_MinReturn : 931.1100463867188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.8160400390625
Train_StdReturn : 0.0
Train_MaxReturn : 949.8160400390625
Train_MinReturn : 949.8160400390625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 212000
TimeSinceStart : 2053.1112287044525
Training Loss : 0.00017473458137828857
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 213 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.33984375
Eval_StdReturn : 10.682040214538574
Eval_MaxReturn : 963.9620361328125
Eval_MinReturn : 937.1395263671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.822509765625
Train_StdReturn : 0.0
Train_MaxReturn : 941.822509765625
Train_MinReturn : 941.822509765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 213000
TimeSinceStart : 2064.4409437179565
Training Loss : 0.001005840953439474
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 214 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.2693481445312
Eval_StdReturn : 7.081640243530273
Eval_MaxReturn : 963.19970703125
Eval_MinReturn : 942.588623046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.626708984375
Train_StdReturn : 0.0
Train_MaxReturn : 939.626708984375
Train_MinReturn : 939.626708984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 214000
TimeSinceStart : 2075.967622756958
Training Loss : 0.00029451571754179895
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 215 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.04345703125
Eval_StdReturn : 11.27538013458252
Eval_MaxReturn : 958.3743286132812
Eval_MinReturn : 925.87255859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.7926025390625
Train_StdReturn : 0.0
Train_MaxReturn : 942.7926025390625
Train_MinReturn : 942.7926025390625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 215000
TimeSinceStart : 2087.4507825374603
Training Loss : 5.914728171774186e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 216 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.4972534179688
Eval_StdReturn : 6.718715190887451
Eval_MaxReturn : 951.536376953125
Eval_MinReturn : 931.794189453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.1500244140625
Train_StdReturn : 0.0
Train_MaxReturn : 944.1500244140625
Train_MinReturn : 944.1500244140625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 216000
TimeSinceStart : 2099.3737614154816
Training Loss : 0.00010321203444618732
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 217 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.2844848632812
Eval_StdReturn : 9.758041381835938
Eval_MaxReturn : 962.9302368164062
Eval_MinReturn : 932.4495849609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.8607177734375
Train_StdReturn : 0.0
Train_MaxReturn : 953.8607177734375
Train_MinReturn : 953.8607177734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 217000
TimeSinceStart : 2111.2558772563934
Training Loss : 0.0002992072550114244
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 218 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.6754150390625
Eval_StdReturn : 6.985698223114014
Eval_MaxReturn : 959.916259765625
Eval_MinReturn : 940.57470703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.0028076171875
Train_StdReturn : 0.0
Train_MaxReturn : 933.0028076171875
Train_MinReturn : 933.0028076171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 218000
TimeSinceStart : 2122.414348602295
Training Loss : 0.0004972892347723246
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 219 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.4884643554688
Eval_StdReturn : 6.1723713874816895
Eval_MaxReturn : 958.60595703125
Eval_MinReturn : 941.3350830078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.761962890625
Train_StdReturn : 0.0
Train_MaxReturn : 954.761962890625
Train_MinReturn : 954.761962890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 219000
TimeSinceStart : 2133.5666086673737
Training Loss : 0.0013508581323549151
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 220 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.41357421875
Eval_StdReturn : 14.288444519042969
Eval_MaxReturn : 958.872314453125
Eval_MinReturn : 919.7027587890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 966.8712158203125
Train_StdReturn : 0.0
Train_MaxReturn : 966.8712158203125
Train_MinReturn : 966.8712158203125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 220000
TimeSinceStart : 2144.309265613556
Training Loss : 0.00030265640816651285
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 221 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.0031127929688
Eval_StdReturn : 4.465349197387695
Eval_MaxReturn : 947.4652099609375
Eval_MinReturn : 936.7846069335938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 928.1339111328125
Train_StdReturn : 0.0
Train_MaxReturn : 928.1339111328125
Train_MinReturn : 928.1339111328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 221000
TimeSinceStart : 2155.226254224777
Training Loss : 0.00015090155648067594
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 222 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.5806884765625
Eval_StdReturn : 9.26142406463623
Eval_MaxReturn : 961.0462646484375
Eval_MinReturn : 934.2532348632812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.1423950195312
Train_StdReturn : 0.0
Train_MaxReturn : 958.1423950195312
Train_MinReturn : 958.1423950195312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 222000
TimeSinceStart : 2166.803992986679
Training Loss : 0.0005408315919339657
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 223 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.3616943359375
Eval_StdReturn : 5.900317668914795
Eval_MaxReturn : 952.2113037109375
Eval_MinReturn : 934.3696899414062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 922.6116943359375
Train_StdReturn : 0.0
Train_MaxReturn : 922.6116943359375
Train_MinReturn : 922.6116943359375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 223000
TimeSinceStart : 2178.4742982387543
Training Loss : 0.0005326360114850104
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 224 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.9803466796875
Eval_StdReturn : 6.5503082275390625
Eval_MaxReturn : 953.306884765625
Eval_MinReturn : 937.6972045898438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.93115234375
Train_StdReturn : 0.0
Train_MaxReturn : 951.93115234375
Train_MinReturn : 951.93115234375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 224000
TimeSinceStart : 2190.125365972519
Training Loss : 0.0002195917331846431
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 225 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.0379028320312
Eval_StdReturn : 6.475398063659668
Eval_MaxReturn : 960.140869140625
Eval_MinReturn : 941.0950317382812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.8756103515625
Train_StdReturn : 0.0
Train_MaxReturn : 945.8756103515625
Train_MinReturn : 945.8756103515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 225000
TimeSinceStart : 2201.668247461319
Training Loss : 0.0008244028431363404
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 226 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.6204833984375
Eval_StdReturn : 11.062684059143066
Eval_MaxReturn : 960.0394897460938
Eval_MinReturn : 931.2117919921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.30712890625
Train_StdReturn : 0.0
Train_MaxReturn : 940.30712890625
Train_MinReturn : 940.30712890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 226000
TimeSinceStart : 2213.299038171768
Training Loss : 0.00029453542083501816
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 227 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.263671875
Eval_StdReturn : 11.803228378295898
Eval_MaxReturn : 956.6262817382812
Eval_MinReturn : 925.7694091796875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.7684326171875
Train_StdReturn : 0.0
Train_MaxReturn : 956.7684326171875
Train_MinReturn : 956.7684326171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 227000
TimeSinceStart : 2224.994768857956
Training Loss : 0.00020788430992979556
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 228 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.07275390625
Eval_StdReturn : 5.477293014526367
Eval_MaxReturn : 950.4241943359375
Eval_MinReturn : 936.5763549804688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.9208374023438
Train_StdReturn : 0.0
Train_MaxReturn : 935.9208374023438
Train_MinReturn : 935.9208374023438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 228000
TimeSinceStart : 2237.036952018738
Training Loss : 6.838816625531763e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 229 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 954.4903564453125
Eval_StdReturn : 9.891382217407227
Eval_MaxReturn : 969.1516723632812
Eval_MinReturn : 939.404541015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 932.86669921875
Train_StdReturn : 0.0
Train_MaxReturn : 932.86669921875
Train_MinReturn : 932.86669921875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 229000
TimeSinceStart : 2248.84543299675
Training Loss : 0.00016643019625917077
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 230 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.1793212890625
Eval_StdReturn : 6.381046295166016
Eval_MaxReturn : 954.5385131835938
Eval_MinReturn : 936.227783203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.1580810546875
Train_StdReturn : 0.0
Train_MaxReturn : 950.1580810546875
Train_MinReturn : 950.1580810546875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 230000
TimeSinceStart : 2260.4414191246033
Training Loss : 6.662571831839159e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 231 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.5925903320312
Eval_StdReturn : 11.101116180419922
Eval_MaxReturn : 966.72119140625
Eval_MinReturn : 932.1922607421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.3214111328125
Train_StdReturn : 0.0
Train_MaxReturn : 940.3214111328125
Train_MinReturn : 940.3214111328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 231000
TimeSinceStart : 2272.113047361374
Training Loss : 5.953505024081096e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 232 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.5773315429688
Eval_StdReturn : 7.9394612312316895
Eval_MaxReturn : 959.35986328125
Eval_MinReturn : 934.5003662109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 966.4234008789062
Train_StdReturn : 0.0
Train_MaxReturn : 966.4234008789062
Train_MinReturn : 966.4234008789062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 232000
TimeSinceStart : 2283.877823114395
Training Loss : 0.00011998811532976106
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 233 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.3218994140625
Eval_StdReturn : 19.021629333496094
Eval_MaxReturn : 975.793701171875
Eval_MinReturn : 925.7073974609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.1495361328125
Train_StdReturn : 0.0
Train_MaxReturn : 958.1495361328125
Train_MinReturn : 958.1495361328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 233000
TimeSinceStart : 2295.6293556690216
Training Loss : 0.00012159408652223647
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 234 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 952.71630859375
Eval_StdReturn : 9.019580841064453
Eval_MaxReturn : 964.009521484375
Eval_MinReturn : 937.77587890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.1367797851562
Train_StdReturn : 0.0
Train_MaxReturn : 951.1367797851562
Train_MinReturn : 951.1367797851562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 234000
TimeSinceStart : 2307.218989133835
Training Loss : 8.668647933518514e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 235 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.3858642578125
Eval_StdReturn : 11.259655952453613
Eval_MaxReturn : 965.7359619140625
Eval_MinReturn : 936.86181640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 967.4697265625
Train_StdReturn : 0.0
Train_MaxReturn : 967.4697265625
Train_MinReturn : 967.4697265625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 235000
TimeSinceStart : 2318.5115501880646
Training Loss : 2.9364153306232765e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 236 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.43017578125
Eval_StdReturn : 9.799522399902344
Eval_MaxReturn : 953.41552734375
Eval_MinReturn : 926.4998779296875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 957.1915283203125
Train_StdReturn : 0.0
Train_MaxReturn : 957.1915283203125
Train_MinReturn : 957.1915283203125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 236000
TimeSinceStart : 2330.332416534424
Training Loss : 8.953228098107502e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 237 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.1337890625
Eval_StdReturn : 7.293399333953857
Eval_MaxReturn : 957.4239501953125
Eval_MinReturn : 936.9486694335938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.6817626953125
Train_StdReturn : 0.0
Train_MaxReturn : 948.6817626953125
Train_MinReturn : 948.6817626953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 237000
TimeSinceStart : 2342.1991353034973
Training Loss : 0.00020274368580430746
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 238 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.3939208984375
Eval_StdReturn : 5.714188575744629
Eval_MaxReturn : 957.42236328125
Eval_MinReturn : 941.5900268554688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.6560668945312
Train_StdReturn : 0.0
Train_MaxReturn : 948.6560668945312
Train_MinReturn : 948.6560668945312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 238000
TimeSinceStart : 2354.0629534721375
Training Loss : 0.0005975809181109071
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 239 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.3016357421875
Eval_StdReturn : 4.988606929779053
Eval_MaxReturn : 945.51416015625
Eval_MinReturn : 932.3789672851562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.6470947265625
Train_StdReturn : 0.0
Train_MaxReturn : 941.6470947265625
Train_MinReturn : 941.6470947265625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 239000
TimeSinceStart : 2366.1410343647003
Training Loss : 0.0003204408858437091
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 240 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 953.4625244140625
Eval_StdReturn : 4.907307147979736
Eval_MaxReturn : 962.1455078125
Eval_MinReturn : 948.27197265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.0900268554688
Train_StdReturn : 0.0
Train_MaxReturn : 947.0900268554688
Train_MinReturn : 947.0900268554688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 240000
TimeSinceStart : 2377.9151442050934
Training Loss : 0.0005036568618379533
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 241 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 935.0418090820312
Eval_StdReturn : 2.7544240951538086
Eval_MaxReturn : 939.2244873046875
Eval_MinReturn : 931.78662109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.1400146484375
Train_StdReturn : 0.0
Train_MaxReturn : 941.1400146484375
Train_MinReturn : 941.1400146484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 241000
TimeSinceStart : 2389.721442222595
Training Loss : 0.00010797807044582441
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 242 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.6561279296875
Eval_StdReturn : 13.046600341796875
Eval_MaxReturn : 960.87109375
Eval_MinReturn : 930.5611572265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 926.2476806640625
Train_StdReturn : 0.0
Train_MaxReturn : 926.2476806640625
Train_MinReturn : 926.2476806640625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 242000
TimeSinceStart : 2401.628273963928
Training Loss : 0.0003411422949284315
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 243 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.9928588867188
Eval_StdReturn : 4.206308364868164
Eval_MaxReturn : 947.4310302734375
Eval_MinReturn : 936.3834838867188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.9389038085938
Train_StdReturn : 0.0
Train_MaxReturn : 936.9389038085938
Train_MinReturn : 936.9389038085938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 243000
TimeSinceStart : 2413.4824385643005
Training Loss : 0.00011936139344470575
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 244 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.8917236328125
Eval_StdReturn : 10.30346965789795
Eval_MaxReturn : 958.5716552734375
Eval_MinReturn : 928.9160766601562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.516845703125
Train_StdReturn : 0.0
Train_MaxReturn : 953.516845703125
Train_MinReturn : 953.516845703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 244000
TimeSinceStart : 2425.3663833141327
Training Loss : 0.00019584443361964077
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 245 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.525390625
Eval_StdReturn : 4.457026958465576
Eval_MaxReturn : 943.455322265625
Eval_MinReturn : 931.5276489257812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.912353515625
Train_StdReturn : 0.0
Train_MaxReturn : 944.912353515625
Train_MinReturn : 944.912353515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 245000
TimeSinceStart : 2437.226878643036
Training Loss : 0.0003346928278915584
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 246 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.6917724609375
Eval_StdReturn : 2.260816812515259
Eval_MaxReturn : 953.0693359375
Eval_MinReturn : 947.5252685546875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 929.8897705078125
Train_StdReturn : 0.0
Train_MaxReturn : 929.8897705078125
Train_MinReturn : 929.8897705078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 246000
TimeSinceStart : 2449.1830818653107
Training Loss : 0.0002150322252418846
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 247 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.7722778320312
Eval_StdReturn : 9.498995780944824
Eval_MaxReturn : 953.9816284179688
Eval_MinReturn : 924.796630859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.0894775390625
Train_StdReturn : 0.0
Train_MaxReturn : 943.0894775390625
Train_MinReturn : 943.0894775390625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 247000
TimeSinceStart : 2461.166359424591
Training Loss : 0.0005033042398281395
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 248 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 952.1260986328125
Eval_StdReturn : 14.112269401550293
Eval_MaxReturn : 980.0588989257812
Eval_MinReturn : 942.5751953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 928.056884765625
Train_StdReturn : 0.0
Train_MaxReturn : 928.056884765625
Train_MinReturn : 928.056884765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 248000
TimeSinceStart : 2473.188648700714
Training Loss : 4.783946496900171e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 249 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.8154296875
Eval_StdReturn : 15.091053009033203
Eval_MaxReturn : 950.8007202148438
Eval_MinReturn : 918.9711303710938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 971.16357421875
Train_StdReturn : 0.0
Train_MaxReturn : 971.16357421875
Train_MinReturn : 971.16357421875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 249000
TimeSinceStart : 2485.0919597148895
Training Loss : 0.0002802703238558024
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 250 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.9036865234375
Eval_StdReturn : 9.130475044250488
Eval_MaxReturn : 953.5809326171875
Eval_MinReturn : 930.80615234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.3426513671875
Train_StdReturn : 0.0
Train_MaxReturn : 952.3426513671875
Train_MinReturn : 952.3426513671875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 250000
TimeSinceStart : 2497.0715317726135
Training Loss : 0.00026456464547663927
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 251 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.4857177734375
Eval_StdReturn : 15.446677207946777
Eval_MaxReturn : 961.246337890625
Eval_MinReturn : 926.4331665039062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.3607177734375
Train_StdReturn : 0.0
Train_MaxReturn : 955.3607177734375
Train_MinReturn : 955.3607177734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 251000
TimeSinceStart : 2509.183687210083
Training Loss : 0.00018814633949659765
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 252 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.3230590820312
Eval_StdReturn : 9.68998908996582
Eval_MaxReturn : 955.9132080078125
Eval_MinReturn : 934.3741455078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.8212280273438
Train_StdReturn : 0.0
Train_MaxReturn : 947.8212280273438
Train_MinReturn : 947.8212280273438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 252000
TimeSinceStart : 2520.8971779346466
Training Loss : 0.0002490474726073444
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 253 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.3113403320312
Eval_StdReturn : 9.323286056518555
Eval_MaxReturn : 963.9981689453125
Eval_MinReturn : 939.3255615234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.1677856445312
Train_StdReturn : 0.0
Train_MaxReturn : 939.1677856445312
Train_MinReturn : 939.1677856445312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 253000
TimeSinceStart : 2533.1736533641815
Training Loss : 0.000391975772799924
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 254 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.00439453125
Eval_StdReturn : 13.495159149169922
Eval_MaxReturn : 962.9765625
Eval_MinReturn : 928.7220458984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.0250244140625
Train_StdReturn : 0.0
Train_MaxReturn : 938.0250244140625
Train_MinReturn : 938.0250244140625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 254000
TimeSinceStart : 2545.670222043991
Training Loss : 0.00045552951632998884
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 255 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.7595825195312
Eval_StdReturn : 14.372389793395996
Eval_MaxReturn : 965.0274047851562
Eval_MinReturn : 923.9329833984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 921.8704833984375
Train_StdReturn : 0.0
Train_MaxReturn : 921.8704833984375
Train_MinReturn : 921.8704833984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 255000
TimeSinceStart : 2557.6282007694244
Training Loss : 0.00040480581810697913
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 256 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 953.0885009765625
Eval_StdReturn : 7.602646350860596
Eval_MaxReturn : 962.5404663085938
Eval_MinReturn : 941.0047607421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 932.3131103515625
Train_StdReturn : 0.0
Train_MaxReturn : 932.3131103515625
Train_MinReturn : 932.3131103515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 256000
TimeSinceStart : 2569.6590094566345
Training Loss : 0.00019803739269264042
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 257 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 953.5882568359375
Eval_StdReturn : 6.127898693084717
Eval_MaxReturn : 959.0147705078125
Eval_MinReturn : 941.7803344726562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.4652709960938
Train_StdReturn : 0.0
Train_MaxReturn : 940.4652709960938
Train_MinReturn : 940.4652709960938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 257000
TimeSinceStart : 2581.9035799503326
Training Loss : 0.00031348905758932233
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 258 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.1734619140625
Eval_StdReturn : 2.7118473052978516
Eval_MaxReturn : 941.27783203125
Eval_MinReturn : 933.8834838867188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 917.0369873046875
Train_StdReturn : 0.0
Train_MaxReturn : 917.0369873046875
Train_MinReturn : 917.0369873046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 258000
TimeSinceStart : 2593.96897315979
Training Loss : 0.0006925087072886527
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 259 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.0572509765625
Eval_StdReturn : 10.573715209960938
Eval_MaxReturn : 963.29248046875
Eval_MinReturn : 931.3408203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.8529663085938
Train_StdReturn : 0.0
Train_MaxReturn : 951.8529663085938
Train_MinReturn : 951.8529663085938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 259000
TimeSinceStart : 2606.0574281215668
Training Loss : 0.00013756378029938787
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 260 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.58984375
Eval_StdReturn : 11.442546844482422
Eval_MaxReturn : 968.7140502929688
Eval_MinReturn : 936.4067993164062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.6216430664062
Train_StdReturn : 0.0
Train_MaxReturn : 949.6216430664062
Train_MinReturn : 949.6216430664062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 260000
TimeSinceStart : 2618.6271097660065
Training Loss : 0.00015618735051248223
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 261 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.6839599609375
Eval_StdReturn : 12.522245407104492
Eval_MaxReturn : 955.62841796875
Eval_MinReturn : 921.37060546875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 932.67138671875
Train_StdReturn : 0.0
Train_MaxReturn : 932.67138671875
Train_MinReturn : 932.67138671875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 261000
TimeSinceStart : 2630.570062160492
Training Loss : 0.00025533855659887195
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 262 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.2755737304688
Eval_StdReturn : 5.596519947052002
Eval_MaxReturn : 954.88720703125
Eval_MinReturn : 938.2349853515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.897216796875
Train_StdReturn : 0.0
Train_MaxReturn : 955.897216796875
Train_MinReturn : 955.897216796875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 262000
TimeSinceStart : 2642.8975887298584
Training Loss : 0.0002238219603896141
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 263 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.3267822265625
Eval_StdReturn : 5.055840969085693
Eval_MaxReturn : 943.4249267578125
Eval_MinReturn : 928.6603393554688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.9644775390625
Train_StdReturn : 0.0
Train_MaxReturn : 945.9644775390625
Train_MinReturn : 945.9644775390625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 263000
TimeSinceStart : 2655.161043405533
Training Loss : 6.458439020207152e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 264 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.3722534179688
Eval_StdReturn : 2.6080374717712402
Eval_MaxReturn : 945.938232421875
Eval_MinReturn : 938.097900390625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 925.3505859375
Train_StdReturn : 0.0
Train_MaxReturn : 925.3505859375
Train_MinReturn : 925.3505859375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 264000
TimeSinceStart : 2667.491264104843
Training Loss : 0.0001458638726035133
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 265 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.1138916015625
Eval_StdReturn : 6.952534198760986
Eval_MaxReturn : 960.1280517578125
Eval_MinReturn : 940.8193969726562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.52685546875
Train_StdReturn : 0.0
Train_MaxReturn : 941.52685546875
Train_MinReturn : 941.52685546875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 265000
TimeSinceStart : 2679.677682161331
Training Loss : 4.544427429209463e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 266 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.8212890625
Eval_StdReturn : 3.633026361465454
Eval_MaxReturn : 949.1871337890625
Eval_MinReturn : 939.056640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.274658203125
Train_StdReturn : 0.0
Train_MaxReturn : 958.274658203125
Train_MinReturn : 958.274658203125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 266000
TimeSinceStart : 2691.8657290935516
Training Loss : 0.0003386512689758092
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 267 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.5985107421875
Eval_StdReturn : 11.582075119018555
Eval_MaxReturn : 953.8327026367188
Eval_MinReturn : 925.1312255859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 923.3800659179688
Train_StdReturn : 0.0
Train_MaxReturn : 923.3800659179688
Train_MinReturn : 923.3800659179688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 267000
TimeSinceStart : 2704.5107955932617
Training Loss : 9.545364446239546e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 268 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.8948974609375
Eval_StdReturn : 15.44117259979248
Eval_MaxReturn : 968.0616455078125
Eval_MinReturn : 922.3079833984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.1015625
Train_StdReturn : 0.0
Train_MaxReturn : 950.1015625
Train_MinReturn : 950.1015625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 268000
TimeSinceStart : 2717.0740978717804
Training Loss : 0.0002566046023275703
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 269 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.1644287109375
Eval_StdReturn : 11.58271598815918
Eval_MaxReturn : 953.7445068359375
Eval_MinReturn : 919.3660888671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.4759521484375
Train_StdReturn : 0.0
Train_MaxReturn : 946.4759521484375
Train_MinReturn : 946.4759521484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 269000
TimeSinceStart : 2729.2819652557373
Training Loss : 0.00012466730549931526
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 270 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 935.1173706054688
Eval_StdReturn : 6.962930202484131
Eval_MaxReturn : 946.0592041015625
Eval_MinReturn : 926.5806274414062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.8225708007812
Train_StdReturn : 0.0
Train_MaxReturn : 955.8225708007812
Train_MinReturn : 955.8225708007812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 270000
TimeSinceStart : 2741.7619745731354
Training Loss : 0.00023190013598650694
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 271 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.1253051757812
Eval_StdReturn : 7.3660688400268555
Eval_MaxReturn : 956.370361328125
Eval_MinReturn : 933.7996826171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 931.8366088867188
Train_StdReturn : 0.0
Train_MaxReturn : 931.8366088867188
Train_MinReturn : 931.8366088867188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 271000
TimeSinceStart : 2754.069073677063
Training Loss : 6.3703628256917e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 272 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.6414184570312
Eval_StdReturn : 4.61451530456543
Eval_MaxReturn : 948.4164428710938
Eval_MinReturn : 934.0106201171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.6357421875
Train_StdReturn : 0.0
Train_MaxReturn : 955.6357421875
Train_MinReturn : 955.6357421875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 272000
TimeSinceStart : 2767.3392515182495
Training Loss : 0.0002482902491465211
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 273 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.9505004882812
Eval_StdReturn : 6.799154758453369
Eval_MaxReturn : 954.1369018554688
Eval_MinReturn : 934.82177734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.56396484375
Train_StdReturn : 0.0
Train_MaxReturn : 946.56396484375
Train_MinReturn : 946.56396484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 273000
TimeSinceStart : 2779.8839569091797
Training Loss : 9.9168173619546e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 274 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.9129638671875
Eval_StdReturn : 17.56728172302246
Eval_MaxReturn : 969.7694091796875
Eval_MinReturn : 920.721923828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.0518188476562
Train_StdReturn : 0.0
Train_MaxReturn : 935.0518188476562
Train_MinReturn : 935.0518188476562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 274000
TimeSinceStart : 2791.7351558208466
Training Loss : 0.000134382484247908
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 275 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.3214111328125
Eval_StdReturn : 14.92076301574707
Eval_MaxReturn : 965.9378662109375
Eval_MinReturn : 920.5648193359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.142578125
Train_StdReturn : 0.0
Train_MaxReturn : 947.142578125
Train_MinReturn : 947.142578125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 275000
TimeSinceStart : 2804.3598897457123
Training Loss : 0.00014919183740857989
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 276 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.9109497070312
Eval_StdReturn : 9.251487731933594
Eval_MaxReturn : 963.6858520507812
Eval_MinReturn : 934.7156372070312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.963134765625
Train_StdReturn : 0.0
Train_MaxReturn : 950.963134765625
Train_MinReturn : 950.963134765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 276000
TimeSinceStart : 2816.815937757492
Training Loss : 0.0005592953530140221
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 277 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 932.2803955078125
Eval_StdReturn : 13.46666145324707
Eval_MaxReturn : 954.61572265625
Eval_MinReturn : 912.2592163085938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 925.3492431640625
Train_StdReturn : 0.0
Train_MaxReturn : 925.3492431640625
Train_MinReturn : 925.3492431640625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 277000
TimeSinceStart : 2829.023192167282
Training Loss : 0.00010451889102114365
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 278 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.0598754882812
Eval_StdReturn : 13.656869888305664
Eval_MaxReturn : 960.918212890625
Eval_MinReturn : 926.921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.2913818359375
Train_StdReturn : 0.0
Train_MaxReturn : 945.2913818359375
Train_MinReturn : 945.2913818359375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 278000
TimeSinceStart : 2841.3687794208527
Training Loss : 8.438986697001383e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 279 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.5465698242188
Eval_StdReturn : 10.434677124023438
Eval_MaxReturn : 960.6605224609375
Eval_MinReturn : 928.44091796875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.531005859375
Train_StdReturn : 0.0
Train_MaxReturn : 945.531005859375
Train_MinReturn : 945.531005859375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 279000
TimeSinceStart : 2853.9669711589813
Training Loss : 0.00028204944101162255
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 280 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 920.61474609375
Eval_StdReturn : 6.6558732986450195
Eval_MaxReturn : 930.490234375
Eval_MinReturn : 909.5032958984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.1483154296875
Train_StdReturn : 0.0
Train_MaxReturn : 934.1483154296875
Train_MinReturn : 934.1483154296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 280000
TimeSinceStart : 2866.388123989105
Training Loss : 0.000680372875649482
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 281 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 935.4026489257812
Eval_StdReturn : 9.203858375549316
Eval_MaxReturn : 947.4000244140625
Eval_MinReturn : 920.5999755859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.9068603515625
Train_StdReturn : 0.0
Train_MaxReturn : 947.9068603515625
Train_MinReturn : 947.9068603515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 281000
TimeSinceStart : 2878.9136707782745
Training Loss : 0.00018535289564169943
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 282 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.5418090820312
Eval_StdReturn : 15.898219108581543
Eval_MaxReturn : 968.2449340820312
Eval_MinReturn : 922.45703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.6046142578125
Train_StdReturn : 0.0
Train_MaxReturn : 947.6046142578125
Train_MinReturn : 947.6046142578125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 282000
TimeSinceStart : 2891.6045320034027
Training Loss : 0.00047774097765795887
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 283 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 953.6231689453125
Eval_StdReturn : 7.927558422088623
Eval_MaxReturn : 964.7988891601562
Eval_MinReturn : 944.8831787109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.8533935546875
Train_StdReturn : 0.0
Train_MaxReturn : 939.8533935546875
Train_MinReturn : 939.8533935546875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 283000
TimeSinceStart : 2904.5492107868195
Training Loss : 0.0005295188166201115
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 284 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.2399291992188
Eval_StdReturn : 11.297748565673828
Eval_MaxReturn : 955.805419921875
Eval_MinReturn : 923.8292846679688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.58984375
Train_StdReturn : 0.0
Train_MaxReturn : 945.58984375
Train_MinReturn : 945.58984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 284000
TimeSinceStart : 2917.4099781513214
Training Loss : 0.00011225541675230488
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 285 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.5584716796875
Eval_StdReturn : 11.56385326385498
Eval_MaxReturn : 953.7110595703125
Eval_MinReturn : 925.8775634765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.3438720703125
Train_StdReturn : 0.0
Train_MaxReturn : 938.3438720703125
Train_MinReturn : 938.3438720703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 285000
TimeSinceStart : 2930.1454248428345
Training Loss : 0.0003871676162816584
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 286 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.9943237304688
Eval_StdReturn : 4.018272876739502
Eval_MaxReturn : 945.2635498046875
Eval_MinReturn : 934.509521484375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 959.1829833984375
Train_StdReturn : 0.0
Train_MaxReturn : 959.1829833984375
Train_MinReturn : 959.1829833984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 286000
TimeSinceStart : 2942.8227293491364
Training Loss : 0.00030104778124950826
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 287 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.1292724609375
Eval_StdReturn : 5.523674964904785
Eval_MaxReturn : 951.48974609375
Eval_MinReturn : 937.0108642578125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.929931640625
Train_StdReturn : 0.0
Train_MaxReturn : 942.929931640625
Train_MinReturn : 942.929931640625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 287000
TimeSinceStart : 2955.652202606201
Training Loss : 9.983353811549023e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 288 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.8753662109375
Eval_StdReturn : 18.559921264648438
Eval_MaxReturn : 977.1068725585938
Eval_MinReturn : 921.89599609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.9622192382812
Train_StdReturn : 0.0
Train_MaxReturn : 938.9622192382812
Train_MinReturn : 938.9622192382812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 288000
TimeSinceStart : 2968.4563941955566
Training Loss : 0.0002642555336933583
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 289 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.1353759765625
Eval_StdReturn : 9.365978240966797
Eval_MaxReturn : 950.2863159179688
Eval_MinReturn : 924.2509765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.462646484375
Train_StdReturn : 0.0
Train_MaxReturn : 934.462646484375
Train_MinReturn : 934.462646484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 289000
TimeSinceStart : 2981.6769165992737
Training Loss : 0.00017756823217496276
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 290 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.1488037109375
Eval_StdReturn : 7.937299728393555
Eval_MaxReturn : 944.8641967773438
Eval_MinReturn : 923.7235107421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 928.4312133789062
Train_StdReturn : 0.0
Train_MaxReturn : 928.4312133789062
Train_MinReturn : 928.4312133789062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 290000
TimeSinceStart : 2994.5341641902924
Training Loss : 0.0001983299443963915
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 291 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 953.5051879882812
Eval_StdReturn : 11.793717384338379
Eval_MaxReturn : 971.7154541015625
Eval_MinReturn : 938.8018798828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 963.0895385742188
Train_StdReturn : 0.0
Train_MaxReturn : 963.0895385742188
Train_MinReturn : 963.0895385742188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 291000
TimeSinceStart : 3007.485516309738
Training Loss : 0.0001813260023482144
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 292 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.5696411132812
Eval_StdReturn : 6.717211723327637
Eval_MaxReturn : 947.7400512695312
Eval_MinReturn : 930.192626953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.8775634765625
Train_StdReturn : 0.0
Train_MaxReturn : 935.8775634765625
Train_MinReturn : 935.8775634765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 292000
TimeSinceStart : 3020.159919023514
Training Loss : 0.0008357034530490637
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 293 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.7972412109375
Eval_StdReturn : 12.388673782348633
Eval_MaxReturn : 962.8302001953125
Eval_MinReturn : 926.6009521484375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.109375
Train_StdReturn : 0.0
Train_MaxReturn : 955.109375
Train_MinReturn : 955.109375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 293000
TimeSinceStart : 3032.888239622116
Training Loss : 0.0004272030491847545
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 294 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.8616943359375
Eval_StdReturn : 7.0220794677734375
Eval_MaxReturn : 951.7142333984375
Eval_MinReturn : 932.5648803710938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.2371826171875
Train_StdReturn : 0.0
Train_MaxReturn : 939.2371826171875
Train_MinReturn : 939.2371826171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 294000
TimeSinceStart : 3045.484440803528
Training Loss : 5.444465932669118e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 295 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.2486572265625
Eval_StdReturn : 9.462939262390137
Eval_MaxReturn : 957.10986328125
Eval_MinReturn : 929.3536987304688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.3942260742188
Train_StdReturn : 0.0
Train_MaxReturn : 948.3942260742188
Train_MinReturn : 948.3942260742188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 295000
TimeSinceStart : 3058.3356676101685
Training Loss : 0.000451684434665367
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 296 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.5537109375
Eval_StdReturn : 5.073851108551025
Eval_MaxReturn : 947.423828125
Eval_MinReturn : 934.3455810546875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.1439208984375
Train_StdReturn : 0.0
Train_MaxReturn : 953.1439208984375
Train_MinReturn : 953.1439208984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 296000
TimeSinceStart : 3071.0536592006683
Training Loss : 6.838325498392805e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 297 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 954.5198974609375
Eval_StdReturn : 7.376624584197998
Eval_MaxReturn : 967.420166015625
Eval_MinReturn : 946.6715087890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.7145385742188
Train_StdReturn : 0.0
Train_MaxReturn : 938.7145385742188
Train_MinReturn : 938.7145385742188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 297000
TimeSinceStart : 3084.184299468994
Training Loss : 7.267529872478917e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 298 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.0026245117188
Eval_StdReturn : 8.496882438659668
Eval_MaxReturn : 956.6408081054688
Eval_MinReturn : 934.5631713867188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 930.625732421875
Train_StdReturn : 0.0
Train_MaxReturn : 930.625732421875
Train_MinReturn : 930.625732421875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 298000
TimeSinceStart : 3097.123338699341
Training Loss : 7.74984946474433e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 299 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.8679809570312
Eval_StdReturn : 10.547496795654297
Eval_MaxReturn : 955.771728515625
Eval_MinReturn : 926.753662109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.6766967773438
Train_StdReturn : 0.0
Train_MaxReturn : 948.6766967773438
Train_MinReturn : 948.6766967773438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 299000
TimeSinceStart : 3109.578914165497
Training Loss : 0.00021474529057741165
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 300 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.8004760742188
Eval_StdReturn : 10.403576850891113
Eval_MaxReturn : 958.4080810546875
Eval_MinReturn : 931.7064208984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.62451171875
Train_StdReturn : 0.0
Train_MaxReturn : 936.62451171875
Train_MinReturn : 936.62451171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 300000
TimeSinceStart : 3122.6226332187653
Training Loss : 0.0004473724984563887
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 301 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.4404296875
Eval_StdReturn : 8.97327995300293
Eval_MaxReturn : 955.68896484375
Eval_MinReturn : 932.2896728515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.29052734375
Train_StdReturn : 0.0
Train_MaxReturn : 933.29052734375
Train_MinReturn : 933.29052734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 301000
TimeSinceStart : 3135.747753381729
Training Loss : 0.000359797035343945
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 302 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.3984375
Eval_StdReturn : 12.023177146911621
Eval_MaxReturn : 953.1636352539062
Eval_MinReturn : 921.8094482421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.7503051757812
Train_StdReturn : 0.0
Train_MaxReturn : 955.7503051757812
Train_MinReturn : 955.7503051757812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 302000
TimeSinceStart : 3148.9195375442505
Training Loss : 0.0002442567783873528
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 303 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.8370361328125
Eval_StdReturn : 11.9860258102417
Eval_MaxReturn : 962.2168579101562
Eval_MinReturn : 933.5718994140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.3853759765625
Train_StdReturn : 0.0
Train_MaxReturn : 948.3853759765625
Train_MinReturn : 948.3853759765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 303000
TimeSinceStart : 3162.0262792110443
Training Loss : 0.00026925973361358047
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 304 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.2979736328125
Eval_StdReturn : 9.21091079711914
Eval_MaxReturn : 956.64892578125
Eval_MinReturn : 930.698974609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.024658203125
Train_StdReturn : 0.0
Train_MaxReturn : 951.024658203125
Train_MinReturn : 951.024658203125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 304000
TimeSinceStart : 3175.0398659706116
Training Loss : 0.00024933472741395235
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 305 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.57177734375
Eval_StdReturn : 7.9740777015686035
Eval_MaxReturn : 946.8326416015625
Eval_MinReturn : 924.3331909179688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.689697265625
Train_StdReturn : 0.0
Train_MaxReturn : 952.689697265625
Train_MinReturn : 952.689697265625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 305000
TimeSinceStart : 3188.040872335434
Training Loss : 0.00017025436682160944
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 306 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 952.0695190429688
Eval_StdReturn : 9.3762845993042
Eval_MaxReturn : 965.0042114257812
Eval_MinReturn : 936.5380249023438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.9976196289062
Train_StdReturn : 0.0
Train_MaxReturn : 933.9976196289062
Train_MinReturn : 933.9976196289062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 306000
TimeSinceStart : 3201.4015102386475
Training Loss : 0.0003378364781383425
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 307 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 957.33349609375
Eval_StdReturn : 10.625288009643555
Eval_MaxReturn : 973.1426391601562
Eval_MinReturn : 944.5182495117188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.9736938476562
Train_StdReturn : 0.0
Train_MaxReturn : 954.9736938476562
Train_MinReturn : 954.9736938476562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 307000
TimeSinceStart : 3214.002009153366
Training Loss : 0.00040472543332725763
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 308 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.1656494140625
Eval_StdReturn : 6.701571941375732
Eval_MaxReturn : 945.5723266601562
Eval_MinReturn : 928.9554443359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.48388671875
Train_StdReturn : 0.0
Train_MaxReturn : 950.48388671875
Train_MinReturn : 950.48388671875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 308000
TimeSinceStart : 3226.8598906993866
Training Loss : 4.915485988021828e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 309 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.5568237304688
Eval_StdReturn : 9.899596214294434
Eval_MaxReturn : 959.8822021484375
Eval_MinReturn : 932.3333740234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.1265869140625
Train_StdReturn : 0.0
Train_MaxReturn : 944.1265869140625
Train_MinReturn : 944.1265869140625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 309000
TimeSinceStart : 3239.9202451705933
Training Loss : 0.00034618511563166976
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 310 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.86865234375
Eval_StdReturn : 7.836206912994385
Eval_MaxReturn : 953.2677001953125
Eval_MinReturn : 930.6932373046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.781494140625
Train_StdReturn : 0.0
Train_MaxReturn : 938.781494140625
Train_MinReturn : 938.781494140625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 310000
TimeSinceStart : 3253.3069200515747
Training Loss : 5.261430942482548e-06
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 311 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.7476806640625
Eval_StdReturn : 3.991785764694214
Eval_MaxReturn : 945.999755859375
Eval_MinReturn : 935.2412109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.64990234375
Train_StdReturn : 0.0
Train_MaxReturn : 942.64990234375
Train_MinReturn : 942.64990234375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 311000
TimeSinceStart : 3266.751831293106
Training Loss : 3.3685228117974475e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 312 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 934.7811279296875
Eval_StdReturn : 9.847867965698242
Eval_MaxReturn : 948.1679077148438
Eval_MinReturn : 921.71337890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 924.6944580078125
Train_StdReturn : 0.0
Train_MaxReturn : 924.6944580078125
Train_MinReturn : 924.6944580078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 312000
TimeSinceStart : 3280.0370626449585
Training Loss : 0.00022715795785188675
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 313 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.5109252929688
Eval_StdReturn : 6.69506311416626
Eval_MaxReturn : 955.3426513671875
Eval_MinReturn : 935.0169677734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 961.1591186523438
Train_StdReturn : 0.0
Train_MaxReturn : 961.1591186523438
Train_MinReturn : 961.1591186523438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 313000
TimeSinceStart : 3293.115369081497
Training Loss : 0.0006035654805600643
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 314 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.5260620117188
Eval_StdReturn : 7.102837085723877
Eval_MaxReturn : 956.8269653320312
Eval_MinReturn : 935.4554443359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 959.63720703125
Train_StdReturn : 0.0
Train_MaxReturn : 959.63720703125
Train_MinReturn : 959.63720703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 314000
TimeSinceStart : 3305.9663865566254
Training Loss : 0.00022423946938943118
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 315 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 955.6077880859375
Eval_StdReturn : 7.770999908447266
Eval_MaxReturn : 968.2145385742188
Eval_MinReturn : 947.603515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 959.3731689453125
Train_StdReturn : 0.0
Train_MaxReturn : 959.3731689453125
Train_MinReturn : 959.3731689453125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 315000
TimeSinceStart : 3318.752476453781
Training Loss : 9.400784620083869e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 316 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.8336181640625
Eval_StdReturn : 17.72008514404297
Eval_MaxReturn : 951.8184814453125
Eval_MinReturn : 904.7940063476562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.229736328125
Train_StdReturn : 0.0
Train_MaxReturn : 954.229736328125
Train_MinReturn : 954.229736328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 316000
TimeSinceStart : 3331.2981038093567
Training Loss : 0.00012631324352696538
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 317 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.2429809570312
Eval_StdReturn : 5.5247907638549805
Eval_MaxReturn : 958.0736083984375
Eval_MinReturn : 942.8259887695312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 925.64501953125
Train_StdReturn : 0.0
Train_MaxReturn : 925.64501953125
Train_MinReturn : 925.64501953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 317000
TimeSinceStart : 3343.7486033439636
Training Loss : 0.0001239570410689339
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 318 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 953.0994262695312
Eval_StdReturn : 8.337547302246094
Eval_MaxReturn : 959.89794921875
Eval_MinReturn : 936.7661743164062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 957.069091796875
Train_StdReturn : 0.0
Train_MaxReturn : 957.069091796875
Train_MinReturn : 957.069091796875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 318000
TimeSinceStart : 3356.275449037552
Training Loss : 0.00031265406869351864
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 319 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.9904174804688
Eval_StdReturn : 8.338001251220703
Eval_MaxReturn : 962.48681640625
Eval_MinReturn : 940.5234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.7742919921875
Train_StdReturn : 0.0
Train_MaxReturn : 945.7742919921875
Train_MinReturn : 945.7742919921875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 319000
TimeSinceStart : 3369.2132987976074
Training Loss : 0.000609647308010608
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 320 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 935.0833740234375
Eval_StdReturn : 8.124046325683594
Eval_MaxReturn : 945.3418579101562
Eval_MinReturn : 924.0521240234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 930.8670654296875
Train_StdReturn : 0.0
Train_MaxReturn : 930.8670654296875
Train_MinReturn : 930.8670654296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 320000
TimeSinceStart : 3382.0199654102325
Training Loss : 5.7533688959665596e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 321 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 933.2576293945312
Eval_StdReturn : 13.800353050231934
Eval_MaxReturn : 957.339599609375
Eval_MinReturn : 917.8670654296875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 918.91455078125
Train_StdReturn : 0.0
Train_MaxReturn : 918.91455078125
Train_MinReturn : 918.91455078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 321000
TimeSinceStart : 3394.639425754547
Training Loss : 0.0004210822517052293
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 322 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.1976318359375
Eval_StdReturn : 7.658722400665283
Eval_MaxReturn : 951.6102294921875
Eval_MinReturn : 930.325927734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 957.58447265625
Train_StdReturn : 0.0
Train_MaxReturn : 957.58447265625
Train_MinReturn : 957.58447265625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 322000
TimeSinceStart : 3407.370619535446
Training Loss : 0.00028939233743585646
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 323 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.8154296875
Eval_StdReturn : 8.844707489013672
Eval_MaxReturn : 951.6165161132812
Eval_MinReturn : 925.5830078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.695068359375
Train_StdReturn : 0.0
Train_MaxReturn : 955.695068359375
Train_MinReturn : 955.695068359375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 323000
TimeSinceStart : 3420.017451763153
Training Loss : 0.00038991167093627155
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 324 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.4986572265625
Eval_StdReturn : 6.114940166473389
Eval_MaxReturn : 947.8640747070312
Eval_MinReturn : 931.6727905273438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.9286499023438
Train_StdReturn : 0.0
Train_MaxReturn : 936.9286499023438
Train_MinReturn : 936.9286499023438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 324000
TimeSinceStart : 3432.6115732192993
Training Loss : 0.00033862399868667126
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 325 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.3248291015625
Eval_StdReturn : 12.469712257385254
Eval_MaxReturn : 963.67578125
Eval_MinReturn : 924.947021484375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.7552490234375
Train_StdReturn : 0.0
Train_MaxReturn : 938.7552490234375
Train_MinReturn : 938.7552490234375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 325000
TimeSinceStart : 3445.3733983039856
Training Loss : 0.0003635092871263623
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 326 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.7306518554688
Eval_StdReturn : 7.663053512573242
Eval_MaxReturn : 953.4407348632812
Eval_MinReturn : 930.398681640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.2205200195312
Train_StdReturn : 0.0
Train_MaxReturn : 937.2205200195312
Train_MinReturn : 937.2205200195312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 326000
TimeSinceStart : 3458.8959155082703
Training Loss : 0.00015886995242908597
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 327 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.9192504882812
Eval_StdReturn : 6.7336602210998535
Eval_MaxReturn : 943.3582763671875
Eval_MinReturn : 923.906005859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.804443359375
Train_StdReturn : 0.0
Train_MaxReturn : 947.804443359375
Train_MinReturn : 947.804443359375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 327000
TimeSinceStart : 3472.1809339523315
Training Loss : 0.00016838856390677392
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 328 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.611328125
Eval_StdReturn : 5.560091972351074
Eval_MaxReturn : 959.7597045898438
Eval_MinReturn : 943.9490966796875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.7057495117188
Train_StdReturn : 0.0
Train_MaxReturn : 942.7057495117188
Train_MinReturn : 942.7057495117188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 328000
TimeSinceStart : 3485.2488074302673
Training Loss : 0.00027491358923725784
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 329 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.9964599609375
Eval_StdReturn : 7.636296272277832
Eval_MaxReturn : 956.3050537109375
Eval_MinReturn : 935.0037231445312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.1876220703125
Train_StdReturn : 0.0
Train_MaxReturn : 947.1876220703125
Train_MinReturn : 947.1876220703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 329000
TimeSinceStart : 3498.8525054454803
Training Loss : 8.864707342581823e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 330 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.1316528320312
Eval_StdReturn : 11.469822883605957
Eval_MaxReturn : 950.5955810546875
Eval_MinReturn : 921.6119384765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.9073486328125
Train_StdReturn : 0.0
Train_MaxReturn : 953.9073486328125
Train_MinReturn : 953.9073486328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 330000
TimeSinceStart : 3512.541076183319
Training Loss : 3.582701174309477e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 331 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.58984375
Eval_StdReturn : 10.641998291015625
Eval_MaxReturn : 954.751953125
Eval_MinReturn : 931.07861328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.80908203125
Train_StdReturn : 0.0
Train_MaxReturn : 937.80908203125
Train_MinReturn : 937.80908203125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 331000
TimeSinceStart : 3526.096848011017
Training Loss : 0.000679501798003912
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 332 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 934.1187744140625
Eval_StdReturn : 15.262535095214844
Eval_MaxReturn : 954.2135009765625
Eval_MinReturn : 914.6043090820312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.5099487304688
Train_StdReturn : 0.0
Train_MaxReturn : 940.5099487304688
Train_MinReturn : 940.5099487304688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 332000
TimeSinceStart : 3539.689268350601
Training Loss : 3.392783764866181e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 333 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 932.4560546875
Eval_StdReturn : 6.284041404724121
Eval_MaxReturn : 941.1151123046875
Eval_MinReturn : 925.1463623046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.7132568359375
Train_StdReturn : 0.0
Train_MaxReturn : 942.7132568359375
Train_MinReturn : 942.7132568359375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 333000
TimeSinceStart : 3553.405040740967
Training Loss : 0.00028929737163707614
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 334 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.5321044921875
Eval_StdReturn : 9.06374454498291
Eval_MaxReturn : 952.460205078125
Eval_MinReturn : 927.3715209960938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 931.3287353515625
Train_StdReturn : 0.0
Train_MaxReturn : 931.3287353515625
Train_MinReturn : 931.3287353515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 334000
TimeSinceStart : 3567.193832874298
Training Loss : 0.000422744924435392
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 335 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.0535888671875
Eval_StdReturn : 4.929237365722656
Eval_MaxReturn : 954.4080200195312
Eval_MinReturn : 939.909912109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 928.3900756835938
Train_StdReturn : 0.0
Train_MaxReturn : 928.3900756835938
Train_MinReturn : 928.3900756835938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 335000
TimeSinceStart : 3580.902777671814
Training Loss : 0.0003640835639089346
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 336 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.1292114257812
Eval_StdReturn : 12.343299865722656
Eval_MaxReturn : 961.0015258789062
Eval_MinReturn : 923.1868896484375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.4827880859375
Train_StdReturn : 0.0
Train_MaxReturn : 950.4827880859375
Train_MinReturn : 950.4827880859375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 336000
TimeSinceStart : 3594.5729155540466
Training Loss : 9.80025070020929e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 337 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.1197509765625
Eval_StdReturn : 2.916172981262207
Eval_MaxReturn : 949.7655029296875
Eval_MinReturn : 940.8311767578125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.41064453125
Train_StdReturn : 0.0
Train_MaxReturn : 942.41064453125
Train_MinReturn : 942.41064453125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 337000
TimeSinceStart : 3608.619875192642
Training Loss : 0.00011231381358811632
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 338 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.5452880859375
Eval_StdReturn : 3.5896925926208496
Eval_MaxReturn : 956.8231201171875
Eval_MinReturn : 945.8473510742188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.2531127929688
Train_StdReturn : 0.0
Train_MaxReturn : 953.2531127929688
Train_MinReturn : 953.2531127929688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 338000
TimeSinceStart : 3622.4451637268066
Training Loss : 5.7530374760972336e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 339 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.5029296875
Eval_StdReturn : 5.693947792053223
Eval_MaxReturn : 957.62255859375
Eval_MinReturn : 942.6192626953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.80322265625
Train_StdReturn : 0.0
Train_MaxReturn : 934.80322265625
Train_MinReturn : 934.80322265625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 339000
TimeSinceStart : 3636.004696369171
Training Loss : 0.00035236304393038154
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 340 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.0428466796875
Eval_StdReturn : 11.075393676757812
Eval_MaxReturn : 956.952392578125
Eval_MinReturn : 928.2429809570312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.8026123046875
Train_StdReturn : 0.0
Train_MaxReturn : 940.8026123046875
Train_MinReturn : 940.8026123046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 340000
TimeSinceStart : 3649.5709936618805
Training Loss : 0.0010740458965301514
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 341 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.2796020507812
Eval_StdReturn : 17.19856834411621
Eval_MaxReturn : 960.1011962890625
Eval_MinReturn : 913.3108520507812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.927734375
Train_StdReturn : 0.0
Train_MaxReturn : 953.927734375
Train_MinReturn : 953.927734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 341000
TimeSinceStart : 3663.678645133972
Training Loss : 0.00013690086780115962
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 342 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.06396484375
Eval_StdReturn : 10.346328735351562
Eval_MaxReturn : 961.3385009765625
Eval_MinReturn : 930.26953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.54345703125
Train_StdReturn : 0.0
Train_MaxReturn : 938.54345703125
Train_MinReturn : 938.54345703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 342000
TimeSinceStart : 3677.692655324936
Training Loss : 0.0003352277562953532
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 343 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.7056884765625
Eval_StdReturn : 5.954609394073486
Eval_MaxReturn : 955.7452392578125
Eval_MinReturn : 937.8304443359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 913.0369873046875
Train_StdReturn : 0.0
Train_MaxReturn : 913.0369873046875
Train_MinReturn : 913.0369873046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 343000
TimeSinceStart : 3691.757225751877
Training Loss : 0.00025540959904901683
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 344 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.4129638671875
Eval_StdReturn : 7.936912536621094
Eval_MaxReturn : 949.4700927734375
Eval_MinReturn : 930.4918212890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.78662109375
Train_StdReturn : 0.0
Train_MaxReturn : 953.78662109375
Train_MinReturn : 953.78662109375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 344000
TimeSinceStart : 3705.44193816185
Training Loss : 0.0001924218377098441
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 345 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.0853271484375
Eval_StdReturn : 8.361727714538574
Eval_MaxReturn : 948.620361328125
Eval_MinReturn : 922.5509033203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 963.645751953125
Train_StdReturn : 0.0
Train_MaxReturn : 963.645751953125
Train_MinReturn : 963.645751953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 345000
TimeSinceStart : 3718.9730100631714
Training Loss : 0.00012358420644886792
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 346 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.2584228515625
Eval_StdReturn : 10.901638984680176
Eval_MaxReturn : 954.571533203125
Eval_MinReturn : 924.2409057617188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.3788452148438
Train_StdReturn : 0.0
Train_MaxReturn : 937.3788452148438
Train_MinReturn : 937.3788452148438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 346000
TimeSinceStart : 3732.0527148246765
Training Loss : 0.0007693635998293757
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 347 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.21826171875
Eval_StdReturn : 9.252360343933105
Eval_MaxReturn : 961.107177734375
Eval_MinReturn : 935.3162231445312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 959.2967529296875
Train_StdReturn : 0.0
Train_MaxReturn : 959.2967529296875
Train_MinReturn : 959.2967529296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 347000
TimeSinceStart : 3745.9370963573456
Training Loss : 5.579166827374138e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 348 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.5645751953125
Eval_StdReturn : 17.16240882873535
Eval_MaxReturn : 977.3775024414062
Eval_MinReturn : 931.5930786132812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.4403686523438
Train_StdReturn : 0.0
Train_MaxReturn : 936.4403686523438
Train_MinReturn : 936.4403686523438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 348000
TimeSinceStart : 3759.9360983371735
Training Loss : 0.0002190327359130606
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 349 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.6468505859375
Eval_StdReturn : 7.268422603607178
Eval_MaxReturn : 954.2449951171875
Eval_MinReturn : 935.941162109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.5468139648438
Train_StdReturn : 0.0
Train_MaxReturn : 950.5468139648438
Train_MinReturn : 950.5468139648438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 349000
TimeSinceStart : 3773.788980484009
Training Loss : 0.00013340951409190893
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 350 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.50634765625
Eval_StdReturn : 11.784646034240723
Eval_MaxReturn : 953.0897827148438
Eval_MinReturn : 924.5972290039062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 929.47998046875
Train_StdReturn : 0.0
Train_MaxReturn : 929.47998046875
Train_MinReturn : 929.47998046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 350000
TimeSinceStart : 3787.466824531555
Training Loss : 0.00015154921857174486
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 351 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.6463012695312
Eval_StdReturn : 7.140008449554443
Eval_MaxReturn : 953.253173828125
Eval_MinReturn : 934.0171508789062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.5489501953125
Train_StdReturn : 0.0
Train_MaxReturn : 951.5489501953125
Train_MinReturn : 951.5489501953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 351000
TimeSinceStart : 3801.434719800949
Training Loss : 0.0001907742553157732
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 352 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 961.8692626953125
Eval_StdReturn : 7.3486433029174805
Eval_MaxReturn : 969.8587036132812
Eval_MinReturn : 948.8267211914062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 925.0928955078125
Train_StdReturn : 0.0
Train_MaxReturn : 925.0928955078125
Train_MinReturn : 925.0928955078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 352000
TimeSinceStart : 3815.512445449829
Training Loss : 8.93780161277391e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 353 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.9996337890625
Eval_StdReturn : 6.600212574005127
Eval_MaxReturn : 958.451416015625
Eval_MinReturn : 941.2618408203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.5009765625
Train_StdReturn : 0.0
Train_MaxReturn : 950.5009765625
Train_MinReturn : 950.5009765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 353000
TimeSinceStart : 3829.7861166000366
Training Loss : 0.0006737330695614219
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 354 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.5794677734375
Eval_StdReturn : 11.857014656066895
Eval_MaxReturn : 960.9154052734375
Eval_MinReturn : 929.9539794921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.93603515625
Train_StdReturn : 0.0
Train_MaxReturn : 950.93603515625
Train_MinReturn : 950.93603515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 354000
TimeSinceStart : 3843.877605676651
Training Loss : 0.00032882404047995806
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 355 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.0013427734375
Eval_StdReturn : 7.29981803894043
Eval_MaxReturn : 955.7150268554688
Eval_MinReturn : 936.3753662109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.25927734375
Train_StdReturn : 0.0
Train_MaxReturn : 955.25927734375
Train_MinReturn : 955.25927734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 355000
TimeSinceStart : 3857.267805814743
Training Loss : 0.0008543152362108231
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 356 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 964.3342895507812
Eval_StdReturn : 18.782955169677734
Eval_MaxReturn : 983.8851928710938
Eval_MinReturn : 940.3734130859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 960.7454833984375
Train_StdReturn : 0.0
Train_MaxReturn : 960.7454833984375
Train_MinReturn : 960.7454833984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 356000
TimeSinceStart : 3871.233572244644
Training Loss : 0.009878784418106079
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 357 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.9236450195312
Eval_StdReturn : 10.395062446594238
Eval_MaxReturn : 957.236083984375
Eval_MinReturn : 926.3607177734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.0730590820312
Train_StdReturn : 0.0
Train_MaxReturn : 941.0730590820312
Train_MinReturn : 941.0730590820312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 357000
TimeSinceStart : 3885.258118867874
Training Loss : 0.0001518157951068133
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 358 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.6463012695312
Eval_StdReturn : 5.77746057510376
Eval_MaxReturn : 958.3897094726562
Eval_MinReturn : 941.443603515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.9161987304688
Train_StdReturn : 0.0
Train_MaxReturn : 951.9161987304688
Train_MinReturn : 951.9161987304688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 358000
TimeSinceStart : 3899.6262147426605
Training Loss : 6.433221278712153e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 359 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.0222778320312
Eval_StdReturn : 9.202713012695312
Eval_MaxReturn : 961.2947998046875
Eval_MinReturn : 937.1021118164062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.7623291015625
Train_StdReturn : 0.0
Train_MaxReturn : 938.7623291015625
Train_MinReturn : 938.7623291015625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 359000
TimeSinceStart : 3913.806971549988
Training Loss : 0.00031590054277330637
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 360 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 935.0740356445312
Eval_StdReturn : 8.131492614746094
Eval_MaxReturn : 945.595947265625
Eval_MinReturn : 921.2291259765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.8260498046875
Train_StdReturn : 0.0
Train_MaxReturn : 933.8260498046875
Train_MinReturn : 933.8260498046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 360000
TimeSinceStart : 3927.0374584198
Training Loss : 0.0002230501704616472
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 361 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 952.7537841796875
Eval_StdReturn : 5.834556579589844
Eval_MaxReturn : 958.50927734375
Eval_MinReturn : 941.7970581054688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.9374389648438
Train_StdReturn : 0.0
Train_MaxReturn : 934.9374389648438
Train_MinReturn : 934.9374389648438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 361000
TimeSinceStart : 3940.9959065914154
Training Loss : 0.0004780931049026549
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 362 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.8775634765625
Eval_StdReturn : 10.839122772216797
Eval_MaxReturn : 952.296875
Eval_MinReturn : 920.6823120117188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 960.137939453125
Train_StdReturn : 0.0
Train_MaxReturn : 960.137939453125
Train_MinReturn : 960.137939453125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 362000
TimeSinceStart : 3955.0618891716003
Training Loss : 0.00046431392547674477
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 363 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.9484252929688
Eval_StdReturn : 15.103230476379395
Eval_MaxReturn : 961.219482421875
Eval_MinReturn : 915.0965576171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.0845947265625
Train_StdReturn : 0.0
Train_MaxReturn : 940.0845947265625
Train_MinReturn : 940.0845947265625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 363000
TimeSinceStart : 3969.2655720710754
Training Loss : 0.0003997051389887929
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 364 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.5563354492188
Eval_StdReturn : 12.359492301940918
Eval_MaxReturn : 966.8797607421875
Eval_MinReturn : 935.9641723632812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.1243896484375
Train_StdReturn : 0.0
Train_MaxReturn : 951.1243896484375
Train_MinReturn : 951.1243896484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 364000
TimeSinceStart : 3983.2822926044464
Training Loss : 3.051934254472144e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 365 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.9752807617188
Eval_StdReturn : 12.97828197479248
Eval_MaxReturn : 954.4254150390625
Eval_MinReturn : 917.0949096679688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.8660278320312
Train_StdReturn : 0.0
Train_MaxReturn : 951.8660278320312
Train_MinReturn : 951.8660278320312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 365000
TimeSinceStart : 3996.917726755142
Training Loss : 0.0007974092732183635
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 366 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.9315185546875
Eval_StdReturn : 10.438637733459473
Eval_MaxReturn : 955.02392578125
Eval_MinReturn : 926.3243408203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.865234375
Train_StdReturn : 0.0
Train_MaxReturn : 941.865234375
Train_MinReturn : 941.865234375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 366000
TimeSinceStart : 4011.239800453186
Training Loss : 0.0002118546690326184
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 367 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.9273681640625
Eval_StdReturn : 11.344788551330566
Eval_MaxReturn : 964.9835205078125
Eval_MinReturn : 930.4863891601562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.3901977539062
Train_StdReturn : 0.0
Train_MaxReturn : 933.3901977539062
Train_MinReturn : 933.3901977539062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 367000
TimeSinceStart : 4025.1554288864136
Training Loss : 5.596311530098319e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 368 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.6861572265625
Eval_StdReturn : 6.085360050201416
Eval_MaxReturn : 948.774169921875
Eval_MinReturn : 931.2589111328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.7420654296875
Train_StdReturn : 0.0
Train_MaxReturn : 943.7420654296875
Train_MinReturn : 943.7420654296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 368000
TimeSinceStart : 4038.774782896042
Training Loss : 0.000384403916541487
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 369 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 932.478515625
Eval_StdReturn : 13.689040184020996
Eval_MaxReturn : 958.0090942382812
Eval_MinReturn : 919.6339111328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.2412109375
Train_StdReturn : 0.0
Train_MaxReturn : 956.2412109375
Train_MinReturn : 956.2412109375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 369000
TimeSinceStart : 4052.293292760849
Training Loss : 0.0006009694188833237
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 370 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.7449951171875
Eval_StdReturn : 6.050345420837402
Eval_MaxReturn : 957.4783935546875
Eval_MinReturn : 942.8594970703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.666748046875
Train_StdReturn : 0.0
Train_MaxReturn : 951.666748046875
Train_MinReturn : 951.666748046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 370000
TimeSinceStart : 4065.681434392929
Training Loss : 0.00011927977902814746
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 371 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.2097778320312
Eval_StdReturn : 11.933573722839355
Eval_MaxReturn : 962.7728271484375
Eval_MinReturn : 931.3472290039062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.0286254882812
Train_StdReturn : 0.0
Train_MaxReturn : 938.0286254882812
Train_MinReturn : 938.0286254882812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 371000
TimeSinceStart : 4079.2800550460815
Training Loss : 0.0003682281821966171
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 372 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.1642456054688
Eval_StdReturn : 10.029192924499512
Eval_MaxReturn : 962.4710693359375
Eval_MinReturn : 932.9512939453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 963.506591796875
Train_StdReturn : 0.0
Train_MaxReturn : 963.506591796875
Train_MinReturn : 963.506591796875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 372000
TimeSinceStart : 4092.911157846451
Training Loss : 0.000269157811999321
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 373 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.0269775390625
Eval_StdReturn : 10.079723358154297
Eval_MaxReturn : 968.1312255859375
Eval_MinReturn : 939.8599243164062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.4954833984375
Train_StdReturn : 0.0
Train_MaxReturn : 946.4954833984375
Train_MinReturn : 946.4954833984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 373000
TimeSinceStart : 4106.43190908432
Training Loss : 0.00018678835476748645
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 374 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.5535278320312
Eval_StdReturn : 11.961919784545898
Eval_MaxReturn : 956.9130859375
Eval_MinReturn : 924.5072021484375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.1348266601562
Train_StdReturn : 0.0
Train_MaxReturn : 935.1348266601562
Train_MinReturn : 935.1348266601562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 374000
TimeSinceStart : 4120.879889011383
Training Loss : 0.00017010267765726894
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 375 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.7991333007812
Eval_StdReturn : 10.37808895111084
Eval_MaxReturn : 949.1658325195312
Eval_MinReturn : 923.497802734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 932.781005859375
Train_StdReturn : 0.0
Train_MaxReturn : 932.781005859375
Train_MinReturn : 932.781005859375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 375000
TimeSinceStart : 4135.168145418167
Training Loss : 7.812025432940573e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 376 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.1041259765625
Eval_StdReturn : 6.285676002502441
Eval_MaxReturn : 948.8509521484375
Eval_MinReturn : 930.367431640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 919.9287109375
Train_StdReturn : 0.0
Train_MaxReturn : 919.9287109375
Train_MinReturn : 919.9287109375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 376000
TimeSinceStart : 4149.601222276688
Training Loss : 0.000258422689512372
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 377 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.1822509765625
Eval_StdReturn : 7.468457221984863
Eval_MaxReturn : 951.4266967773438
Eval_MinReturn : 934.5904541015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 929.5980224609375
Train_StdReturn : 0.0
Train_MaxReturn : 929.5980224609375
Train_MinReturn : 929.5980224609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 377000
TimeSinceStart : 4164.121963024139
Training Loss : 0.00023004466493148357
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 378 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.7063598632812
Eval_StdReturn : 9.980445861816406
Eval_MaxReturn : 957.4984130859375
Eval_MinReturn : 930.4913940429688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 925.8865966796875
Train_StdReturn : 0.0
Train_MaxReturn : 925.8865966796875
Train_MinReturn : 925.8865966796875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 378000
TimeSinceStart : 4178.558379888535
Training Loss : 0.00010737480624811724
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 379 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 956.9833984375
Eval_StdReturn : 11.724319458007812
Eval_MaxReturn : 975.2471313476562
Eval_MinReturn : 945.14501953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.5018920898438
Train_StdReturn : 0.0
Train_MaxReturn : 949.5018920898438
Train_MinReturn : 949.5018920898438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 379000
TimeSinceStart : 4192.990878343582
Training Loss : 0.00012286390119697899
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 380 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.0771484375
Eval_StdReturn : 9.291095733642578
Eval_MaxReturn : 954.1130981445312
Eval_MinReturn : 928.89990234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 962.346435546875
Train_StdReturn : 0.0
Train_MaxReturn : 962.346435546875
Train_MinReturn : 962.346435546875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 380000
TimeSinceStart : 4207.614609718323
Training Loss : 0.00027878250693902373
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 381 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 954.5382690429688
Eval_StdReturn : 11.170106887817383
Eval_MaxReturn : 971.2871704101562
Eval_MinReturn : 944.9293823242188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.13623046875
Train_StdReturn : 0.0
Train_MaxReturn : 935.13623046875
Train_MinReturn : 935.13623046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 381000
TimeSinceStart : 4222.209883451462
Training Loss : 0.00038943561958149076
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 382 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 954.0709228515625
Eval_StdReturn : 4.422686576843262
Eval_MaxReturn : 960.4108276367188
Eval_MinReturn : 948.7808227539062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.68310546875
Train_StdReturn : 0.0
Train_MaxReturn : 945.68310546875
Train_MinReturn : 945.68310546875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 382000
TimeSinceStart : 4236.668210983276
Training Loss : 0.00011770999117288738
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 383 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.6969604492188
Eval_StdReturn : 8.917367935180664
Eval_MaxReturn : 959.3802490234375
Eval_MinReturn : 933.0458374023438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.176513671875
Train_StdReturn : 0.0
Train_MaxReturn : 948.176513671875
Train_MinReturn : 948.176513671875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 383000
TimeSinceStart : 4250.579858779907
Training Loss : 0.0004803626798093319
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 384 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.4684448242188
Eval_StdReturn : 7.603522777557373
Eval_MaxReturn : 948.5032958984375
Eval_MinReturn : 925.987548828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.57470703125
Train_StdReturn : 0.0
Train_MaxReturn : 945.57470703125
Train_MinReturn : 945.57470703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 384000
TimeSinceStart : 4264.596000909805
Training Loss : 0.00014485331485047936
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 385 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 953.2384033203125
Eval_StdReturn : 12.918031692504883
Eval_MaxReturn : 966.70458984375
Eval_MinReturn : 930.7215576171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.4146118164062
Train_StdReturn : 0.0
Train_MaxReturn : 937.4146118164062
Train_MinReturn : 937.4146118164062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 385000
TimeSinceStart : 4279.32537984848
Training Loss : 8.712033741176128e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 386 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.5452880859375
Eval_StdReturn : 11.63335132598877
Eval_MaxReturn : 958.6622314453125
Eval_MinReturn : 928.8543701171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.6558227539062
Train_StdReturn : 0.0
Train_MaxReturn : 942.6558227539062
Train_MinReturn : 942.6558227539062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 386000
TimeSinceStart : 4293.652983188629
Training Loss : 0.0002812862803693861
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 387 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 934.01611328125
Eval_StdReturn : 8.639057159423828
Eval_MaxReturn : 945.6590576171875
Eval_MinReturn : 921.6258544921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.5902099609375
Train_StdReturn : 0.0
Train_MaxReturn : 940.5902099609375
Train_MinReturn : 940.5902099609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 387000
TimeSinceStart : 4308.158266782761
Training Loss : 0.0002456115325912833
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 388 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.5950317382812
Eval_StdReturn : 9.671502113342285
Eval_MaxReturn : 955.9735107421875
Eval_MinReturn : 932.2778930664062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.5826416015625
Train_StdReturn : 0.0
Train_MaxReturn : 937.5826416015625
Train_MinReturn : 937.5826416015625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 388000
TimeSinceStart : 4322.799545288086
Training Loss : 0.0002130312059307471
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 389 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.0960083007812
Eval_StdReturn : 7.135090351104736
Eval_MaxReturn : 945.41064453125
Eval_MinReturn : 926.60302734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 932.9992065429688
Train_StdReturn : 0.0
Train_MaxReturn : 932.9992065429688
Train_MinReturn : 932.9992065429688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 389000
TimeSinceStart : 4337.370888471603
Training Loss : 0.0006051478558219969
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 390 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.1311645507812
Eval_StdReturn : 10.651664733886719
Eval_MaxReturn : 964.2275390625
Eval_MinReturn : 935.9256591796875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.8514404296875
Train_StdReturn : 0.0
Train_MaxReturn : 945.8514404296875
Train_MinReturn : 945.8514404296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 390000
TimeSinceStart : 4352.048111438751
Training Loss : 0.0007143925176933408
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 391 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.3084716796875
Eval_StdReturn : 11.397908210754395
Eval_MaxReturn : 963.002197265625
Eval_MinReturn : 932.4605712890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.9140625
Train_StdReturn : 0.0
Train_MaxReturn : 950.9140625
Train_MinReturn : 950.9140625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 391000
TimeSinceStart : 4366.057332754135
Training Loss : 0.000635220785625279
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 392 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.1891479492188
Eval_StdReturn : 16.358171463012695
Eval_MaxReturn : 962.3837890625
Eval_MinReturn : 912.9993896484375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.5069580078125
Train_StdReturn : 0.0
Train_MaxReturn : 948.5069580078125
Train_MinReturn : 948.5069580078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 392000
TimeSinceStart : 4380.566629648209
Training Loss : 5.630249870591797e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 393 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.7283325195312
Eval_StdReturn : 6.222545146942139
Eval_MaxReturn : 956.3494873046875
Eval_MinReturn : 939.1890258789062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.39599609375
Train_StdReturn : 0.0
Train_MaxReturn : 956.39599609375
Train_MinReturn : 956.39599609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 393000
TimeSinceStart : 4394.998104810715
Training Loss : 0.0003665044787339866
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 394 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.4610595703125
Eval_StdReturn : 12.132452011108398
Eval_MaxReturn : 958.0441284179688
Eval_MinReturn : 921.0374755859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.83203125
Train_StdReturn : 0.0
Train_MaxReturn : 951.83203125
Train_MinReturn : 951.83203125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 394000
TimeSinceStart : 4409.557836294174
Training Loss : 0.0002696230949368328
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 395 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.6525268554688
Eval_StdReturn : 10.742399215698242
Eval_MaxReturn : 957.232177734375
Eval_MinReturn : 924.340087890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.6264038085938
Train_StdReturn : 0.0
Train_MaxReturn : 936.6264038085938
Train_MinReturn : 936.6264038085938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 395000
TimeSinceStart : 4424.373873472214
Training Loss : 9.895674884319305e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 396 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.2296142578125
Eval_StdReturn : 11.547185897827148
Eval_MaxReturn : 959.760009765625
Eval_MinReturn : 928.7156982421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.1141357421875
Train_StdReturn : 0.0
Train_MaxReturn : 958.1141357421875
Train_MinReturn : 958.1141357421875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 396000
TimeSinceStart : 4438.878094434738
Training Loss : 0.0006051163654774427
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 397 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.22607421875
Eval_StdReturn : 11.400697708129883
Eval_MaxReturn : 965.6427612304688
Eval_MinReturn : 930.7235107421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.9853515625
Train_StdReturn : 0.0
Train_MaxReturn : 951.9853515625
Train_MinReturn : 951.9853515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 397000
TimeSinceStart : 4453.553922176361
Training Loss : 0.00043234735494479537
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 398 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.0189208984375
Eval_StdReturn : 9.87760066986084
Eval_MaxReturn : 952.5457763671875
Eval_MinReturn : 930.4549560546875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.354736328125
Train_StdReturn : 0.0
Train_MaxReturn : 935.354736328125
Train_MinReturn : 935.354736328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 398000
TimeSinceStart : 4468.289031744003
Training Loss : 7.056887989165261e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 399 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.0397338867188
Eval_StdReturn : 9.347553253173828
Eval_MaxReturn : 961.6627197265625
Eval_MinReturn : 933.7772216796875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 960.3922119140625
Train_StdReturn : 0.0
Train_MaxReturn : 960.3922119140625
Train_MinReturn : 960.3922119140625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 399000
TimeSinceStart : 4483.048922777176
Training Loss : 0.0007644979632459581
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 400 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.3258056640625
Eval_StdReturn : 3.9438652992248535
Eval_MaxReturn : 950.2207641601562
Eval_MinReturn : 939.0743408203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.1363525390625
Train_StdReturn : 0.0
Train_MaxReturn : 941.1363525390625
Train_MinReturn : 941.1363525390625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 400000
TimeSinceStart : 4497.591893672943
Training Loss : 0.0003920353774446994
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 401 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.9913940429688
Eval_StdReturn : 7.113015174865723
Eval_MaxReturn : 951.28515625
Eval_MinReturn : 929.8106689453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.1497192382812
Train_StdReturn : 0.0
Train_MaxReturn : 949.1497192382812
Train_MinReturn : 949.1497192382812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 401000
TimeSinceStart : 4512.709035158157
Training Loss : 0.00034692377084866166
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 402 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.4591674804688
Eval_StdReturn : 10.336331367492676
Eval_MaxReturn : 959.347412109375
Eval_MinReturn : 930.97021484375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.3845825195312
Train_StdReturn : 0.0
Train_MaxReturn : 941.3845825195312
Train_MinReturn : 941.3845825195312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 402000
TimeSinceStart : 4527.839776992798
Training Loss : 0.0004611465847119689
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 403 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 932.2000732421875
Eval_StdReturn : 10.18531608581543
Eval_MaxReturn : 947.0017700195312
Eval_MinReturn : 921.66015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.06787109375
Train_StdReturn : 0.0
Train_MaxReturn : 949.06787109375
Train_MinReturn : 949.06787109375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 403000
TimeSinceStart : 4542.903685331345
Training Loss : 0.0005768740666098893
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 404 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.8798828125
Eval_StdReturn : 7.68225622177124
Eval_MaxReturn : 952.6851806640625
Eval_MinReturn : 934.964599609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 931.65087890625
Train_StdReturn : 0.0
Train_MaxReturn : 931.65087890625
Train_MinReturn : 931.65087890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 404000
TimeSinceStart : 4557.4075129032135
Training Loss : 0.00043937345617450774
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 405 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.7279052734375
Eval_StdReturn : 8.297028541564941
Eval_MaxReturn : 956.784912109375
Eval_MinReturn : 935.2593994140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.0674438476562
Train_StdReturn : 0.0
Train_MaxReturn : 934.0674438476562
Train_MinReturn : 934.0674438476562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 405000
TimeSinceStart : 4572.3200669288635
Training Loss : 0.0005961705464869738
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 406 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.7169189453125
Eval_StdReturn : 12.272377967834473
Eval_MaxReturn : 950.6810302734375
Eval_MinReturn : 920.1994018554688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.947509765625
Train_StdReturn : 0.0
Train_MaxReturn : 955.947509765625
Train_MinReturn : 955.947509765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 406000
TimeSinceStart : 4587.401874303818
Training Loss : 0.0001629453181521967
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 407 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 954.9691162109375
Eval_StdReturn : 9.085921287536621
Eval_MaxReturn : 969.9868774414062
Eval_MinReturn : 946.4314575195312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.6693725585938
Train_StdReturn : 0.0
Train_MaxReturn : 941.6693725585938
Train_MinReturn : 941.6693725585938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 407000
TimeSinceStart : 4602.171519994736
Training Loss : 0.00020172802032902837
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 408 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 964.9488525390625
Eval_StdReturn : 7.965311527252197
Eval_MaxReturn : 975.3582763671875
Eval_MinReturn : 953.5480346679688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 924.4342041015625
Train_StdReturn : 0.0
Train_MaxReturn : 924.4342041015625
Train_MinReturn : 924.4342041015625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 408000
TimeSinceStart : 4617.009488105774
Training Loss : 0.0017450536834076047
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 409 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.0930786132812
Eval_StdReturn : 11.949943542480469
Eval_MaxReturn : 957.8145751953125
Eval_MinReturn : 926.731689453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.0100708007812
Train_StdReturn : 0.0
Train_MaxReturn : 954.0100708007812
Train_MinReturn : 954.0100708007812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 409000
TimeSinceStart : 4632.034064531326
Training Loss : 0.000240896173636429
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 410 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 928.2301635742188
Eval_StdReturn : 13.776655197143555
Eval_MaxReturn : 954.892822265625
Eval_MinReturn : 916.9309692382812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 925.976806640625
Train_StdReturn : 0.0
Train_MaxReturn : 925.976806640625
Train_MinReturn : 925.976806640625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 410000
TimeSinceStart : 4647.353241205215
Training Loss : 0.0003340435214340687
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 411 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.7150268554688
Eval_StdReturn : 13.635161399841309
Eval_MaxReturn : 964.9189453125
Eval_MinReturn : 928.1885986328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.2809448242188
Train_StdReturn : 0.0
Train_MaxReturn : 939.2809448242188
Train_MinReturn : 939.2809448242188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 411000
TimeSinceStart : 4662.439063310623
Training Loss : 0.0005992741207592189
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 412 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.9371337890625
Eval_StdReturn : 10.366576194763184
Eval_MaxReturn : 960.2724609375
Eval_MinReturn : 932.3984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.5086669921875
Train_StdReturn : 0.0
Train_MaxReturn : 935.5086669921875
Train_MinReturn : 935.5086669921875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 412000
TimeSinceStart : 4677.514603853226
Training Loss : 9.406486060470343e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 413 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.92529296875
Eval_StdReturn : 9.456767082214355
Eval_MaxReturn : 960.487060546875
Eval_MinReturn : 932.017822265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 929.2200927734375
Train_StdReturn : 0.0
Train_MaxReturn : 929.2200927734375
Train_MinReturn : 929.2200927734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 413000
TimeSinceStart : 4692.665239572525
Training Loss : 9.401054558111355e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 414 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.4638671875
Eval_StdReturn : 6.305068016052246
Eval_MaxReturn : 950.6387939453125
Eval_MinReturn : 932.7813110351562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 930.5101318359375
Train_StdReturn : 0.0
Train_MaxReturn : 930.5101318359375
Train_MinReturn : 930.5101318359375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 414000
TimeSinceStart : 4707.899190664291
Training Loss : 6.488277722382918e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 415 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.24072265625
Eval_StdReturn : 9.54017448425293
Eval_MaxReturn : 967.0145874023438
Eval_MinReturn : 941.16455078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.0044555664062
Train_StdReturn : 0.0
Train_MaxReturn : 939.0044555664062
Train_MinReturn : 939.0044555664062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 415000
TimeSinceStart : 4722.255145788193
Training Loss : 2.119426972058136e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 416 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.9818115234375
Eval_StdReturn : 15.123271942138672
Eval_MaxReturn : 967.0030517578125
Eval_MinReturn : 926.866455078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.7194213867188
Train_StdReturn : 0.0
Train_MaxReturn : 933.7194213867188
Train_MinReturn : 933.7194213867188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 416000
TimeSinceStart : 4736.99403834343
Training Loss : 0.0011315259616822004
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 417 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.3214721679688
Eval_StdReturn : 4.371267795562744
Eval_MaxReturn : 946.858154296875
Eval_MinReturn : 933.9410400390625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.32373046875
Train_StdReturn : 0.0
Train_MaxReturn : 937.32373046875
Train_MinReturn : 937.32373046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 417000
TimeSinceStart : 4752.02254652977
Training Loss : 0.0005239189486019313
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 418 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.6407470703125
Eval_StdReturn : 11.679500579833984
Eval_MaxReturn : 948.2569580078125
Eval_MinReturn : 920.489013671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.0672607421875
Train_StdReturn : 0.0
Train_MaxReturn : 951.0672607421875
Train_MinReturn : 951.0672607421875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 418000
TimeSinceStart : 4767.450622081757
Training Loss : 0.0004145030688960105
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 419 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 956.2429809570312
Eval_StdReturn : 8.787354469299316
Eval_MaxReturn : 964.9365234375
Eval_MinReturn : 942.2884521484375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.53515625
Train_StdReturn : 0.0
Train_MaxReturn : 937.53515625
Train_MinReturn : 937.53515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 419000
TimeSinceStart : 4782.845714330673
Training Loss : 0.0006594230653718114
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 420 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.6383056640625
Eval_StdReturn : 11.142303466796875
Eval_MaxReturn : 963.9452514648438
Eval_MinReturn : 929.142822265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 927.7899780273438
Train_StdReturn : 0.0
Train_MaxReturn : 927.7899780273438
Train_MinReturn : 927.7899780273438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 420000
TimeSinceStart : 4797.774615764618
Training Loss : 9.100929310079664e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 421 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.7344970703125
Eval_StdReturn : 4.492614269256592
Eval_MaxReturn : 954.2883911132812
Eval_MinReturn : 941.5245971679688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.1666870117188
Train_StdReturn : 0.0
Train_MaxReturn : 938.1666870117188
Train_MinReturn : 938.1666870117188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 421000
TimeSinceStart : 4813.075504779816
Training Loss : 0.00039589821244589984
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 422 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.6156005859375
Eval_StdReturn : 14.052780151367188
Eval_MaxReturn : 956.9646606445312
Eval_MinReturn : 918.376220703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 957.8294677734375
Train_StdReturn : 0.0
Train_MaxReturn : 957.8294677734375
Train_MinReturn : 957.8294677734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 422000
TimeSinceStart : 4828.391020298004
Training Loss : 0.00036226073279976845
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 423 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 935.4597778320312
Eval_StdReturn : 5.86235237121582
Eval_MaxReturn : 941.1766357421875
Eval_MinReturn : 924.7687377929688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.7025146484375
Train_StdReturn : 0.0
Train_MaxReturn : 953.7025146484375
Train_MinReturn : 953.7025146484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 423000
TimeSinceStart : 4843.483167648315
Training Loss : 0.00036918744444847107
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 424 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.9703369140625
Eval_StdReturn : 4.107080936431885
Eval_MaxReturn : 949.50341796875
Eval_MinReturn : 938.1304931640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 964.1478271484375
Train_StdReturn : 0.0
Train_MaxReturn : 964.1478271484375
Train_MinReturn : 964.1478271484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 424000
TimeSinceStart : 4858.622889041901
Training Loss : 2.159084215236362e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 425 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.2681884765625
Eval_StdReturn : 12.951303482055664
Eval_MaxReturn : 971.82666015625
Eval_MinReturn : 932.6707763671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.0296630859375
Train_StdReturn : 0.0
Train_MaxReturn : 951.0296630859375
Train_MinReturn : 951.0296630859375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 425000
TimeSinceStart : 4873.101115942001
Training Loss : 0.00038223693263716996
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 426 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.0374755859375
Eval_StdReturn : 9.715176582336426
Eval_MaxReturn : 960.9152221679688
Eval_MinReturn : 931.474609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.6976318359375
Train_StdReturn : 0.0
Train_MaxReturn : 940.6976318359375
Train_MinReturn : 940.6976318359375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 426000
TimeSinceStart : 4887.658220291138
Training Loss : 0.00043547406676225364
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 427 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.3343505859375
Eval_StdReturn : 12.403097152709961
Eval_MaxReturn : 969.111083984375
Eval_MinReturn : 933.2686767578125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 920.4608154296875
Train_StdReturn : 0.0
Train_MaxReturn : 920.4608154296875
Train_MinReturn : 920.4608154296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 427000
TimeSinceStart : 4901.976431131363
Training Loss : 0.00029422101215459406
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 428 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.0997314453125
Eval_StdReturn : 4.383054256439209
Eval_MaxReturn : 942.7421264648438
Eval_MinReturn : 930.9163818359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.12890625
Train_StdReturn : 0.0
Train_MaxReturn : 946.12890625
Train_MinReturn : 946.12890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 428000
TimeSinceStart : 4916.6821303367615
Training Loss : 8.825022814562544e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 429 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.0921020507812
Eval_StdReturn : 5.3955817222595215
Eval_MaxReturn : 959.4521484375
Eval_MinReturn : 944.046142578125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.29541015625
Train_StdReturn : 0.0
Train_MaxReturn : 955.29541015625
Train_MinReturn : 955.29541015625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 429000
TimeSinceStart : 4931.733161687851
Training Loss : 0.00022554404858965427
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 430 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.9237060546875
Eval_StdReturn : 4.923330783843994
Eval_MaxReturn : 947.22265625
Eval_MinReturn : 933.3400268554688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 962.506591796875
Train_StdReturn : 0.0
Train_MaxReturn : 962.506591796875
Train_MinReturn : 962.506591796875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 430000
TimeSinceStart : 4947.1492512226105
Training Loss : 0.0001578128430992365
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 431 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.9150390625
Eval_StdReturn : 11.21825122833252
Eval_MaxReturn : 969.501953125
Eval_MinReturn : 939.60009765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.143798828125
Train_StdReturn : 0.0
Train_MaxReturn : 935.143798828125
Train_MinReturn : 935.143798828125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 431000
TimeSinceStart : 4962.191797018051
Training Loss : 6.412904622266069e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 432 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.5289916992188
Eval_StdReturn : 8.237622261047363
Eval_MaxReturn : 962.4178466796875
Eval_MinReturn : 938.7272338867188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.63427734375
Train_StdReturn : 0.0
Train_MaxReturn : 952.63427734375
Train_MinReturn : 952.63427734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 432000
TimeSinceStart : 4977.543709516525
Training Loss : 0.0002417307550786063
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 433 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.3092041015625
Eval_StdReturn : 5.162723064422607
Eval_MaxReturn : 942.3919677734375
Eval_MinReturn : 928.396240234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.4970703125
Train_StdReturn : 0.0
Train_MaxReturn : 947.4970703125
Train_MinReturn : 947.4970703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 433000
TimeSinceStart : 4992.799429655075
Training Loss : 0.00026073286426253617
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 434 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.12109375
Eval_StdReturn : 12.094319343566895
Eval_MaxReturn : 953.31298828125
Eval_MinReturn : 920.8778686523438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.01416015625
Train_StdReturn : 0.0
Train_MaxReturn : 952.01416015625
Train_MinReturn : 952.01416015625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 434000
TimeSinceStart : 5008.450931072235
Training Loss : 6.003239468554966e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 435 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 935.3992309570312
Eval_StdReturn : 9.087357521057129
Eval_MaxReturn : 944.92578125
Eval_MinReturn : 920.2810668945312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.9666137695312
Train_StdReturn : 0.0
Train_MaxReturn : 956.9666137695312
Train_MinReturn : 956.9666137695312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 435000
TimeSinceStart : 5023.75542140007
Training Loss : 0.00032817365718074143
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 436 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.4085083007812
Eval_StdReturn : 17.16971778869629
Eval_MaxReturn : 968.3592529296875
Eval_MinReturn : 917.6661376953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.9925537109375
Train_StdReturn : 0.0
Train_MaxReturn : 936.9925537109375
Train_MinReturn : 936.9925537109375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 436000
TimeSinceStart : 5038.919881820679
Training Loss : 0.00029898734646849334
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 437 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.6959838867188
Eval_StdReturn : 17.35408592224121
Eval_MaxReturn : 958.9942626953125
Eval_MinReturn : 909.988037109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.85107421875
Train_StdReturn : 0.0
Train_MaxReturn : 951.85107421875
Train_MinReturn : 951.85107421875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 437000
TimeSinceStart : 5054.466572999954
Training Loss : 0.00022316952527035028
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 438 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.9669799804688
Eval_StdReturn : 6.567288398742676
Eval_MaxReturn : 955.7947387695312
Eval_MinReturn : 936.1026611328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.4237670898438
Train_StdReturn : 0.0
Train_MaxReturn : 935.4237670898438
Train_MinReturn : 935.4237670898438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 438000
TimeSinceStart : 5069.859607934952
Training Loss : 0.00010320459841750562
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 439 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.2555541992188
Eval_StdReturn : 6.084646224975586
Eval_MaxReturn : 948.9681396484375
Eval_MinReturn : 934.5045166015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.4946899414062
Train_StdReturn : 0.0
Train_MaxReturn : 938.4946899414062
Train_MinReturn : 938.4946899414062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 439000
TimeSinceStart : 5085.131055593491
Training Loss : 9.665176912676543e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 440 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.3106689453125
Eval_StdReturn : 3.8124942779541016
Eval_MaxReturn : 954.8123168945312
Eval_MinReturn : 944.423828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.3992919921875
Train_StdReturn : 0.0
Train_MaxReturn : 942.3992919921875
Train_MinReturn : 942.3992919921875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 440000
TimeSinceStart : 5100.01948428154
Training Loss : 0.00010342307359678671
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 441 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 957.72119140625
Eval_StdReturn : 12.479207992553711
Eval_MaxReturn : 973.7418212890625
Eval_MinReturn : 938.4092407226562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.5465087890625
Train_StdReturn : 0.0
Train_MaxReturn : 938.5465087890625
Train_MinReturn : 938.5465087890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 441000
TimeSinceStart : 5115.357491493225
Training Loss : 0.00012338522356003523
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 442 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 934.2369995117188
Eval_StdReturn : 15.19435977935791
Eval_MaxReturn : 956.8892822265625
Eval_MinReturn : 912.2935791015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.6229248046875
Train_StdReturn : 0.0
Train_MaxReturn : 935.6229248046875
Train_MinReturn : 935.6229248046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 442000
TimeSinceStart : 5130.8913424015045
Training Loss : 2.1629899492836557e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 443 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.3287353515625
Eval_StdReturn : 14.59771728515625
Eval_MaxReturn : 966.815673828125
Eval_MinReturn : 923.4558715820312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.2874755859375
Train_StdReturn : 0.0
Train_MaxReturn : 944.2874755859375
Train_MinReturn : 944.2874755859375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 443000
TimeSinceStart : 5146.425338983536
Training Loss : 0.00011277037992840633
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 444 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.7984619140625
Eval_StdReturn : 5.354399681091309
Eval_MaxReturn : 952.3336181640625
Eval_MinReturn : 938.21484375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.775146484375
Train_StdReturn : 0.0
Train_MaxReturn : 941.775146484375
Train_MinReturn : 941.775146484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 444000
TimeSinceStart : 5161.24360871315
Training Loss : 0.0002550646604504436
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 445 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.5641479492188
Eval_StdReturn : 7.295602798461914
Eval_MaxReturn : 955.0933837890625
Eval_MinReturn : 935.8817749023438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 922.3209228515625
Train_StdReturn : 0.0
Train_MaxReturn : 922.3209228515625
Train_MinReturn : 922.3209228515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 445000
TimeSinceStart : 5176.75447845459
Training Loss : 0.0001121036330005154
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 446 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.0753784179688
Eval_StdReturn : 13.312908172607422
Eval_MaxReturn : 966.0220947265625
Eval_MinReturn : 928.53076171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 957.0560302734375
Train_StdReturn : 0.0
Train_MaxReturn : 957.0560302734375
Train_MinReturn : 957.0560302734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 446000
TimeSinceStart : 5192.143347740173
Training Loss : 0.00010327107884222642
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 447 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.7071533203125
Eval_StdReturn : 9.106708526611328
Eval_MaxReturn : 964.2452392578125
Eval_MinReturn : 936.5631103515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 965.5537109375
Train_StdReturn : 0.0
Train_MaxReturn : 965.5537109375
Train_MinReturn : 965.5537109375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 447000
TimeSinceStart : 5207.631738185883
Training Loss : 0.0005158677231520414
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 448 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.80712890625
Eval_StdReturn : 15.713679313659668
Eval_MaxReturn : 962.490478515625
Eval_MinReturn : 926.2012939453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.9430541992188
Train_StdReturn : 0.0
Train_MaxReturn : 951.9430541992188
Train_MinReturn : 951.9430541992188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 448000
TimeSinceStart : 5223.261487483978
Training Loss : 9.034085815073922e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 449 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 931.07275390625
Eval_StdReturn : 16.857717514038086
Eval_MaxReturn : 963.30908203125
Eval_MinReturn : 913.8837890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 929.3419189453125
Train_StdReturn : 0.0
Train_MaxReturn : 929.3419189453125
Train_MinReturn : 929.3419189453125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 449000
TimeSinceStart : 5238.955340623856
Training Loss : 0.0008022384718060493
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 450 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.4557495117188
Eval_StdReturn : 8.275424003601074
Eval_MaxReturn : 948.753173828125
Eval_MinReturn : 923.095947265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.3690795898438
Train_StdReturn : 0.0
Train_MaxReturn : 936.3690795898438
Train_MinReturn : 936.3690795898438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 450000
TimeSinceStart : 5254.363695383072
Training Loss : 0.00036196812288835645
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 451 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.2738037109375
Eval_StdReturn : 14.948637008666992
Eval_MaxReturn : 963.6787109375
Eval_MinReturn : 920.8042602539062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.8291015625
Train_StdReturn : 0.0
Train_MaxReturn : 943.8291015625
Train_MinReturn : 943.8291015625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 451000
TimeSinceStart : 5269.905706882477
Training Loss : 0.00032831047428771853
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 452 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.6653442382812
Eval_StdReturn : 13.744351387023926
Eval_MaxReturn : 961.157470703125
Eval_MinReturn : 927.7374267578125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 957.455322265625
Train_StdReturn : 0.0
Train_MaxReturn : 957.455322265625
Train_MinReturn : 957.455322265625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 452000
TimeSinceStart : 5285.460186958313
Training Loss : 0.0004602057742886245
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 453 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.4093627929688
Eval_StdReturn : 8.673392295837402
Eval_MaxReturn : 955.1807861328125
Eval_MinReturn : 930.6416015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.205810546875
Train_StdReturn : 0.0
Train_MaxReturn : 940.205810546875
Train_MinReturn : 940.205810546875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 453000
TimeSinceStart : 5300.887431144714
Training Loss : 0.00023694483388680965
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 454 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.20849609375
Eval_StdReturn : 7.101330280303955
Eval_MaxReturn : 954.1936645507812
Eval_MinReturn : 935.0685424804688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.39111328125
Train_StdReturn : 0.0
Train_MaxReturn : 940.39111328125
Train_MinReturn : 940.39111328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 454000
TimeSinceStart : 5315.573475599289
Training Loss : 0.0008660635794512928
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 455 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.3709106445312
Eval_StdReturn : 6.541247844696045
Eval_MaxReturn : 947.171142578125
Eval_MinReturn : 928.49365234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.610595703125
Train_StdReturn : 0.0
Train_MaxReturn : 944.610595703125
Train_MinReturn : 944.610595703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 455000
TimeSinceStart : 5331.059695720673
Training Loss : 0.00011111162166344002
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 456 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.181640625
Eval_StdReturn : 3.7504544258117676
Eval_MaxReturn : 952.607177734375
Eval_MinReturn : 942.269775390625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.7357177734375
Train_StdReturn : 0.0
Train_MaxReturn : 948.7357177734375
Train_MinReturn : 948.7357177734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 456000
TimeSinceStart : 5346.328014135361
Training Loss : 0.00012396844977047294
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 457 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.2052001953125
Eval_StdReturn : 14.551069259643555
Eval_MaxReturn : 969.6925659179688
Eval_MinReturn : 928.4277954101562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.6707763671875
Train_StdReturn : 0.0
Train_MaxReturn : 947.6707763671875
Train_MinReturn : 947.6707763671875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 457000
TimeSinceStart : 5362.088502645493
Training Loss : 0.00011403988173697144
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 458 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.0636596679688
Eval_StdReturn : 4.9566779136657715
Eval_MaxReturn : 952.705810546875
Eval_MinReturn : 939.6232299804688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.5836181640625
Train_StdReturn : 0.0
Train_MaxReturn : 948.5836181640625
Train_MinReturn : 948.5836181640625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 458000
TimeSinceStart : 5377.521972894669
Training Loss : 0.00024393980856984854
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 459 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 952.0422973632812
Eval_StdReturn : 12.462420463562012
Eval_MaxReturn : 973.194091796875
Eval_MinReturn : 935.8427124023438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.4534912109375
Train_StdReturn : 0.0
Train_MaxReturn : 948.4534912109375
Train_MinReturn : 948.4534912109375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 459000
TimeSinceStart : 5393.182117938995
Training Loss : 0.0005528123583644629
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 460 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.1058349609375
Eval_StdReturn : 8.27695369720459
Eval_MaxReturn : 956.9957275390625
Eval_MinReturn : 932.9228515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.5625610351562
Train_StdReturn : 0.0
Train_MaxReturn : 935.5625610351562
Train_MinReturn : 935.5625610351562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 460000
TimeSinceStart : 5409.217684030533
Training Loss : 0.0002810877631418407
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 461 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.9710083007812
Eval_StdReturn : 11.28754997253418
Eval_MaxReturn : 970.022216796875
Eval_MinReturn : 936.121826171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 929.33154296875
Train_StdReturn : 0.0
Train_MaxReturn : 929.33154296875
Train_MinReturn : 929.33154296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 461000
TimeSinceStart : 5424.981682777405
Training Loss : 0.0005503853899426758
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 462 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.6480712890625
Eval_StdReturn : 14.114846229553223
Eval_MaxReturn : 957.4281005859375
Eval_MinReturn : 918.36865234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.1682739257812
Train_StdReturn : 0.0
Train_MaxReturn : 933.1682739257812
Train_MinReturn : 933.1682739257812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 462000
TimeSinceStart : 5440.459408283234
Training Loss : 0.00025874286075122654
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 463 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 955.1622314453125
Eval_StdReturn : 6.704494476318359
Eval_MaxReturn : 966.14892578125
Eval_MinReturn : 945.8067626953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.6478271484375
Train_StdReturn : 0.0
Train_MaxReturn : 947.6478271484375
Train_MinReturn : 947.6478271484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 463000
TimeSinceStart : 5456.5771498680115
Training Loss : 0.00044152780901640654
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 464 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.7554931640625
Eval_StdReturn : 9.970239639282227
Eval_MaxReturn : 958.5344848632812
Eval_MinReturn : 927.4073486328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 960.7459716796875
Train_StdReturn : 0.0
Train_MaxReturn : 960.7459716796875
Train_MinReturn : 960.7459716796875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 464000
TimeSinceStart : 5472.653274059296
Training Loss : 0.00018821186677087098
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 465 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.2723388671875
Eval_StdReturn : 10.397490501403809
Eval_MaxReturn : 956.8262939453125
Eval_MinReturn : 926.0264892578125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 962.4591064453125
Train_StdReturn : 0.0
Train_MaxReturn : 962.4591064453125
Train_MinReturn : 962.4591064453125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 465000
TimeSinceStart : 5488.733249425888
Training Loss : 0.0006550227990373969
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 466 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.7340698242188
Eval_StdReturn : 7.472485065460205
Eval_MaxReturn : 956.1913452148438
Eval_MinReturn : 934.48583984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.2822265625
Train_StdReturn : 0.0
Train_MaxReturn : 951.2822265625
Train_MinReturn : 951.2822265625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 466000
TimeSinceStart : 5504.940430164337
Training Loss : 6.139643664937466e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 467 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.9127807617188
Eval_StdReturn : 9.349867820739746
Eval_MaxReturn : 955.4085693359375
Eval_MinReturn : 932.6353149414062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.333251953125
Train_StdReturn : 0.0
Train_MaxReturn : 934.333251953125
Train_MinReturn : 934.333251953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 467000
TimeSinceStart : 5520.900859594345
Training Loss : 0.00026929701562039554
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 468 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.04248046875
Eval_StdReturn : 4.214683532714844
Eval_MaxReturn : 955.819580078125
Eval_MinReturn : 944.3701782226562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.5388793945312
Train_StdReturn : 0.0
Train_MaxReturn : 947.5388793945312
Train_MinReturn : 947.5388793945312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 468000
TimeSinceStart : 5536.721739530563
Training Loss : 0.0002930776390712708
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 469 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.0447387695312
Eval_StdReturn : 6.87321138381958
Eval_MaxReturn : 963.0548706054688
Eval_MinReturn : 943.3182373046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 965.020751953125
Train_StdReturn : 0.0
Train_MaxReturn : 965.020751953125
Train_MinReturn : 965.020751953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 469000
TimeSinceStart : 5552.567982435226
Training Loss : 0.00022281594283413142
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 470 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.2981567382812
Eval_StdReturn : 17.11966896057129
Eval_MaxReturn : 968.9755249023438
Eval_MinReturn : 917.2864990234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.5284423828125
Train_StdReturn : 0.0
Train_MaxReturn : 943.5284423828125
Train_MinReturn : 943.5284423828125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 470000
TimeSinceStart : 5568.620262861252
Training Loss : 3.5808705433737487e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 471 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.4654541015625
Eval_StdReturn : 7.664838790893555
Eval_MaxReturn : 950.739013671875
Eval_MinReturn : 929.4964599609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.8795166015625
Train_StdReturn : 0.0
Train_MaxReturn : 946.8795166015625
Train_MinReturn : 946.8795166015625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 471000
TimeSinceStart : 5584.579346656799
Training Loss : 9.499380394117907e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 472 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.8011474609375
Eval_StdReturn : 6.356979846954346
Eval_MaxReturn : 952.28466796875
Eval_MinReturn : 934.1526489257812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.4609375
Train_StdReturn : 0.0
Train_MaxReturn : 950.4609375
Train_MinReturn : 950.4609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 472000
TimeSinceStart : 5600.633467912674
Training Loss : 0.0004640844417735934
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 473 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.2584228515625
Eval_StdReturn : 10.558426856994629
Eval_MaxReturn : 955.4363403320312
Eval_MinReturn : 924.1961669921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.2666625976562
Train_StdReturn : 0.0
Train_MaxReturn : 935.2666625976562
Train_MinReturn : 935.2666625976562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 473000
TimeSinceStart : 5616.704265356064
Training Loss : 0.00019603002874646336
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 474 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.8529052734375
Eval_StdReturn : 9.566162109375
Eval_MaxReturn : 955.29443359375
Eval_MinReturn : 928.914306640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.9065551757812
Train_StdReturn : 0.0
Train_MaxReturn : 951.9065551757812
Train_MinReturn : 951.9065551757812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 474000
TimeSinceStart : 5632.65096116066
Training Loss : 0.00022421544417738914
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 475 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 955.7362060546875
Eval_StdReturn : 8.882909774780273
Eval_MaxReturn : 967.083740234375
Eval_MinReturn : 939.9909057617188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 961.8438720703125
Train_StdReturn : 0.0
Train_MaxReturn : 961.8438720703125
Train_MinReturn : 961.8438720703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 475000
TimeSinceStart : 5648.536459207535
Training Loss : 5.85310990572907e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 476 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.0827026367188
Eval_StdReturn : 14.002236366271973
Eval_MaxReturn : 962.2310180664062
Eval_MinReturn : 923.7980346679688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.9550170898438
Train_StdReturn : 0.0
Train_MaxReturn : 939.9550170898438
Train_MinReturn : 939.9550170898438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 476000
TimeSinceStart : 5664.534597873688
Training Loss : 3.9472997741540894e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 477 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.8479614257812
Eval_StdReturn : 12.593171119689941
Eval_MaxReturn : 957.0504150390625
Eval_MinReturn : 925.7041015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.8013916015625
Train_StdReturn : 0.0
Train_MaxReturn : 939.8013916015625
Train_MinReturn : 939.8013916015625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 477000
TimeSinceStart : 5680.4132578372955
Training Loss : 0.0007076397305354476
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 478 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.0286865234375
Eval_StdReturn : 5.467278957366943
Eval_MaxReturn : 956.5933837890625
Eval_MinReturn : 941.5098876953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.1417236328125
Train_StdReturn : 0.0
Train_MaxReturn : 958.1417236328125
Train_MinReturn : 958.1417236328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 478000
TimeSinceStart : 5696.666792154312
Training Loss : 0.0002905720903072506
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 479 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.7980346679688
Eval_StdReturn : 11.89881420135498
Eval_MaxReturn : 951.158203125
Eval_MinReturn : 922.8777465820312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.359375
Train_StdReturn : 0.0
Train_MaxReturn : 940.359375
Train_MinReturn : 940.359375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 479000
TimeSinceStart : 5712.447816848755
Training Loss : 0.0003235280164517462
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 480 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 952.5603637695312
Eval_StdReturn : 13.906759262084961
Eval_MaxReturn : 973.104248046875
Eval_MinReturn : 933.580078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 926.8392333984375
Train_StdReturn : 0.0
Train_MaxReturn : 926.8392333984375
Train_MinReturn : 926.8392333984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 480000
TimeSinceStart : 5728.386731863022
Training Loss : 0.00023293911362998188
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 481 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.0022583007812
Eval_StdReturn : 6.9607110023498535
Eval_MaxReturn : 945.909423828125
Eval_MinReturn : 925.1610107421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.4901733398438
Train_StdReturn : 0.0
Train_MaxReturn : 936.4901733398438
Train_MinReturn : 936.4901733398438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 481000
TimeSinceStart : 5744.28511929512
Training Loss : 0.0005835270858369768
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 482 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.1920166015625
Eval_StdReturn : 9.231161117553711
Eval_MaxReturn : 961.0743408203125
Eval_MinReturn : 935.9891967773438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.1263427734375
Train_StdReturn : 0.0
Train_MaxReturn : 943.1263427734375
Train_MinReturn : 943.1263427734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 482000
TimeSinceStart : 5760.360132932663
Training Loss : 0.00017264726920984685
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 483 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.7942504882812
Eval_StdReturn : 5.229804992675781
Eval_MaxReturn : 955.7053833007812
Eval_MinReturn : 940.8057861328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.642578125
Train_StdReturn : 0.0
Train_MaxReturn : 938.642578125
Train_MinReturn : 938.642578125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 483000
TimeSinceStart : 5776.848752975464
Training Loss : 0.00048421829706057906
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 484 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.9830322265625
Eval_StdReturn : 15.281173706054688
Eval_MaxReturn : 968.2767333984375
Eval_MinReturn : 925.2020874023438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.9255981445312
Train_StdReturn : 0.0
Train_MaxReturn : 937.9255981445312
Train_MinReturn : 937.9255981445312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 484000
TimeSinceStart : 5792.8991532325745
Training Loss : 0.00011683149205055088
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 485 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 954.3128051757812
Eval_StdReturn : 6.967512130737305
Eval_MaxReturn : 962.0831298828125
Eval_MinReturn : 944.6214599609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.0777587890625
Train_StdReturn : 0.0
Train_MaxReturn : 935.0777587890625
Train_MinReturn : 935.0777587890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 485000
TimeSinceStart : 5809.003755569458
Training Loss : 0.000643460953142494
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 486 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.8695068359375
Eval_StdReturn : 9.143718719482422
Eval_MaxReturn : 961.438720703125
Eval_MinReturn : 936.8953857421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.3468017578125
Train_StdReturn : 0.0
Train_MaxReturn : 944.3468017578125
Train_MinReturn : 944.3468017578125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 486000
TimeSinceStart : 5824.755820512772
Training Loss : 3.8312322431011125e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 487 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.9138793945312
Eval_StdReturn : 11.525040626525879
Eval_MaxReturn : 960.4888305664062
Eval_MinReturn : 927.398681640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.2671508789062
Train_StdReturn : 0.0
Train_MaxReturn : 952.2671508789062
Train_MinReturn : 952.2671508789062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 487000
TimeSinceStart : 5841.173214197159
Training Loss : 0.00028488165116868913
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 488 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.37890625
Eval_StdReturn : 15.456576347351074
Eval_MaxReturn : 964.0706787109375
Eval_MinReturn : 929.895751953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 928.6857299804688
Train_StdReturn : 0.0
Train_MaxReturn : 928.6857299804688
Train_MinReturn : 928.6857299804688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 488000
TimeSinceStart : 5856.770433664322
Training Loss : 0.00011913398338947445
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 489 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.9826049804688
Eval_StdReturn : 8.621728897094727
Eval_MaxReturn : 949.9804077148438
Eval_MinReturn : 925.6937255859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 960.86669921875
Train_StdReturn : 0.0
Train_MaxReturn : 960.86669921875
Train_MinReturn : 960.86669921875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 489000
TimeSinceStart : 5872.674399852753
Training Loss : 0.00016040069749578834
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 490 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 934.1359252929688
Eval_StdReturn : 13.515539169311523
Eval_MaxReturn : 946.5110473632812
Eval_MinReturn : 909.6166381835938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 924.7760009765625
Train_StdReturn : 0.0
Train_MaxReturn : 924.7760009765625
Train_MinReturn : 924.7760009765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 490000
TimeSinceStart : 5888.2556483745575
Training Loss : 0.00016010757826734334
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 491 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.7388916015625
Eval_StdReturn : 4.024384498596191
Eval_MaxReturn : 945.5308837890625
Eval_MinReturn : 934.11376953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.9951782226562
Train_StdReturn : 0.0
Train_MaxReturn : 940.9951782226562
Train_MinReturn : 940.9951782226562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 491000
TimeSinceStart : 5904.437474966049
Training Loss : 0.000348646251950413
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 492 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.119140625
Eval_StdReturn : 5.26649284362793
Eval_MaxReturn : 946.49560546875
Eval_MinReturn : 931.137939453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.5106201171875
Train_StdReturn : 0.0
Train_MaxReturn : 944.5106201171875
Train_MinReturn : 944.5106201171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 492000
TimeSinceStart : 5920.57902598381
Training Loss : 0.00033480956335552037
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 493 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 934.8282470703125
Eval_StdReturn : 11.986567497253418
Eval_MaxReturn : 946.587890625
Eval_MinReturn : 917.1976318359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.8091430664062
Train_StdReturn : 0.0
Train_MaxReturn : 950.8091430664062
Train_MinReturn : 950.8091430664062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 493000
TimeSinceStart : 5937.076613664627
Training Loss : 0.00027742190286517143
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 494 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.9650268554688
Eval_StdReturn : 5.10562801361084
Eval_MaxReturn : 953.5918579101562
Eval_MinReturn : 938.581787109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 923.919677734375
Train_StdReturn : 0.0
Train_MaxReturn : 923.919677734375
Train_MinReturn : 923.919677734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 494000
TimeSinceStart : 5953.539208650589
Training Loss : 0.00024132370890583843
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 495 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.71484375
Eval_StdReturn : 10.717952728271484
Eval_MaxReturn : 957.943115234375
Eval_MinReturn : 930.4857177734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.9053955078125
Train_StdReturn : 0.0
Train_MaxReturn : 955.9053955078125
Train_MinReturn : 955.9053955078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 495000
TimeSinceStart : 5969.870560884476
Training Loss : 0.00014234658738132566
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 496 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 935.3131103515625
Eval_StdReturn : 7.458075046539307
Eval_MaxReturn : 943.955078125
Eval_MinReturn : 924.0428466796875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.4447021484375
Train_StdReturn : 0.0
Train_MaxReturn : 934.4447021484375
Train_MinReturn : 934.4447021484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 496000
TimeSinceStart : 5986.1876475811005
Training Loss : 0.00035204007872380316
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 497 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.802734375
Eval_StdReturn : 8.005270004272461
Eval_MaxReturn : 953.2403564453125
Eval_MinReturn : 931.3261108398438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.9658203125
Train_StdReturn : 0.0
Train_MaxReturn : 935.9658203125
Train_MinReturn : 935.9658203125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 497000
TimeSinceStart : 6002.214612483978
Training Loss : 0.0001391203550156206
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 498 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.6575927734375
Eval_StdReturn : 9.946870803833008
Eval_MaxReturn : 951.7023315429688
Eval_MinReturn : 924.6774291992188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 926.956298828125
Train_StdReturn : 0.0
Train_MaxReturn : 926.956298828125
Train_MinReturn : 926.956298828125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 498000
TimeSinceStart : 6017.970568418503
Training Loss : 0.00011493826605146751
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 499 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.896484375
Eval_StdReturn : 13.150753021240234
Eval_MaxReturn : 970.8778076171875
Eval_MinReturn : 931.3870849609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 918.737060546875
Train_StdReturn : 0.0
Train_MaxReturn : 918.737060546875
Train_MinReturn : 918.737060546875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 499000
TimeSinceStart : 6033.446510314941
Training Loss : 0.00028362913872115314
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 500 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 930.2967529296875
Eval_StdReturn : 15.040558815002441
Eval_MaxReturn : 948.4744873046875
Eval_MinReturn : 909.8018798828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.4024658203125
Train_StdReturn : 0.0
Train_MaxReturn : 951.4024658203125
Train_MinReturn : 951.4024658203125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 500000
TimeSinceStart : 6049.778348445892
Training Loss : 0.00029851129511371255
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 501 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.3836059570312
Eval_StdReturn : 6.002026081085205
Eval_MaxReturn : 944.7498168945312
Eval_MinReturn : 927.9519653320312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.0036010742188
Train_StdReturn : 0.0
Train_MaxReturn : 958.0036010742188
Train_MinReturn : 958.0036010742188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 501000
TimeSinceStart : 6066.0241522789
Training Loss : 0.0005160821019671857
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 502 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 935.8099365234375
Eval_StdReturn : 11.584525108337402
Eval_MaxReturn : 948.836669921875
Eval_MinReturn : 914.5155029296875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.2996215820312
Train_StdReturn : 0.0
Train_MaxReturn : 948.2996215820312
Train_MinReturn : 948.2996215820312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 502000
TimeSinceStart : 6082.487549543381
Training Loss : 0.0004734085814561695
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 503 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.2565307617188
Eval_StdReturn : 4.877261638641357
Eval_MaxReturn : 957.4536743164062
Eval_MinReturn : 943.4136352539062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.2059326171875
Train_StdReturn : 0.0
Train_MaxReturn : 951.2059326171875
Train_MinReturn : 951.2059326171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 503000
TimeSinceStart : 6098.551003217697
Training Loss : 0.00021905728499405086
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 504 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.4152221679688
Eval_StdReturn : 5.602620601654053
Eval_MaxReturn : 953.9166259765625
Eval_MinReturn : 937.9146118164062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.421142578125
Train_StdReturn : 0.0
Train_MaxReturn : 937.421142578125
Train_MinReturn : 937.421142578125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 504000
TimeSinceStart : 6114.792484760284
Training Loss : 0.0008662889595143497
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 505 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.0755615234375
Eval_StdReturn : 13.530691146850586
Eval_MaxReturn : 950.0953979492188
Eval_MinReturn : 914.2581787109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.4382934570312
Train_StdReturn : 0.0
Train_MaxReturn : 947.4382934570312
Train_MinReturn : 947.4382934570312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 505000
TimeSinceStart : 6131.505346536636
Training Loss : 0.0003214296593796462
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 506 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 954.7771606445312
Eval_StdReturn : 14.519529342651367
Eval_MaxReturn : 973.95751953125
Eval_MinReturn : 935.0759887695312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.2442626953125
Train_StdReturn : 0.0
Train_MaxReturn : 954.2442626953125
Train_MinReturn : 954.2442626953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 506000
TimeSinceStart : 6147.596978664398
Training Loss : 0.00027745586703531444
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 507 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.5748291015625
Eval_StdReturn : 10.882349014282227
Eval_MaxReturn : 957.665771484375
Eval_MinReturn : 927.802001953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.857666015625
Train_StdReturn : 0.0
Train_MaxReturn : 934.857666015625
Train_MinReturn : 934.857666015625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 507000
TimeSinceStart : 6163.682543754578
Training Loss : 9.607138781575486e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 508 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.5084838867188
Eval_StdReturn : 11.983538627624512
Eval_MaxReturn : 966.5731201171875
Eval_MinReturn : 934.122802734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.0924072265625
Train_StdReturn : 0.0
Train_MaxReturn : 937.0924072265625
Train_MinReturn : 937.0924072265625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 508000
TimeSinceStart : 6180.199764966965
Training Loss : 0.0003526080399751663
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 509 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.5320434570312
Eval_StdReturn : 6.6956000328063965
Eval_MaxReturn : 955.6314697265625
Eval_MinReturn : 939.7869873046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.020751953125
Train_StdReturn : 0.0
Train_MaxReturn : 948.020751953125
Train_MinReturn : 948.020751953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 509000
TimeSinceStart : 6196.687221288681
Training Loss : 0.00018739537335932255
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 510 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 933.984375
Eval_StdReturn : 13.659066200256348
Eval_MaxReturn : 946.6160278320312
Eval_MinReturn : 909.2625732421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.688232421875
Train_StdReturn : 0.0
Train_MaxReturn : 940.688232421875
Train_MinReturn : 940.688232421875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 510000
TimeSinceStart : 6213.005711317062
Training Loss : 0.000408646825235337
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 511 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.8111572265625
Eval_StdReturn : 14.775896072387695
Eval_MaxReturn : 959.607666015625
Eval_MinReturn : 917.6497802734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.332763671875
Train_StdReturn : 0.0
Train_MaxReturn : 946.332763671875
Train_MinReturn : 946.332763671875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 511000
TimeSinceStart : 6229.076725959778
Training Loss : 7.49816172174178e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 512 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 927.9063720703125
Eval_StdReturn : 7.776386737823486
Eval_MaxReturn : 936.9051513671875
Eval_MinReturn : 915.080078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.6563110351562
Train_StdReturn : 0.0
Train_MaxReturn : 949.6563110351562
Train_MinReturn : 949.6563110351562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 512000
TimeSinceStart : 6245.250270605087
Training Loss : 0.0001999455998884514
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 513 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.9542846679688
Eval_StdReturn : 6.233129024505615
Eval_MaxReturn : 951.8748779296875
Eval_MinReturn : 933.222900390625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.1719360351562
Train_StdReturn : 0.0
Train_MaxReturn : 940.1719360351562
Train_MinReturn : 940.1719360351562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 513000
TimeSinceStart : 6261.614716291428
Training Loss : 0.00023025750124361366
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 514 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.58544921875
Eval_StdReturn : 13.834147453308105
Eval_MaxReturn : 964.6019287109375
Eval_MinReturn : 924.208740234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 929.6842041015625
Train_StdReturn : 0.0
Train_MaxReturn : 929.6842041015625
Train_MinReturn : 929.6842041015625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 514000
TimeSinceStart : 6277.925484895706
Training Loss : 0.00014884892152622342
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 515 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.9830322265625
Eval_StdReturn : 7.063717842102051
Eval_MaxReturn : 954.7371826171875
Eval_MinReturn : 934.23291015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.408203125
Train_StdReturn : 0.0
Train_MaxReturn : 941.408203125
Train_MinReturn : 941.408203125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 515000
TimeSinceStart : 6294.291642904282
Training Loss : 0.00019803836767096072
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 516 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.5023193359375
Eval_StdReturn : 6.267221927642822
Eval_MaxReturn : 957.420166015625
Eval_MinReturn : 940.3638916015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.6627807617188
Train_StdReturn : 0.0
Train_MaxReturn : 955.6627807617188
Train_MinReturn : 955.6627807617188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 516000
TimeSinceStart : 6311.661861419678
Training Loss : 0.0007058922201395035
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 517 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.4509887695312
Eval_StdReturn : 11.518439292907715
Eval_MaxReturn : 961.6038818359375
Eval_MinReturn : 933.3157958984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.451904296875
Train_StdReturn : 0.0
Train_MaxReturn : 941.451904296875
Train_MinReturn : 941.451904296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 517000
TimeSinceStart : 6328.199109792709
Training Loss : 0.00012313674960751086
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 518 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 952.2696533203125
Eval_StdReturn : 15.114065170288086
Eval_MaxReturn : 967.5970458984375
Eval_MinReturn : 932.4586181640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.64599609375
Train_StdReturn : 0.0
Train_MaxReturn : 945.64599609375
Train_MinReturn : 945.64599609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 518000
TimeSinceStart : 6344.752177476883
Training Loss : 0.0004944441025145352
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 519 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.7481689453125
Eval_StdReturn : 10.005200386047363
Eval_MaxReturn : 952.7506103515625
Eval_MinReturn : 926.0170288085938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.483154296875
Train_StdReturn : 0.0
Train_MaxReturn : 949.483154296875
Train_MinReturn : 949.483154296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 519000
TimeSinceStart : 6361.765849351883
Training Loss : 0.00022130373690743
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 520 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.5681762695312
Eval_StdReturn : 13.184577941894531
Eval_MaxReturn : 958.56201171875
Eval_MinReturn : 922.369140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 963.9129638671875
Train_StdReturn : 0.0
Train_MaxReturn : 963.9129638671875
Train_MinReturn : 963.9129638671875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 520000
TimeSinceStart : 6378.195758104324
Training Loss : 0.0002824795083142817
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 521 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.9528198242188
Eval_StdReturn : 6.949231147766113
Eval_MaxReturn : 956.724609375
Eval_MinReturn : 937.2769165039062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.837158203125
Train_StdReturn : 0.0
Train_MaxReturn : 935.837158203125
Train_MinReturn : 935.837158203125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 521000
TimeSinceStart : 6394.668286085129
Training Loss : 0.0002397378848399967
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 522 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.4244995117188
Eval_StdReturn : 18.2902774810791
Eval_MaxReturn : 971.6282958984375
Eval_MinReturn : 915.0411987304688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.0034790039062
Train_StdReturn : 0.0
Train_MaxReturn : 950.0034790039062
Train_MinReturn : 950.0034790039062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 522000
TimeSinceStart : 6411.106786727905
Training Loss : 8.023667032830417e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 523 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.6993408203125
Eval_StdReturn : 5.887717247009277
Eval_MaxReturn : 957.51318359375
Eval_MinReturn : 939.5617065429688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.1739501953125
Train_StdReturn : 0.0
Train_MaxReturn : 958.1739501953125
Train_MinReturn : 958.1739501953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 523000
TimeSinceStart : 6427.5747673511505
Training Loss : 7.307990017579868e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 524 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.4509887695312
Eval_StdReturn : 2.4111344814300537
Eval_MaxReturn : 953.2620239257812
Eval_MinReturn : 945.92822265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.1559448242188
Train_StdReturn : 0.0
Train_MaxReturn : 936.1559448242188
Train_MinReturn : 936.1559448242188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 524000
TimeSinceStart : 6444.258690357208
Training Loss : 0.00018865703896153718
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 525 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.541015625
Eval_StdReturn : 2.706650972366333
Eval_MaxReturn : 951.1596069335938
Eval_MinReturn : 943.65869140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 924.0458984375
Train_StdReturn : 0.0
Train_MaxReturn : 924.0458984375
Train_MinReturn : 924.0458984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 525000
TimeSinceStart : 6460.8429844379425
Training Loss : 0.0005025120335631073
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 526 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.9544677734375
Eval_StdReturn : 2.3490729331970215
Eval_MaxReturn : 946.74169921875
Eval_MinReturn : 939.6224365234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.4176025390625
Train_StdReturn : 0.0
Train_MaxReturn : 943.4176025390625
Train_MinReturn : 943.4176025390625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 526000
TimeSinceStart : 6477.582440853119
Training Loss : 0.00018951683887280524
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 527 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 953.8082275390625
Eval_StdReturn : 4.216117858886719
Eval_MaxReturn : 961.0557250976562
Eval_MinReturn : 948.3662109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.02490234375
Train_StdReturn : 0.0
Train_MaxReturn : 943.02490234375
Train_MinReturn : 943.02490234375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 527000
TimeSinceStart : 6494.299223899841
Training Loss : 6.769539322704077e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 528 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.6404418945312
Eval_StdReturn : 13.958626747131348
Eval_MaxReturn : 960.724609375
Eval_MinReturn : 926.3052978515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.0247192382812
Train_StdReturn : 0.0
Train_MaxReturn : 950.0247192382812
Train_MinReturn : 950.0247192382812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 528000
TimeSinceStart : 6510.973938941956
Training Loss : 3.410998760955408e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 529 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.5831909179688
Eval_StdReturn : 8.333362579345703
Eval_MaxReturn : 948.3350830078125
Eval_MinReturn : 924.0962524414062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.956787109375
Train_StdReturn : 0.0
Train_MaxReturn : 944.956787109375
Train_MinReturn : 944.956787109375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 529000
TimeSinceStart : 6527.6379935741425
Training Loss : 0.0004118248471058905
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 530 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.7696533203125
Eval_StdReturn : 10.165966987609863
Eval_MaxReturn : 957.269775390625
Eval_MinReturn : 929.4219970703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.34619140625
Train_StdReturn : 0.0
Train_MaxReturn : 942.34619140625
Train_MinReturn : 942.34619140625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 530000
TimeSinceStart : 6544.640206336975
Training Loss : 0.00022549665300175548
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 531 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.2942504882812
Eval_StdReturn : 11.370943069458008
Eval_MaxReturn : 952.8126831054688
Eval_MinReturn : 922.2967529296875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 925.505126953125
Train_StdReturn : 0.0
Train_MaxReturn : 925.505126953125
Train_MinReturn : 925.505126953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 531000
TimeSinceStart : 6561.70111823082
Training Loss : 0.000290780357317999
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 532 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 933.603515625
Eval_StdReturn : 12.087695121765137
Eval_MaxReturn : 947.91943359375
Eval_MinReturn : 919.7135620117188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 930.2801513671875
Train_StdReturn : 0.0
Train_MaxReturn : 930.2801513671875
Train_MinReturn : 930.2801513671875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 532000
TimeSinceStart : 6579.226539850235
Training Loss : 0.00020189712813589722
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 533 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.4732666015625
Eval_StdReturn : 9.031785011291504
Eval_MaxReturn : 967.04541015625
Eval_MinReturn : 939.6544189453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.4863891601562
Train_StdReturn : 0.0
Train_MaxReturn : 949.4863891601562
Train_MinReturn : 949.4863891601562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 533000
TimeSinceStart : 6596.013021945953
Training Loss : 0.0003365304146427661
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 534 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.2757568359375
Eval_StdReturn : 13.122190475463867
Eval_MaxReturn : 955.5809326171875
Eval_MinReturn : 916.5752563476562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.1453247070312
Train_StdReturn : 0.0
Train_MaxReturn : 942.1453247070312
Train_MinReturn : 942.1453247070312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 534000
TimeSinceStart : 6613.082356452942
Training Loss : 0.0003561530611477792
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 535 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.4235229492188
Eval_StdReturn : 4.342382431030273
Eval_MaxReturn : 949.5218505859375
Eval_MinReturn : 937.1701049804688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.497802734375
Train_StdReturn : 0.0
Train_MaxReturn : 948.497802734375
Train_MinReturn : 948.497802734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 535000
TimeSinceStart : 6630.203377246857
Training Loss : 3.1740877602715045e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 536 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.41748046875
Eval_StdReturn : 15.942869186401367
Eval_MaxReturn : 954.4893798828125
Eval_MinReturn : 910.0416259765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.87451171875
Train_StdReturn : 0.0
Train_MaxReturn : 933.87451171875
Train_MinReturn : 933.87451171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 536000
TimeSinceStart : 6646.506111383438
Training Loss : 0.00019470605184324086
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 537 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.92626953125
Eval_StdReturn : 10.416223526000977
Eval_MaxReturn : 960.8416748046875
Eval_MinReturn : 932.0043334960938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 965.5153198242188
Train_StdReturn : 0.0
Train_MaxReturn : 965.5153198242188
Train_MinReturn : 965.5153198242188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 537000
TimeSinceStart : 6663.247001409531
Training Loss : 0.0003929506056010723
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 538 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.8814697265625
Eval_StdReturn : 10.151472091674805
Eval_MaxReturn : 956.7257690429688
Eval_MinReturn : 929.502197265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.869140625
Train_StdReturn : 0.0
Train_MaxReturn : 939.869140625
Train_MinReturn : 939.869140625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 538000
TimeSinceStart : 6680.10634303093
Training Loss : 0.0002613483229652047
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 539 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 932.73291015625
Eval_StdReturn : 6.564755439758301
Eval_MaxReturn : 940.2319946289062
Eval_MinReturn : 920.7283935546875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.796630859375
Train_StdReturn : 0.0
Train_MaxReturn : 949.796630859375
Train_MinReturn : 949.796630859375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 539000
TimeSinceStart : 6697.240869522095
Training Loss : 0.00023391017748508602
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 540 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.3411865234375
Eval_StdReturn : 5.109104156494141
Eval_MaxReturn : 951.0135498046875
Eval_MinReturn : 937.8126220703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.2181396484375
Train_StdReturn : 0.0
Train_MaxReturn : 958.2181396484375
Train_MinReturn : 958.2181396484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 540000
TimeSinceStart : 6714.33430480957
Training Loss : 0.00011272479605395347
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 541 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 959.2434692382812
Eval_StdReturn : 8.856285095214844
Eval_MaxReturn : 971.815673828125
Eval_MinReturn : 947.828369140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 962.365966796875
Train_StdReturn : 0.0
Train_MaxReturn : 962.365966796875
Train_MinReturn : 962.365966796875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 541000
TimeSinceStart : 6730.5466685295105
Training Loss : 0.00046857050620019436
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 542 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.1131591796875
Eval_StdReturn : 7.140803813934326
Eval_MaxReturn : 948.1423950195312
Eval_MinReturn : 931.4581298828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 959.7332763671875
Train_StdReturn : 0.0
Train_MaxReturn : 959.7332763671875
Train_MinReturn : 959.7332763671875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 542000
TimeSinceStart : 6746.72700214386
Training Loss : 4.936395271215588e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 543 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.8970947265625
Eval_StdReturn : 8.35831356048584
Eval_MaxReturn : 949.920166015625
Eval_MinReturn : 926.055419921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 959.429931640625
Train_StdReturn : 0.0
Train_MaxReturn : 959.429931640625
Train_MinReturn : 959.429931640625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 543000
TimeSinceStart : 6762.89159321785
Training Loss : 0.0004021544009447098
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 544 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.5263671875
Eval_StdReturn : 4.811745643615723
Eval_MaxReturn : 945.2784423828125
Eval_MinReturn : 932.0537109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.3759765625
Train_StdReturn : 0.0
Train_MaxReturn : 936.3759765625
Train_MinReturn : 936.3759765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 544000
TimeSinceStart : 6779.326813459396
Training Loss : 0.0005060550174675882
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 545 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 934.4434814453125
Eval_StdReturn : 16.40894317626953
Eval_MaxReturn : 961.445068359375
Eval_MinReturn : 917.7269287109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.5828247070312
Train_StdReturn : 0.0
Train_MaxReturn : 941.5828247070312
Train_MinReturn : 941.5828247070312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 545000
TimeSinceStart : 6796.611699342728
Training Loss : 0.00022751695360057056
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 546 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.251953125
Eval_StdReturn : 7.997232437133789
Eval_MaxReturn : 954.1812744140625
Eval_MinReturn : 933.6935424804688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 921.0091552734375
Train_StdReturn : 0.0
Train_MaxReturn : 921.0091552734375
Train_MinReturn : 921.0091552734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 546000
TimeSinceStart : 6813.974888563156
Training Loss : 9.226206748280674e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 547 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 931.5037231445312
Eval_StdReturn : 7.769134044647217
Eval_MaxReturn : 945.6558837890625
Eval_MinReturn : 923.015380859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.1798095703125
Train_StdReturn : 0.0
Train_MaxReturn : 941.1798095703125
Train_MinReturn : 941.1798095703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 547000
TimeSinceStart : 6830.625621557236
Training Loss : 0.0005584591417573392
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 548 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.5452270507812
Eval_StdReturn : 7.917593479156494
Eval_MaxReturn : 954.0953369140625
Eval_MinReturn : 931.7108154296875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.2489624023438
Train_StdReturn : 0.0
Train_MaxReturn : 941.2489624023438
Train_MinReturn : 941.2489624023438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 548000
TimeSinceStart : 6847.946943998337
Training Loss : 6.925489287823439e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 549 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.9180908203125
Eval_StdReturn : 5.436756610870361
Eval_MaxReturn : 950.554931640625
Eval_MinReturn : 935.0042724609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.28857421875
Train_StdReturn : 0.0
Train_MaxReturn : 956.28857421875
Train_MinReturn : 956.28857421875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 549000
TimeSinceStart : 6865.143423080444
Training Loss : 0.000284887122688815
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 550 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.08544921875
Eval_StdReturn : 12.379695892333984
Eval_MaxReturn : 964.7117919921875
Eval_MinReturn : 934.9083251953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 924.2677001953125
Train_StdReturn : 0.0
Train_MaxReturn : 924.2677001953125
Train_MinReturn : 924.2677001953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 550000
TimeSinceStart : 6882.040613412857
Training Loss : 0.00018931915110442787
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 551 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.8841552734375
Eval_StdReturn : 15.42785358428955
Eval_MaxReturn : 965.6858520507812
Eval_MinReturn : 924.6082763671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 967.2249755859375
Train_StdReturn : 0.0
Train_MaxReturn : 967.2249755859375
Train_MinReturn : 967.2249755859375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 551000
TimeSinceStart : 6899.230332374573
Training Loss : 0.0003762338310480118
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 552 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.9761962890625
Eval_StdReturn : 6.872081279754639
Eval_MaxReturn : 955.7696533203125
Eval_MinReturn : 937.057861328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 928.0541381835938
Train_StdReturn : 0.0
Train_MaxReturn : 928.0541381835938
Train_MinReturn : 928.0541381835938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 552000
TimeSinceStart : 6916.89044547081
Training Loss : 0.00013785083137918264
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 553 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.5670166015625
Eval_StdReturn : 7.35048770904541
Eval_MaxReturn : 953.95166015625
Eval_MinReturn : 934.23095703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.5682373046875
Train_StdReturn : 0.0
Train_MaxReturn : 958.5682373046875
Train_MinReturn : 958.5682373046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 553000
TimeSinceStart : 6934.318702220917
Training Loss : 0.00019442861957941204
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 554 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.4534912109375
Eval_StdReturn : 11.33072280883789
Eval_MaxReturn : 967.98291015625
Eval_MinReturn : 938.59033203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.2030029296875
Train_StdReturn : 0.0
Train_MaxReturn : 948.2030029296875
Train_MinReturn : 948.2030029296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 554000
TimeSinceStart : 6950.786033630371
Training Loss : 0.0001608048187335953
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 555 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 956.0036010742188
Eval_StdReturn : 8.175764083862305
Eval_MaxReturn : 970.888671875
Eval_MinReturn : 947.8046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.8821411132812
Train_StdReturn : 0.0
Train_MaxReturn : 946.8821411132812
Train_MinReturn : 946.8821411132812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 555000
TimeSinceStart : 6967.824104070663
Training Loss : 0.00018246847321279347
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 556 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.1242065429688
Eval_StdReturn : 9.372106552124023
Eval_MaxReturn : 952.6975708007812
Eval_MinReturn : 927.7595825195312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.122802734375
Train_StdReturn : 0.0
Train_MaxReturn : 941.122802734375
Train_MinReturn : 941.122802734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 556000
TimeSinceStart : 6985.084194421768
Training Loss : 0.00010293677041772753
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 557 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.6121826171875
Eval_StdReturn : 8.378052711486816
Eval_MaxReturn : 953.472900390625
Eval_MinReturn : 932.9653930664062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.2764892578125
Train_StdReturn : 0.0
Train_MaxReturn : 947.2764892578125
Train_MinReturn : 947.2764892578125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 557000
TimeSinceStart : 7002.1970064640045
Training Loss : 0.0002116555260727182
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 558 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.9481201171875
Eval_StdReturn : 10.308443069458008
Eval_MaxReturn : 967.6658325195312
Eval_MinReturn : 939.0987548828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.3502197265625
Train_StdReturn : 0.0
Train_MaxReturn : 933.3502197265625
Train_MinReturn : 933.3502197265625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 558000
TimeSinceStart : 7019.894789457321
Training Loss : 0.0004054891469422728
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 559 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.0338134765625
Eval_StdReturn : 11.041325569152832
Eval_MaxReturn : 954.888916015625
Eval_MinReturn : 926.439208984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 924.339111328125
Train_StdReturn : 0.0
Train_MaxReturn : 924.339111328125
Train_MinReturn : 924.339111328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 559000
TimeSinceStart : 7037.459594964981
Training Loss : 4.784365955856629e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 560 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 954.58837890625
Eval_StdReturn : 10.045047760009766
Eval_MaxReturn : 968.4013671875
Eval_MinReturn : 937.9935302734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.4512329101562
Train_StdReturn : 0.0
Train_MaxReturn : 951.4512329101562
Train_MinReturn : 951.4512329101562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 560000
TimeSinceStart : 7055.575009584427
Training Loss : 0.0004484571691136807
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 561 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.7269287109375
Eval_StdReturn : 6.348918437957764
Eval_MaxReturn : 951.4417724609375
Eval_MinReturn : 935.425048828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.09765625
Train_StdReturn : 0.0
Train_MaxReturn : 952.09765625
Train_MinReturn : 952.09765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 561000
TimeSinceStart : 7073.278668880463
Training Loss : 5.2369734476087615e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 562 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.8757934570312
Eval_StdReturn : 15.051539421081543
Eval_MaxReturn : 964.1182250976562
Eval_MinReturn : 921.891845703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.4302978515625
Train_StdReturn : 0.0
Train_MaxReturn : 939.4302978515625
Train_MinReturn : 939.4302978515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 562000
TimeSinceStart : 7090.782655954361
Training Loss : 0.00041469099232926965
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 563 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 934.9161987304688
Eval_StdReturn : 11.874892234802246
Eval_MaxReturn : 946.805908203125
Eval_MinReturn : 914.1436157226562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.653076171875
Train_StdReturn : 0.0
Train_MaxReturn : 953.653076171875
Train_MinReturn : 953.653076171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 563000
TimeSinceStart : 7108.519763946533
Training Loss : 0.00024581325124017894
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 564 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.1633911132812
Eval_StdReturn : 14.406184196472168
Eval_MaxReturn : 959.4530029296875
Eval_MinReturn : 923.7757568359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 961.85205078125
Train_StdReturn : 0.0
Train_MaxReturn : 961.85205078125
Train_MinReturn : 961.85205078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 564000
TimeSinceStart : 7126.759765386581
Training Loss : 9.231013973476365e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 565 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.8631591796875
Eval_StdReturn : 12.867636680603027
Eval_MaxReturn : 966.0526123046875
Eval_MinReturn : 930.6814575195312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.0189208984375
Train_StdReturn : 0.0
Train_MaxReturn : 958.0189208984375
Train_MinReturn : 958.0189208984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 565000
TimeSinceStart : 7144.667300224304
Training Loss : 0.00025541719514876604
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 566 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.8761596679688
Eval_StdReturn : 9.209911346435547
Eval_MaxReturn : 960.5028686523438
Eval_MinReturn : 932.9573974609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 957.4989013671875
Train_StdReturn : 0.0
Train_MaxReturn : 957.4989013671875
Train_MinReturn : 957.4989013671875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 566000
TimeSinceStart : 7162.708221197128
Training Loss : 0.000162566575454548
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 567 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.6726684570312
Eval_StdReturn : 13.000929832458496
Eval_MaxReturn : 954.6644897460938
Eval_MinReturn : 917.6724853515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.89306640625
Train_StdReturn : 0.0
Train_MaxReturn : 933.89306640625
Train_MinReturn : 933.89306640625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 567000
TimeSinceStart : 7180.89613032341
Training Loss : 1.8786031432682648e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 568 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.0109252929688
Eval_StdReturn : 8.916207313537598
Eval_MaxReturn : 953.648193359375
Eval_MinReturn : 930.166259765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.6616821289062
Train_StdReturn : 0.0
Train_MaxReturn : 952.6616821289062
Train_MinReturn : 952.6616821289062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 568000
TimeSinceStart : 7198.758763551712
Training Loss : 0.00012372256605885923
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 569 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.3419799804688
Eval_StdReturn : 8.11769962310791
Eval_MaxReturn : 947.691162109375
Eval_MinReturn : 928.305419921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.5330810546875
Train_StdReturn : 0.0
Train_MaxReturn : 944.5330810546875
Train_MinReturn : 944.5330810546875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 569000
TimeSinceStart : 7216.101100206375
Training Loss : 0.0003712237812578678
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 570 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.640625
Eval_StdReturn : 8.31596565246582
Eval_MaxReturn : 949.3487548828125
Eval_MinReturn : 926.440185546875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.3717041015625
Train_StdReturn : 0.0
Train_MaxReturn : 944.3717041015625
Train_MinReturn : 944.3717041015625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 570000
TimeSinceStart : 7234.1680636405945
Training Loss : 0.00014334439765661955
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 571 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.9971923828125
Eval_StdReturn : 11.884318351745605
Eval_MaxReturn : 971.1529541015625
Eval_MinReturn : 938.8290405273438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.054931640625
Train_StdReturn : 0.0
Train_MaxReturn : 954.054931640625
Train_MinReturn : 954.054931640625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 571000
TimeSinceStart : 7251.551649808884
Training Loss : 0.00042257981840521097
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 572 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.0418090820312
Eval_StdReturn : 6.22481632232666
Eval_MaxReturn : 961.1859130859375
Eval_MinReturn : 941.7789306640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 957.2032470703125
Train_StdReturn : 0.0
Train_MaxReturn : 957.2032470703125
Train_MinReturn : 957.2032470703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 572000
TimeSinceStart : 7269.1584804058075
Training Loss : 0.00024658170877955854
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 573 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.3992309570312
Eval_StdReturn : 7.723443984985352
Eval_MaxReturn : 961.8655395507812
Eval_MinReturn : 939.698486328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.5252685546875
Train_StdReturn : 0.0
Train_MaxReturn : 945.5252685546875
Train_MinReturn : 945.5252685546875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 573000
TimeSinceStart : 7287.197465419769
Training Loss : 0.0003998294996563345
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 574 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 957.7445068359375
Eval_StdReturn : 10.57726001739502
Eval_MaxReturn : 968.180419921875
Eval_MinReturn : 943.3038940429688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 928.748291015625
Train_StdReturn : 0.0
Train_MaxReturn : 928.748291015625
Train_MinReturn : 928.748291015625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 574000
TimeSinceStart : 7304.80867433548
Training Loss : 0.00041289805085398257
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 575 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.1837768554688
Eval_StdReturn : 9.513517379760742
Eval_MaxReturn : 946.3357543945312
Eval_MinReturn : 918.57470703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.5111694335938
Train_StdReturn : 0.0
Train_MaxReturn : 950.5111694335938
Train_MinReturn : 950.5111694335938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 575000
TimeSinceStart : 7322.69590139389
Training Loss : 7.429940160363913e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 576 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 954.2998046875
Eval_StdReturn : 8.644937515258789
Eval_MaxReturn : 962.3912353515625
Eval_MinReturn : 938.145263671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.2052001953125
Train_StdReturn : 0.0
Train_MaxReturn : 940.2052001953125
Train_MinReturn : 940.2052001953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 576000
TimeSinceStart : 7340.665520429611
Training Loss : 6.323041452560574e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 577 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.5330810546875
Eval_StdReturn : 4.253175735473633
Eval_MaxReturn : 945.3408203125
Eval_MinReturn : 932.443359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.3436279296875
Train_StdReturn : 0.0
Train_MaxReturn : 954.3436279296875
Train_MinReturn : 954.3436279296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 577000
TimeSinceStart : 7358.480700969696
Training Loss : 0.00024383887648582458
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 578 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.4177856445312
Eval_StdReturn : 11.462384223937988
Eval_MaxReturn : 961.1509399414062
Eval_MinReturn : 927.13818359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.5646362304688
Train_StdReturn : 0.0
Train_MaxReturn : 938.5646362304688
Train_MinReturn : 938.5646362304688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 578000
TimeSinceStart : 7376.489680290222
Training Loss : 0.0006696304772049189
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 579 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.146484375
Eval_StdReturn : 15.992060661315918
Eval_MaxReturn : 963.867431640625
Eval_MinReturn : 924.273681640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 930.2369384765625
Train_StdReturn : 0.0
Train_MaxReturn : 930.2369384765625
Train_MinReturn : 930.2369384765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 579000
TimeSinceStart : 7394.559958934784
Training Loss : 9.857390978140756e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 580 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.7356567382812
Eval_StdReturn : 6.799135684967041
Eval_MaxReturn : 945.6817626953125
Eval_MinReturn : 928.4496459960938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.9437866210938
Train_StdReturn : 0.0
Train_MaxReturn : 956.9437866210938
Train_MinReturn : 956.9437866210938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 580000
TimeSinceStart : 7412.818337202072
Training Loss : 0.0002014509227592498
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 581 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 952.8656005859375
Eval_StdReturn : 3.4539387226104736
Eval_MaxReturn : 957.3269653320312
Eval_MinReturn : 947.0047607421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 959.640380859375
Train_StdReturn : 0.0
Train_MaxReturn : 959.640380859375
Train_MinReturn : 959.640380859375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 581000
TimeSinceStart : 7430.575560569763
Training Loss : 0.0001549122971482575
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 582 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.3800659179688
Eval_StdReturn : 14.763154029846191
Eval_MaxReturn : 960.3062744140625
Eval_MinReturn : 918.1429443359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.9351806640625
Train_StdReturn : 0.0
Train_MaxReturn : 940.9351806640625
Train_MinReturn : 940.9351806640625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 582000
TimeSinceStart : 7448.387807369232
Training Loss : 0.00014596930122934282
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 583 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.52001953125
Eval_StdReturn : 14.839517593383789
Eval_MaxReturn : 972.625244140625
Eval_MinReturn : 928.96826171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.8717041015625
Train_StdReturn : 0.0
Train_MaxReturn : 950.8717041015625
Train_MinReturn : 950.8717041015625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 583000
TimeSinceStart : 7466.430198192596
Training Loss : 0.00036591358366422355
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 584 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.88232421875
Eval_StdReturn : 8.301263809204102
Eval_MaxReturn : 957.4937744140625
Eval_MinReturn : 937.95947265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.9898681640625
Train_StdReturn : 0.0
Train_MaxReturn : 943.9898681640625
Train_MinReturn : 943.9898681640625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 584000
TimeSinceStart : 7484.438972234726
Training Loss : 0.0008871532627381384
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 585 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 952.0400390625
Eval_StdReturn : 10.124664306640625
Eval_MaxReturn : 970.893310546875
Eval_MinReturn : 944.206298828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.677490234375
Train_StdReturn : 0.0
Train_MaxReturn : 954.677490234375
Train_MinReturn : 954.677490234375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 585000
TimeSinceStart : 7502.391070365906
Training Loss : 0.00023105261789169163
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 586 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.857421875
Eval_StdReturn : 13.891965866088867
Eval_MaxReturn : 955.0470581054688
Eval_MinReturn : 918.3447875976562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.507080078125
Train_StdReturn : 0.0
Train_MaxReturn : 947.507080078125
Train_MinReturn : 947.507080078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 586000
TimeSinceStart : 7520.611096858978
Training Loss : 0.0004006294475402683
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 587 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.5631713867188
Eval_StdReturn : 6.029187202453613
Eval_MaxReturn : 954.739501953125
Eval_MinReturn : 936.7635498046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.73095703125
Train_StdReturn : 0.0
Train_MaxReturn : 940.73095703125
Train_MinReturn : 940.73095703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 587000
TimeSinceStart : 7538.868665218353
Training Loss : 0.00036345532862469554
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 588 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.7833251953125
Eval_StdReturn : 14.029160499572754
Eval_MaxReturn : 953.6582641601562
Eval_MinReturn : 922.17919921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.1660766601562
Train_StdReturn : 0.0
Train_MaxReturn : 938.1660766601562
Train_MinReturn : 938.1660766601562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 588000
TimeSinceStart : 7556.814565658569
Training Loss : 0.0006516073481179774
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 589 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.6943359375
Eval_StdReturn : 8.521967887878418
Eval_MaxReturn : 956.84765625
Eval_MinReturn : 930.6605834960938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.34326171875
Train_StdReturn : 0.0
Train_MaxReturn : 945.34326171875
Train_MinReturn : 945.34326171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 589000
TimeSinceStart : 7575.087933540344
Training Loss : 0.00040785319288261235
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 590 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.4007568359375
Eval_StdReturn : 9.96945571899414
Eval_MaxReturn : 957.4985961914062
Eval_MinReturn : 932.533447265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.8089599609375
Train_StdReturn : 0.0
Train_MaxReturn : 948.8089599609375
Train_MinReturn : 948.8089599609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 590000
TimeSinceStart : 7592.366559743881
Training Loss : 0.00018431163334753364
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 591 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.7267456054688
Eval_StdReturn : 14.835728645324707
Eval_MaxReturn : 963.3267822265625
Eval_MinReturn : 920.1265869140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.3995361328125
Train_StdReturn : 0.0
Train_MaxReturn : 943.3995361328125
Train_MinReturn : 943.3995361328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 591000
TimeSinceStart : 7609.932505607605
Training Loss : 0.0003108686942141503
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 592 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.5466918945312
Eval_StdReturn : 7.587672710418701
Eval_MaxReturn : 952.38916015625
Eval_MinReturn : 929.639404296875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.5657348632812
Train_StdReturn : 0.0
Train_MaxReturn : 951.5657348632812
Train_MinReturn : 951.5657348632812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 592000
TimeSinceStart : 7628.1395745277405
Training Loss : 0.00017869992007035762
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 593 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 934.3349609375
Eval_StdReturn : 8.62105941772461
Eval_MaxReturn : 945.8814697265625
Eval_MinReturn : 920.0380859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.5540771484375
Train_StdReturn : 0.0
Train_MaxReturn : 949.5540771484375
Train_MinReturn : 949.5540771484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 593000
TimeSinceStart : 7646.957066059113
Training Loss : 0.0002367488923482597
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 594 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.41259765625
Eval_StdReturn : 5.7207207679748535
Eval_MaxReturn : 951.8926391601562
Eval_MinReturn : 934.8116455078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 927.7415771484375
Train_StdReturn : 0.0
Train_MaxReturn : 927.7415771484375
Train_MinReturn : 927.7415771484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 594000
TimeSinceStart : 7665.126531839371
Training Loss : 0.00019630725728347898
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 595 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.1017456054688
Eval_StdReturn : 13.343371391296387
Eval_MaxReturn : 960.1097412109375
Eval_MinReturn : 923.12890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 932.6021728515625
Train_StdReturn : 0.0
Train_MaxReturn : 932.6021728515625
Train_MinReturn : 932.6021728515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 595000
TimeSinceStart : 7683.3073823452
Training Loss : 0.0001829421817092225
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 596 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 933.7845458984375
Eval_StdReturn : 6.412438869476318
Eval_MaxReturn : 945.8016357421875
Eval_MinReturn : 928.4510498046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.8153076171875
Train_StdReturn : 0.0
Train_MaxReturn : 955.8153076171875
Train_MinReturn : 955.8153076171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 596000
TimeSinceStart : 7701.785737276077
Training Loss : 0.00039295523311011493
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 597 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.1560668945312
Eval_StdReturn : 9.833196640014648
Eval_MaxReturn : 957.21435546875
Eval_MinReturn : 935.9343872070312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.2896728515625
Train_StdReturn : 0.0
Train_MaxReturn : 955.2896728515625
Train_MinReturn : 955.2896728515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 597000
TimeSinceStart : 7720.563326120377
Training Loss : 0.00010570801532594487
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 598 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.5173950195312
Eval_StdReturn : 11.894723892211914
Eval_MaxReturn : 963.1451416015625
Eval_MinReturn : 930.1064453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.6141967773438
Train_StdReturn : 0.0
Train_MaxReturn : 945.6141967773438
Train_MinReturn : 945.6141967773438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 598000
TimeSinceStart : 7739.315970897675
Training Loss : 6.925158959347755e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 599 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.9324340820312
Eval_StdReturn : 10.788122177124023
Eval_MaxReturn : 958.142822265625
Eval_MinReturn : 931.8694458007812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.2127075195312
Train_StdReturn : 0.0
Train_MaxReturn : 950.2127075195312
Train_MinReturn : 950.2127075195312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 599000
TimeSinceStart : 7758.110817909241
Training Loss : 0.0005589797510765493
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 600 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.6726684570312
Eval_StdReturn : 11.526318550109863
Eval_MaxReturn : 964.37353515625
Eval_MinReturn : 931.909912109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.8114624023438
Train_StdReturn : 0.0
Train_MaxReturn : 945.8114624023438
Train_MinReturn : 945.8114624023438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 600000
TimeSinceStart : 7776.406231880188
Training Loss : 0.0005913791828788817
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 601 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.8387451171875
Eval_StdReturn : 8.491958618164062
Eval_MaxReturn : 958.9754638671875
Eval_MinReturn : 933.3179931640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 966.7177124023438
Train_StdReturn : 0.0
Train_MaxReturn : 966.7177124023438
Train_MinReturn : 966.7177124023438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 601000
TimeSinceStart : 7795.08572936058
Training Loss : 0.00018262065714225173
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 602 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.7833251953125
Eval_StdReturn : 4.869540691375732
Eval_MaxReturn : 943.6341552734375
Eval_MinReturn : 929.7029418945312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.2307739257812
Train_StdReturn : 0.0
Train_MaxReturn : 935.2307739257812
Train_MinReturn : 935.2307739257812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 602000
TimeSinceStart : 7813.792222976685
Training Loss : 1.6254678484983742e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 603 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.4578857421875
Eval_StdReturn : 6.473263740539551
Eval_MaxReturn : 958.5331420898438
Eval_MinReturn : 942.03369140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 926.4212646484375
Train_StdReturn : 0.0
Train_MaxReturn : 926.4212646484375
Train_MinReturn : 926.4212646484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 603000
TimeSinceStart : 7832.269001722336
Training Loss : 4.785655255545862e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 604 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.1890869140625
Eval_StdReturn : 9.318328857421875
Eval_MaxReturn : 955.095458984375
Eval_MinReturn : 930.6214599609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 925.1122436523438
Train_StdReturn : 0.0
Train_MaxReturn : 925.1122436523438
Train_MinReturn : 925.1122436523438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 604000
TimeSinceStart : 7850.718168735504
Training Loss : 0.0006664709653705359
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 605 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.58154296875
Eval_StdReturn : 6.530670166015625
Eval_MaxReturn : 960.9940185546875
Eval_MinReturn : 942.429931640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.22607421875
Train_StdReturn : 0.0
Train_MaxReturn : 943.22607421875
Train_MinReturn : 943.22607421875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 605000
TimeSinceStart : 7869.1638259887695
Training Loss : 5.0651207857299596e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 606 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.9208984375
Eval_StdReturn : 12.882960319519043
Eval_MaxReturn : 959.547119140625
Eval_MinReturn : 925.989013671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 919.954833984375
Train_StdReturn : 0.0
Train_MaxReturn : 919.954833984375
Train_MinReturn : 919.954833984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 606000
TimeSinceStart : 7887.119675159454
Training Loss : 9.836516983341426e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 607 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.1696166992188
Eval_StdReturn : 7.2108473777771
Eval_MaxReturn : 952.9732666015625
Eval_MinReturn : 936.4803466796875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.4326171875
Train_StdReturn : 0.0
Train_MaxReturn : 955.4326171875
Train_MinReturn : 955.4326171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 607000
TimeSinceStart : 7905.765812397003
Training Loss : 0.0005444051348604262
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 608 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.2852783203125
Eval_StdReturn : 6.6897101402282715
Eval_MaxReturn : 955.5230102539062
Eval_MinReturn : 937.09326171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.5313720703125
Train_StdReturn : 0.0
Train_MaxReturn : 942.5313720703125
Train_MinReturn : 942.5313720703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 608000
TimeSinceStart : 7925.245744228363
Training Loss : 0.0003618720220401883
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 609 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.7442626953125
Eval_StdReturn : 17.543724060058594
Eval_MaxReturn : 978.3232421875
Eval_MinReturn : 929.1227416992188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.3187255859375
Train_StdReturn : 0.0
Train_MaxReturn : 940.3187255859375
Train_MinReturn : 940.3187255859375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 609000
TimeSinceStart : 7944.174634218216
Training Loss : 0.00041573907947167754
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 610 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 933.677734375
Eval_StdReturn : 12.479033470153809
Eval_MaxReturn : 956.357177734375
Eval_MinReturn : 921.4150390625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.18603515625
Train_StdReturn : 0.0
Train_MaxReturn : 952.18603515625
Train_MinReturn : 952.18603515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 610000
TimeSinceStart : 7962.588420391083
Training Loss : 0.00019323000742588192
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 611 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.0543212890625
Eval_StdReturn : 16.741010665893555
Eval_MaxReturn : 963.59716796875
Eval_MinReturn : 916.90185546875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.0728759765625
Train_StdReturn : 0.0
Train_MaxReturn : 939.0728759765625
Train_MinReturn : 939.0728759765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 611000
TimeSinceStart : 7981.373593568802
Training Loss : 0.0005794249591417611
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 612 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.6551513671875
Eval_StdReturn : 12.11159610748291
Eval_MaxReturn : 953.727294921875
Eval_MinReturn : 919.9520263671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.6018676757812
Train_StdReturn : 0.0
Train_MaxReturn : 950.6018676757812
Train_MinReturn : 950.6018676757812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 612000
TimeSinceStart : 8000.044789791107
Training Loss : 3.659238063846715e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 613 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 933.7071533203125
Eval_StdReturn : 14.877273559570312
Eval_MaxReturn : 957.6156005859375
Eval_MinReturn : 913.4739990234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.9500122070312
Train_StdReturn : 0.0
Train_MaxReturn : 950.9500122070312
Train_MinReturn : 950.9500122070312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 613000
TimeSinceStart : 8018.369482755661
Training Loss : 0.00026580484700389206
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 614 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.0138549804688
Eval_StdReturn : 6.514025688171387
Eval_MaxReturn : 959.87255859375
Eval_MinReturn : 941.3898315429688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.18603515625
Train_StdReturn : 0.0
Train_MaxReturn : 934.18603515625
Train_MinReturn : 934.18603515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 614000
TimeSinceStart : 8037.1053211688995
Training Loss : 0.00036983302561566234
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 615 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.3746337890625
Eval_StdReturn : 13.399709701538086
Eval_MaxReturn : 951.06591796875
Eval_MinReturn : 913.96240234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 963.8007202148438
Train_StdReturn : 0.0
Train_MaxReturn : 963.8007202148438
Train_MinReturn : 963.8007202148438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 615000
TimeSinceStart : 8056.244461297989
Training Loss : 0.0001031223582685925
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 616 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.525390625
Eval_StdReturn : 10.020503044128418
Eval_MaxReturn : 957.62109375
Eval_MinReturn : 927.0438232421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.5723876953125
Train_StdReturn : 0.0
Train_MaxReturn : 954.5723876953125
Train_MinReturn : 954.5723876953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 616000
TimeSinceStart : 8074.9216413497925
Training Loss : 0.00037199692451395094
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 617 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.6513671875
Eval_StdReturn : 3.423206090927124
Eval_MaxReturn : 953.8677978515625
Eval_MinReturn : 944.489013671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.9100952148438
Train_StdReturn : 0.0
Train_MaxReturn : 954.9100952148438
Train_MinReturn : 954.9100952148438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 617000
TimeSinceStart : 8093.781105518341
Training Loss : 0.00019818029250018299
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 618 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.9986572265625
Eval_StdReturn : 16.90324592590332
Eval_MaxReturn : 967.1419677734375
Eval_MinReturn : 922.2979736328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.3011474609375
Train_StdReturn : 0.0
Train_MaxReturn : 958.3011474609375
Train_MinReturn : 958.3011474609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 618000
TimeSinceStart : 8112.524407148361
Training Loss : 0.0002774589229375124
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 619 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 933.3980712890625
Eval_StdReturn : 10.096962928771973
Eval_MaxReturn : 946.0849609375
Eval_MinReturn : 919.4066162109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 969.9482421875
Train_StdReturn : 0.0
Train_MaxReturn : 969.9482421875
Train_MinReturn : 969.9482421875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 619000
TimeSinceStart : 8131.341337919235
Training Loss : 0.00024546138592995703
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 620 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.8759765625
Eval_StdReturn : 14.468151092529297
Eval_MaxReturn : 965.4932861328125
Eval_MinReturn : 923.9984741210938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 926.1761474609375
Train_StdReturn : 0.0
Train_MaxReturn : 926.1761474609375
Train_MinReturn : 926.1761474609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 620000
TimeSinceStart : 8149.959882736206
Training Loss : 0.00023400453210342675
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 621 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.3063354492188
Eval_StdReturn : 14.242241859436035
Eval_MaxReturn : 969.1019287109375
Eval_MinReturn : 929.56640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.308837890625
Train_StdReturn : 0.0
Train_MaxReturn : 943.308837890625
Train_MinReturn : 943.308837890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 621000
TimeSinceStart : 8168.688569545746
Training Loss : 9.839239646680653e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 622 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.9619140625
Eval_StdReturn : 10.026013374328613
Eval_MaxReturn : 947.6238403320312
Eval_MinReturn : 919.4801635742188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.9550170898438
Train_StdReturn : 0.0
Train_MaxReturn : 937.9550170898438
Train_MinReturn : 937.9550170898438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 622000
TimeSinceStart : 8187.642533063889
Training Loss : 0.00015591623377986252
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 623 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.0525512695312
Eval_StdReturn : 4.366058826446533
Eval_MaxReturn : 949.0809936523438
Eval_MinReturn : 937.0130615234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 961.236572265625
Train_StdReturn : 0.0
Train_MaxReturn : 961.236572265625
Train_MinReturn : 961.236572265625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 623000
TimeSinceStart : 8206.6029586792
Training Loss : 0.00013401691103354096
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 624 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.6258544921875
Eval_StdReturn : 7.6984734535217285
Eval_MaxReturn : 952.8656616210938
Eval_MinReturn : 932.9312744140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.5982055664062
Train_StdReturn : 0.0
Train_MaxReturn : 940.5982055664062
Train_MinReturn : 940.5982055664062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 624000
TimeSinceStart : 8225.425852298737
Training Loss : 0.0005680511821992695
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 625 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.92626953125
Eval_StdReturn : 3.8722989559173584
Eval_MaxReturn : 957.3235473632812
Eval_MinReturn : 947.2061157226562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 924.612060546875
Train_StdReturn : 0.0
Train_MaxReturn : 924.612060546875
Train_MinReturn : 924.612060546875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 625000
TimeSinceStart : 8244.811139822006
Training Loss : 0.00030785839771851897
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 626 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.8406372070312
Eval_StdReturn : 10.552043914794922
Eval_MaxReturn : 956.797607421875
Eval_MinReturn : 927.7899169921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 961.4174194335938
Train_StdReturn : 0.0
Train_MaxReturn : 961.4174194335938
Train_MinReturn : 961.4174194335938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 626000
TimeSinceStart : 8264.17902803421
Training Loss : 5.836008858750574e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 627 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.2595825195312
Eval_StdReturn : 7.846132755279541
Eval_MaxReturn : 951.9940795898438
Eval_MinReturn : 927.8268432617188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.4735107421875
Train_StdReturn : 0.0
Train_MaxReturn : 935.4735107421875
Train_MinReturn : 935.4735107421875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 627000
TimeSinceStart : 8283.387785434723
Training Loss : 0.000174928194610402
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 628 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.7438354492188
Eval_StdReturn : 7.976818084716797
Eval_MaxReturn : 957.9209594726562
Eval_MinReturn : 938.170654296875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.0638427734375
Train_StdReturn : 0.0
Train_MaxReturn : 934.0638427734375
Train_MinReturn : 934.0638427734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 628000
TimeSinceStart : 8302.369003534317
Training Loss : 0.00016751952352933586
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 629 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 952.0543212890625
Eval_StdReturn : 14.611251831054688
Eval_MaxReturn : 975.1700439453125
Eval_MinReturn : 934.805908203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.7819213867188
Train_StdReturn : 0.0
Train_MaxReturn : 938.7819213867188
Train_MinReturn : 938.7819213867188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 629000
TimeSinceStart : 8320.905552625656
Training Loss : 0.00032634157105349004
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 630 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.1162109375
Eval_StdReturn : 12.8516263961792
Eval_MaxReturn : 961.5963745117188
Eval_MinReturn : 921.626708984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.86376953125
Train_StdReturn : 0.0
Train_MaxReturn : 948.86376953125
Train_MinReturn : 948.86376953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 630000
TimeSinceStart : 8339.74729847908
Training Loss : 0.0007115157786756754
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 631 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 933.32080078125
Eval_StdReturn : 19.37559700012207
Eval_MaxReturn : 967.1651611328125
Eval_MinReturn : 912.3773193359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 963.9624633789062
Train_StdReturn : 0.0
Train_MaxReturn : 963.9624633789062
Train_MinReturn : 963.9624633789062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 631000
TimeSinceStart : 8358.779091358185
Training Loss : 0.0002633532858453691
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 632 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.59326171875
Eval_StdReturn : 16.5380916595459
Eval_MaxReturn : 963.2042236328125
Eval_MinReturn : 926.113037109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.7838134765625
Train_StdReturn : 0.0
Train_MaxReturn : 941.7838134765625
Train_MinReturn : 941.7838134765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 632000
TimeSinceStart : 8377.839257717133
Training Loss : 0.00047964550321921706
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 633 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.0416259765625
Eval_StdReturn : 15.61881160736084
Eval_MaxReturn : 970.7525634765625
Eval_MinReturn : 927.376220703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 922.991455078125
Train_StdReturn : 0.0
Train_MaxReturn : 922.991455078125
Train_MinReturn : 922.991455078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 633000
TimeSinceStart : 8396.945508480072
Training Loss : 0.00016954983584582806
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 634 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.97607421875
Eval_StdReturn : 13.466711044311523
Eval_MaxReturn : 962.27783203125
Eval_MinReturn : 925.776123046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.1976318359375
Train_StdReturn : 0.0
Train_MaxReturn : 938.1976318359375
Train_MinReturn : 938.1976318359375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 634000
TimeSinceStart : 8416.024428367615
Training Loss : 0.00019677705131471157
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 635 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.27197265625
Eval_StdReturn : 4.647019863128662
Eval_MaxReturn : 950.35107421875
Eval_MinReturn : 937.3291625976562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.9274291992188
Train_StdReturn : 0.0
Train_MaxReturn : 952.9274291992188
Train_MinReturn : 952.9274291992188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 635000
TimeSinceStart : 8434.957751512527
Training Loss : 2.4959839720395394e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 636 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.2156372070312
Eval_StdReturn : 10.510785102844238
Eval_MaxReturn : 956.6556396484375
Eval_MinReturn : 928.1236572265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.174560546875
Train_StdReturn : 0.0
Train_MaxReturn : 948.174560546875
Train_MinReturn : 948.174560546875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 636000
TimeSinceStart : 8454.009862661362
Training Loss : 0.00010830015526153147
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 637 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 934.2537841796875
Eval_StdReturn : 12.271278381347656
Eval_MaxReturn : 955.6365966796875
Eval_MinReturn : 921.733642578125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.1433715820312
Train_StdReturn : 0.0
Train_MaxReturn : 938.1433715820312
Train_MinReturn : 938.1433715820312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 637000
TimeSinceStart : 8473.307296514511
Training Loss : 0.00016759391291998327
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 638 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.6357421875
Eval_StdReturn : 9.563583374023438
Eval_MaxReturn : 951.9080810546875
Eval_MinReturn : 929.0814208984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.3856811523438
Train_StdReturn : 0.0
Train_MaxReturn : 952.3856811523438
Train_MinReturn : 952.3856811523438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 638000
TimeSinceStart : 8492.72444820404
Training Loss : 0.00014356478641275316
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 639 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.4806518554688
Eval_StdReturn : 10.49582290649414
Eval_MaxReturn : 960.027099609375
Eval_MinReturn : 935.3907470703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 963.1707153320312
Train_StdReturn : 0.0
Train_MaxReturn : 963.1707153320312
Train_MinReturn : 963.1707153320312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 639000
TimeSinceStart : 8511.87999677658
Training Loss : 0.0002659164019860327
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 640 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.5662841796875
Eval_StdReturn : 8.469452857971191
Eval_MaxReturn : 965.2327270507812
Eval_MinReturn : 943.8746948242188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 925.5340576171875
Train_StdReturn : 0.0
Train_MaxReturn : 925.5340576171875
Train_MinReturn : 925.5340576171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 640000
TimeSinceStart : 8531.304699659348
Training Loss : 0.00034031024551950395
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 641 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.11083984375
Eval_StdReturn : 13.211099624633789
Eval_MaxReturn : 955.1259765625
Eval_MinReturn : 918.1619873046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.48828125
Train_StdReturn : 0.0
Train_MaxReturn : 945.48828125
Train_MinReturn : 945.48828125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 641000
TimeSinceStart : 8550.596840143204
Training Loss : 0.00010842356277862564
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 642 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.3932495117188
Eval_StdReturn : 9.772655487060547
Eval_MaxReturn : 962.25537109375
Eval_MinReturn : 935.32080078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 925.830078125
Train_StdReturn : 0.0
Train_MaxReturn : 925.830078125
Train_MinReturn : 925.830078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 642000
TimeSinceStart : 8570.034989118576
Training Loss : 0.00026958936359733343
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 643 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.8826293945312
Eval_StdReturn : 13.080449104309082
Eval_MaxReturn : 956.4096069335938
Eval_MinReturn : 921.6304931640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.3759155273438
Train_StdReturn : 0.0
Train_MaxReturn : 954.3759155273438
Train_MinReturn : 954.3759155273438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 643000
TimeSinceStart : 8588.995830059052
Training Loss : 8.201083255698904e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 644 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.9513549804688
Eval_StdReturn : 10.917861938476562
Eval_MaxReturn : 964.733154296875
Eval_MinReturn : 933.62255859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.7403564453125
Train_StdReturn : 0.0
Train_MaxReturn : 946.7403564453125
Train_MinReturn : 946.7403564453125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 644000
TimeSinceStart : 8608.110064983368
Training Loss : 0.0002182593016186729
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 645 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.7654418945312
Eval_StdReturn : 7.556042194366455
Eval_MaxReturn : 951.5830078125
Eval_MinReturn : 929.4517822265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 930.467529296875
Train_StdReturn : 0.0
Train_MaxReturn : 930.467529296875
Train_MinReturn : 930.467529296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 645000
TimeSinceStart : 8627.28744149208
Training Loss : 0.0001371293910779059
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 646 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.5133056640625
Eval_StdReturn : 11.219327926635742
Eval_MaxReturn : 960.6625366210938
Eval_MinReturn : 929.552490234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.9920043945312
Train_StdReturn : 0.0
Train_MaxReturn : 954.9920043945312
Train_MinReturn : 954.9920043945312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 646000
TimeSinceStart : 8646.54430103302
Training Loss : 0.0001465137756895274
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 647 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.9903564453125
Eval_StdReturn : 9.262556076049805
Eval_MaxReturn : 958.5066528320312
Eval_MinReturn : 932.260986328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 930.7655029296875
Train_StdReturn : 0.0
Train_MaxReturn : 930.7655029296875
Train_MinReturn : 930.7655029296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 647000
TimeSinceStart : 8665.991466522217
Training Loss : 0.0002448364393785596
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 648 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.8416137695312
Eval_StdReturn : 7.002828598022461
Eval_MaxReturn : 952.8497314453125
Eval_MinReturn : 933.6355590820312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.9208984375
Train_StdReturn : 0.0
Train_MaxReturn : 954.9208984375
Train_MinReturn : 954.9208984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 648000
TimeSinceStart : 8684.801293849945
Training Loss : 0.0005177821731194854
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 649 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.7952880859375
Eval_StdReturn : 14.72506332397461
Eval_MaxReturn : 968.8572998046875
Eval_MinReturn : 925.4125366210938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 915.3331298828125
Train_StdReturn : 0.0
Train_MaxReturn : 915.3331298828125
Train_MinReturn : 915.3331298828125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 649000
TimeSinceStart : 8703.673964977264
Training Loss : 0.00016283516015391797
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 650 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 958.2496337890625
Eval_StdReturn : 15.459781646728516
Eval_MaxReturn : 982.4144897460938
Eval_MinReturn : 938.324462890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.3919677734375
Train_StdReturn : 0.0
Train_MaxReturn : 950.3919677734375
Train_MinReturn : 950.3919677734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 650000
TimeSinceStart : 8723.284598350525
Training Loss : 4.581034227157943e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 651 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 952.4813232421875
Eval_StdReturn : 16.350719451904297
Eval_MaxReturn : 971.3209228515625
Eval_MinReturn : 932.420654296875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.9722900390625
Train_StdReturn : 0.0
Train_MaxReturn : 944.9722900390625
Train_MinReturn : 944.9722900390625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 651000
TimeSinceStart : 8742.974841117859
Training Loss : 0.00043668918078765273
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 652 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.1799926757812
Eval_StdReturn : 7.802464962005615
Eval_MaxReturn : 951.6378173828125
Eval_MinReturn : 928.5817260742188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.5762939453125
Train_StdReturn : 0.0
Train_MaxReturn : 939.5762939453125
Train_MinReturn : 939.5762939453125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 652000
TimeSinceStart : 8763.304701805115
Training Loss : 0.000292727054329589
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 653 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.1715087890625
Eval_StdReturn : 3.0139849185943604
Eval_MaxReturn : 947.15478515625
Eval_MinReturn : 938.7176513671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.25634765625
Train_StdReturn : 0.0
Train_MaxReturn : 935.25634765625
Train_MinReturn : 935.25634765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 653000
TimeSinceStart : 8782.809496641159
Training Loss : 0.00010234305227641016
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 654 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.1834106445312
Eval_StdReturn : 11.31427001953125
Eval_MaxReturn : 963.7425537109375
Eval_MinReturn : 933.0910034179688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 929.1817016601562
Train_StdReturn : 0.0
Train_MaxReturn : 929.1817016601562
Train_MinReturn : 929.1817016601562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 654000
TimeSinceStart : 8802.508556604385
Training Loss : 0.0003388601471669972
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 655 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.4744873046875
Eval_StdReturn : 9.155831336975098
Eval_MaxReturn : 957.3187255859375
Eval_MinReturn : 930.6421508789062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 964.547607421875
Train_StdReturn : 0.0
Train_MaxReturn : 964.547607421875
Train_MinReturn : 964.547607421875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 655000
TimeSinceStart : 8822.310982227325
Training Loss : 8.476593211526051e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 656 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.97314453125
Eval_StdReturn : 7.743086814880371
Eval_MaxReturn : 964.9102783203125
Eval_MinReturn : 942.8069458007812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.0680541992188
Train_StdReturn : 0.0
Train_MaxReturn : 952.0680541992188
Train_MinReturn : 952.0680541992188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 656000
TimeSinceStart : 8841.817602872849
Training Loss : 0.0002628111687954515
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 657 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.42333984375
Eval_StdReturn : 10.824546813964844
Eval_MaxReturn : 966.833251953125
Eval_MinReturn : 934.1768798828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.2777099609375
Train_StdReturn : 0.0
Train_MaxReturn : 939.2777099609375
Train_MinReturn : 939.2777099609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 657000
TimeSinceStart : 8860.783940553665
Training Loss : 0.00010533707245485857
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 658 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.6396484375
Eval_StdReturn : 4.823104381561279
Eval_MaxReturn : 953.1088256835938
Eval_MinReturn : 939.6856079101562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.260498046875
Train_StdReturn : 0.0
Train_MaxReturn : 946.260498046875
Train_MinReturn : 946.260498046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 658000
TimeSinceStart : 8880.27191734314
Training Loss : 5.4853786423336715e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 659 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.1281127929688
Eval_StdReturn : 12.760905265808105
Eval_MaxReturn : 956.8660278320312
Eval_MinReturn : 925.09765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.7298583984375
Train_StdReturn : 0.0
Train_MaxReturn : 948.7298583984375
Train_MinReturn : 948.7298583984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 659000
TimeSinceStart : 8900.094101667404
Training Loss : 0.00039301844662986696
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 660 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.0
Eval_StdReturn : 7.439552307128906
Eval_MaxReturn : 950.5546875
Eval_MinReturn : 928.9501342773438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.393798828125
Train_StdReturn : 0.0
Train_MaxReturn : 951.393798828125
Train_MinReturn : 951.393798828125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 660000
TimeSinceStart : 8919.713871717453
Training Loss : 4.135999915888533e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 661 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 956.9915771484375
Eval_StdReturn : 2.993347644805908
Eval_MaxReturn : 959.8717041015625
Eval_MinReturn : 951.3991088867188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.2117919921875
Train_StdReturn : 0.0
Train_MaxReturn : 952.2117919921875
Train_MinReturn : 952.2117919921875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 661000
TimeSinceStart : 8939.093823194504
Training Loss : 0.00022418917797040194
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 662 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.4533081054688
Eval_StdReturn : 11.200031280517578
Eval_MaxReturn : 954.259765625
Eval_MinReturn : 927.569580078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 970.1109619140625
Train_StdReturn : 0.0
Train_MaxReturn : 970.1109619140625
Train_MinReturn : 970.1109619140625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 662000
TimeSinceStart : 8958.640011072159
Training Loss : 8.337048348039389e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 663 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.5304565429688
Eval_StdReturn : 9.618021965026855
Eval_MaxReturn : 963.548095703125
Eval_MinReturn : 940.1622314453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.0533447265625
Train_StdReturn : 0.0
Train_MaxReturn : 939.0533447265625
Train_MinReturn : 939.0533447265625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 663000
TimeSinceStart : 8978.289782047272
Training Loss : 0.00039136226405389607
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 664 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.8175048828125
Eval_StdReturn : 11.67487621307373
Eval_MaxReturn : 961.8660888671875
Eval_MinReturn : 930.6168823242188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 932.588134765625
Train_StdReturn : 0.0
Train_MaxReturn : 932.588134765625
Train_MinReturn : 932.588134765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 664000
TimeSinceStart : 8997.655442476273
Training Loss : 0.00031324769952334464
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 665 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.4860229492188
Eval_StdReturn : 12.393157005310059
Eval_MaxReturn : 955.532958984375
Eval_MinReturn : 922.0302734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.771484375
Train_StdReturn : 0.0
Train_MaxReturn : 948.771484375
Train_MinReturn : 948.771484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 665000
TimeSinceStart : 9017.542860507965
Training Loss : 0.00015055487165227532
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 666 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.8943481445312
Eval_StdReturn : 11.726078033447266
Eval_MaxReturn : 949.729248046875
Eval_MinReturn : 919.3150634765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 959.2218017578125
Train_StdReturn : 0.0
Train_MaxReturn : 959.2218017578125
Train_MinReturn : 959.2218017578125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 666000
TimeSinceStart : 9038.382226228714
Training Loss : 0.00011058303061872721
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 667 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.3466796875
Eval_StdReturn : 11.227265357971191
Eval_MaxReturn : 960.7862548828125
Eval_MinReturn : 929.3763427734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 930.7132568359375
Train_StdReturn : 0.0
Train_MaxReturn : 930.7132568359375
Train_MinReturn : 930.7132568359375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 667000
TimeSinceStart : 9058.260658979416
Training Loss : 0.00013670707994606346
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 668 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.7958984375
Eval_StdReturn : 15.816142082214355
Eval_MaxReturn : 966.093994140625
Eval_MinReturn : 926.2352294921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.261962890625
Train_StdReturn : 0.0
Train_MaxReturn : 945.261962890625
Train_MinReturn : 945.261962890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 668000
TimeSinceStart : 9078.375392198563
Training Loss : 0.0003007824416272342
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 669 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.5631103515625
Eval_StdReturn : 6.94956636428833
Eval_MaxReturn : 956.4990234375
Eval_MinReturn : 937.7025146484375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.42724609375
Train_StdReturn : 0.0
Train_MaxReturn : 948.42724609375
Train_MinReturn : 948.42724609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 669000
TimeSinceStart : 9098.83979678154
Training Loss : 0.00030320684891194105
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 670 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 932.8156127929688
Eval_StdReturn : 13.776745796203613
Eval_MaxReturn : 950.523193359375
Eval_MinReturn : 916.2572021484375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.55126953125
Train_StdReturn : 0.0
Train_MaxReturn : 954.55126953125
Train_MinReturn : 954.55126953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 670000
TimeSinceStart : 9118.350812911987
Training Loss : 0.000215298161492683
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 671 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.2708740234375
Eval_StdReturn : 11.86050033569336
Eval_MaxReturn : 961.0302734375
Eval_MinReturn : 929.7777709960938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 966.4619750976562
Train_StdReturn : 0.0
Train_MaxReturn : 966.4619750976562
Train_MinReturn : 966.4619750976562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 671000
TimeSinceStart : 9138.31625533104
Training Loss : 0.00018949474906548858
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 672 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.2291870117188
Eval_StdReturn : 14.802145004272461
Eval_MaxReturn : 955.9368286132812
Eval_MinReturn : 916.90478515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 929.0032958984375
Train_StdReturn : 0.0
Train_MaxReturn : 929.0032958984375
Train_MinReturn : 929.0032958984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 672000
TimeSinceStart : 9158.23358631134
Training Loss : 0.0004098550998605788
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 673 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.8560791015625
Eval_StdReturn : 12.265339851379395
Eval_MaxReturn : 968.0782470703125
Eval_MinReturn : 931.72265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.3409423828125
Train_StdReturn : 0.0
Train_MaxReturn : 938.3409423828125
Train_MinReturn : 938.3409423828125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 673000
TimeSinceStart : 9178.185108184814
Training Loss : 0.0002793363528326154
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 674 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.3767700195312
Eval_StdReturn : 12.166016578674316
Eval_MaxReturn : 963.2431030273438
Eval_MinReturn : 931.0723876953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.5199584960938
Train_StdReturn : 0.0
Train_MaxReturn : 951.5199584960938
Train_MinReturn : 951.5199584960938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 674000
TimeSinceStart : 9198.328454971313
Training Loss : 0.0008772752480581403
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 675 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.7951049804688
Eval_StdReturn : 9.998551368713379
Eval_MaxReturn : 951.1529541015625
Eval_MinReturn : 920.359130859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.8599853515625
Train_StdReturn : 0.0
Train_MaxReturn : 944.8599853515625
Train_MinReturn : 944.8599853515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 675000
TimeSinceStart : 9217.78023815155
Training Loss : 3.237014607293531e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 676 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.1015625
Eval_StdReturn : 8.554734230041504
Eval_MaxReturn : 964.1768798828125
Eval_MinReturn : 940.7080078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.1068725585938
Train_StdReturn : 0.0
Train_MaxReturn : 952.1068725585938
Train_MinReturn : 952.1068725585938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 676000
TimeSinceStart : 9237.852703332901
Training Loss : 0.00021593316341750324
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 677 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.3380737304688
Eval_StdReturn : 4.745730876922607
Eval_MaxReturn : 947.8629150390625
Eval_MinReturn : 934.558837890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 959.975341796875
Train_StdReturn : 0.0
Train_MaxReturn : 959.975341796875
Train_MinReturn : 959.975341796875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 677000
TimeSinceStart : 9257.66100859642
Training Loss : 0.0003468539216555655
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 678 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 957.0338745117188
Eval_StdReturn : 12.685291290283203
Eval_MaxReturn : 967.8740234375
Eval_MinReturn : 932.6588134765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.350830078125
Train_StdReturn : 0.0
Train_MaxReturn : 936.350830078125
Train_MinReturn : 936.350830078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 678000
TimeSinceStart : 9277.372615814209
Training Loss : 0.00022796723351348191
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 679 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.9794921875
Eval_StdReturn : 7.008286952972412
Eval_MaxReturn : 953.3814697265625
Eval_MinReturn : 932.330810546875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.0452880859375
Train_StdReturn : 0.0
Train_MaxReturn : 944.0452880859375
Train_MinReturn : 944.0452880859375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 679000
TimeSinceStart : 9297.953090190887
Training Loss : 0.00015232442819979042
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 680 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.1439208984375
Eval_StdReturn : 13.22441291809082
Eval_MaxReturn : 957.36181640625
Eval_MinReturn : 918.862548828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.0643920898438
Train_StdReturn : 0.0
Train_MaxReturn : 953.0643920898438
Train_MinReturn : 953.0643920898438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 680000
TimeSinceStart : 9318.231127023697
Training Loss : 0.00012524898920673877
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 681 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.0149536132812
Eval_StdReturn : 4.150651931762695
Eval_MaxReturn : 947.1528930664062
Eval_MinReturn : 935.6796264648438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 932.548828125
Train_StdReturn : 0.0
Train_MaxReturn : 932.548828125
Train_MinReturn : 932.548828125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 681000
TimeSinceStart : 9338.267628908157
Training Loss : 0.0003212645824532956
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 682 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.9969482421875
Eval_StdReturn : 5.151500225067139
Eval_MaxReturn : 954.4737548828125
Eval_MinReturn : 940.3256225585938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.3865966796875
Train_StdReturn : 0.0
Train_MaxReturn : 949.3865966796875
Train_MinReturn : 949.3865966796875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 682000
TimeSinceStart : 9358.619826555252
Training Loss : 0.00020711436809506267
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 683 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.4053955078125
Eval_StdReturn : 15.57000732421875
Eval_MaxReturn : 973.46875
Eval_MinReturn : 936.0970458984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 957.309814453125
Train_StdReturn : 0.0
Train_MaxReturn : 957.309814453125
Train_MinReturn : 957.309814453125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 683000
TimeSinceStart : 9379.181502819061
Training Loss : 0.00010127419227501377
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 684 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 935.5875244140625
Eval_StdReturn : 11.090202331542969
Eval_MaxReturn : 948.00634765625
Eval_MinReturn : 920.03564453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 959.989013671875
Train_StdReturn : 0.0
Train_MaxReturn : 959.989013671875
Train_MinReturn : 959.989013671875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 684000
TimeSinceStart : 9399.487139225006
Training Loss : 6.0655715060420334e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 685 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.1463012695312
Eval_StdReturn : 11.69430160522461
Eval_MaxReturn : 963.3294677734375
Eval_MinReturn : 933.9434814453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.8748779296875
Train_StdReturn : 0.0
Train_MaxReturn : 953.8748779296875
Train_MinReturn : 953.8748779296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 685000
TimeSinceStart : 9419.70732831955
Training Loss : 0.0004433046851772815
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 686 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 927.7059326171875
Eval_StdReturn : 13.693370819091797
Eval_MaxReturn : 949.647216796875
Eval_MinReturn : 906.58740234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.4779052734375
Train_StdReturn : 0.0
Train_MaxReturn : 934.4779052734375
Train_MinReturn : 934.4779052734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 686000
TimeSinceStart : 9439.89002776146
Training Loss : 0.0003070295788347721
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 687 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.4186401367188
Eval_StdReturn : 9.774949073791504
Eval_MaxReturn : 969.3213500976562
Eval_MinReturn : 942.507568359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.375
Train_StdReturn : 0.0
Train_MaxReturn : 937.375
Train_MinReturn : 937.375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 687000
TimeSinceStart : 9460.318095445633
Training Loss : 0.0006374047370627522
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 688 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.8428955078125
Eval_StdReturn : 6.655937671661377
Eval_MaxReturn : 950.9812622070312
Eval_MinReturn : 932.216796875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 960.6949462890625
Train_StdReturn : 0.0
Train_MaxReturn : 960.6949462890625
Train_MinReturn : 960.6949462890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 688000
TimeSinceStart : 9480.524063825607
Training Loss : 0.0002643773623276502
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 689 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 932.4738159179688
Eval_StdReturn : 16.509199142456055
Eval_MaxReturn : 951.506103515625
Eval_MinReturn : 903.2320556640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.8609619140625
Train_StdReturn : 0.0
Train_MaxReturn : 952.8609619140625
Train_MinReturn : 952.8609619140625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 689000
TimeSinceStart : 9500.715237379074
Training Loss : 0.00023513427004218102
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 690 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.7449951171875
Eval_StdReturn : 9.754197120666504
Eval_MaxReturn : 956.5531005859375
Eval_MinReturn : 929.82080078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.89599609375
Train_StdReturn : 0.0
Train_MaxReturn : 941.89599609375
Train_MinReturn : 941.89599609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 690000
TimeSinceStart : 9520.65836238861
Training Loss : 0.00019967096159234643
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 691 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.65966796875
Eval_StdReturn : 12.53332805633545
Eval_MaxReturn : 952.981201171875
Eval_MinReturn : 915.0368041992188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.3670043945312
Train_StdReturn : 0.0
Train_MaxReturn : 954.3670043945312
Train_MinReturn : 954.3670043945312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 691000
TimeSinceStart : 9540.57251214981
Training Loss : 0.000180957984412089
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 692 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.38427734375
Eval_StdReturn : 12.714029312133789
Eval_MaxReturn : 962.9285888671875
Eval_MinReturn : 931.8894653320312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.6937866210938
Train_StdReturn : 0.0
Train_MaxReturn : 936.6937866210938
Train_MinReturn : 936.6937866210938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 692000
TimeSinceStart : 9561.062337398529
Training Loss : 5.3987649152986705e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 693 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.1676025390625
Eval_StdReturn : 9.980729103088379
Eval_MaxReturn : 952.6326904296875
Eval_MinReturn : 926.2771606445312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 960.294921875
Train_StdReturn : 0.0
Train_MaxReturn : 960.294921875
Train_MinReturn : 960.294921875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 693000
TimeSinceStart : 9581.867575645447
Training Loss : 0.0002884649729821831
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 694 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 952.2320556640625
Eval_StdReturn : 3.22200345993042
Eval_MaxReturn : 955.4947509765625
Eval_MinReturn : 947.4892578125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.8846435546875
Train_StdReturn : 0.0
Train_MaxReturn : 938.8846435546875
Train_MinReturn : 938.8846435546875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 694000
TimeSinceStart : 9602.250212430954
Training Loss : 0.00010022133210441098
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 695 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.6046142578125
Eval_StdReturn : 17.242338180541992
Eval_MaxReturn : 966.1799926757812
Eval_MinReturn : 914.8839721679688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.9553833007812
Train_StdReturn : 0.0
Train_MaxReturn : 933.9553833007812
Train_MinReturn : 933.9553833007812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 695000
TimeSinceStart : 9622.105585098267
Training Loss : 0.00034647557185962796
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 696 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.8186645507812
Eval_StdReturn : 5.8271613121032715
Eval_MaxReturn : 947.7865600585938
Eval_MinReturn : 932.64990234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.245361328125
Train_StdReturn : 0.0
Train_MaxReturn : 951.245361328125
Train_MinReturn : 951.245361328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 696000
TimeSinceStart : 9642.744037151337
Training Loss : 0.0001924808311741799
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 697 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.744140625
Eval_StdReturn : 11.334685325622559
Eval_MaxReturn : 962.1212158203125
Eval_MinReturn : 929.3231811523438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 932.8511962890625
Train_StdReturn : 0.0
Train_MaxReturn : 932.8511962890625
Train_MinReturn : 932.8511962890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 697000
TimeSinceStart : 9662.223110198975
Training Loss : 0.00014177372213453054
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 698 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.2110595703125
Eval_StdReturn : 8.371280670166016
Eval_MaxReturn : 964.41796875
Eval_MinReturn : 941.4625244140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.858154296875
Train_StdReturn : 0.0
Train_MaxReturn : 948.858154296875
Train_MinReturn : 948.858154296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 698000
TimeSinceStart : 9682.710874080658
Training Loss : 7.791759708197787e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 699 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 956.3448486328125
Eval_StdReturn : 6.947160720825195
Eval_MaxReturn : 969.6134033203125
Eval_MinReturn : 950.43798828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.6650390625
Train_StdReturn : 0.0
Train_MaxReturn : 939.6650390625
Train_MinReturn : 939.6650390625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 699000
TimeSinceStart : 9703.428199768066
Training Loss : 6.318582745734602e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 700 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.7037353515625
Eval_StdReturn : 5.615846633911133
Eval_MaxReturn : 951.69677734375
Eval_MinReturn : 937.8720703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.2496337890625
Train_StdReturn : 0.0
Train_MaxReturn : 950.2496337890625
Train_MinReturn : 950.2496337890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 700000
TimeSinceStart : 9724.141864538193
Training Loss : 6.697114440612495e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 701 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.0960693359375
Eval_StdReturn : 22.409406661987305
Eval_MaxReturn : 972.8416748046875
Eval_MinReturn : 915.1510009765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.4195556640625
Train_StdReturn : 0.0
Train_MaxReturn : 943.4195556640625
Train_MinReturn : 943.4195556640625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 701000
TimeSinceStart : 9744.571530342102
Training Loss : 0.000154424604261294
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 702 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.5226440429688
Eval_StdReturn : 5.942331314086914
Eval_MaxReturn : 951.14453125
Eval_MinReturn : 933.2174072265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 923.713623046875
Train_StdReturn : 0.0
Train_MaxReturn : 923.713623046875
Train_MinReturn : 923.713623046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 702000
TimeSinceStart : 9765.315478563309
Training Loss : 7.426814136124449e-06
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 703 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.7515869140625
Eval_StdReturn : 20.348527908325195
Eval_MaxReturn : 975.6324462890625
Eval_MinReturn : 921.2119140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.7891235351562
Train_StdReturn : 0.0
Train_MaxReturn : 937.7891235351562
Train_MinReturn : 937.7891235351562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 703000
TimeSinceStart : 9785.47701883316
Training Loss : 6.785872392356396e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 704 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.6282958984375
Eval_StdReturn : 7.511329174041748
Eval_MaxReturn : 952.8106689453125
Eval_MinReturn : 931.5341186523438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.7401733398438
Train_StdReturn : 0.0
Train_MaxReturn : 937.7401733398438
Train_MinReturn : 937.7401733398438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 704000
TimeSinceStart : 9805.840304136276
Training Loss : 0.00015706216800026596
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 705 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.46484375
Eval_StdReturn : 16.178672790527344
Eval_MaxReturn : 958.9924926757812
Eval_MinReturn : 915.701416015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.2181396484375
Train_StdReturn : 0.0
Train_MaxReturn : 945.2181396484375
Train_MinReturn : 945.2181396484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 705000
TimeSinceStart : 9826.58119225502
Training Loss : 0.00023415658506564796
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 706 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.3366088867188
Eval_StdReturn : 7.679276466369629
Eval_MaxReturn : 948.709716796875
Eval_MinReturn : 929.529052734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.7903442382812
Train_StdReturn : 0.0
Train_MaxReturn : 946.7903442382812
Train_MinReturn : 946.7903442382812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 706000
TimeSinceStart : 9847.429053068161
Training Loss : 0.0002700636105146259
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 707 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.0582885742188
Eval_StdReturn : 9.065711975097656
Eval_MaxReturn : 960.81494140625
Eval_MinReturn : 932.6458740234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 924.1016845703125
Train_StdReturn : 0.0
Train_MaxReturn : 924.1016845703125
Train_MinReturn : 924.1016845703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 707000
TimeSinceStart : 9868.357344150543
Training Loss : 0.0008417866774834692
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 708 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.4547729492188
Eval_StdReturn : 14.231664657592773
Eval_MaxReturn : 958.3717651367188
Eval_MinReturn : 913.5150146484375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 966.7135009765625
Train_StdReturn : 0.0
Train_MaxReturn : 966.7135009765625
Train_MinReturn : 966.7135009765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 708000
TimeSinceStart : 9889.136680603027
Training Loss : 0.0004646828747354448
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 709 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.0443115234375
Eval_StdReturn : 3.6705563068389893
Eval_MaxReturn : 941.6197509765625
Eval_MinReturn : 930.0299072265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.579345703125
Train_StdReturn : 0.0
Train_MaxReturn : 947.579345703125
Train_MinReturn : 947.579345703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 709000
TimeSinceStart : 9909.632203102112
Training Loss : 0.0002920670958701521
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 710 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.494140625
Eval_StdReturn : 11.187041282653809
Eval_MaxReturn : 958.9488525390625
Eval_MinReturn : 931.5047607421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.971435546875
Train_StdReturn : 0.0
Train_MaxReturn : 948.971435546875
Train_MinReturn : 948.971435546875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 710000
TimeSinceStart : 9930.085865736008
Training Loss : 3.6061450373381376e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 711 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.0703125
Eval_StdReturn : 5.806685447692871
Eval_MaxReturn : 949.5862426757812
Eval_MinReturn : 932.70849609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.7394409179688
Train_StdReturn : 0.0
Train_MaxReturn : 954.7394409179688
Train_MinReturn : 954.7394409179688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 711000
TimeSinceStart : 9951.191864490509
Training Loss : 0.00024790133466012776
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 712 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.4363403320312
Eval_StdReturn : 12.800882339477539
Eval_MaxReturn : 972.8165283203125
Eval_MinReturn : 935.4485473632812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 932.4252319335938
Train_StdReturn : 0.0
Train_MaxReturn : 932.4252319335938
Train_MinReturn : 932.4252319335938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 712000
TimeSinceStart : 9972.11507844925
Training Loss : 0.000698639138136059
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 713 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.44580078125
Eval_StdReturn : 7.689245700836182
Eval_MaxReturn : 953.7672119140625
Eval_MinReturn : 934.4019165039062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.0980224609375
Train_StdReturn : 0.0
Train_MaxReturn : 941.0980224609375
Train_MinReturn : 941.0980224609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 713000
TimeSinceStart : 9992.981922626495
Training Loss : 9.115252760238945e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 714 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.3150634765625
Eval_StdReturn : 12.369890213012695
Eval_MaxReturn : 956.1727294921875
Eval_MinReturn : 922.7158203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.4334716796875
Train_StdReturn : 0.0
Train_MaxReturn : 958.4334716796875
Train_MinReturn : 958.4334716796875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 714000
TimeSinceStart : 10013.84911108017
Training Loss : 0.0004194929788354784
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 715 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.1057739257812
Eval_StdReturn : 15.126648902893066
Eval_MaxReturn : 957.06640625
Eval_MinReturn : 918.843505859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.9121704101562
Train_StdReturn : 0.0
Train_MaxReturn : 946.9121704101562
Train_MinReturn : 946.9121704101562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 715000
TimeSinceStart : 10034.210422039032
Training Loss : 0.0001907087571453303
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 716 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.2744140625
Eval_StdReturn : 9.100434303283691
Eval_MaxReturn : 956.5112915039062
Eval_MinReturn : 933.5640258789062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.1707763671875
Train_StdReturn : 0.0
Train_MaxReturn : 958.1707763671875
Train_MinReturn : 958.1707763671875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 716000
TimeSinceStart : 10055.028661251068
Training Loss : 0.0002990138891618699
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 717 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.0283203125
Eval_StdReturn : 8.531705856323242
Eval_MaxReturn : 964.3394165039062
Eval_MinReturn : 941.1485595703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.6544189453125
Train_StdReturn : 0.0
Train_MaxReturn : 934.6544189453125
Train_MinReturn : 934.6544189453125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 717000
TimeSinceStart : 10075.82723903656
Training Loss : 9.86451850621961e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 718 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.4152221679688
Eval_StdReturn : 11.570996284484863
Eval_MaxReturn : 958.120849609375
Eval_MinReturn : 926.3257446289062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.1668701171875
Train_StdReturn : 0.0
Train_MaxReturn : 949.1668701171875
Train_MinReturn : 949.1668701171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 718000
TimeSinceStart : 10096.742968082428
Training Loss : 0.0002211663086200133
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 719 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.9318237304688
Eval_StdReturn : 12.40159797668457
Eval_MaxReturn : 965.987548828125
Eval_MinReturn : 936.0177001953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 926.8515625
Train_StdReturn : 0.0
Train_MaxReturn : 926.8515625
Train_MinReturn : 926.8515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 719000
TimeSinceStart : 10117.460377693176
Training Loss : 0.00028075516456738114
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 720 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.1558837890625
Eval_StdReturn : 12.77109146118164
Eval_MaxReturn : 961.3563232421875
Eval_MinReturn : 924.7266845703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.078369140625
Train_StdReturn : 0.0
Train_MaxReturn : 937.078369140625
Train_MinReturn : 937.078369140625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 720000
TimeSinceStart : 10137.983597040176
Training Loss : 0.00031953398138284683
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 721 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.0953979492188
Eval_StdReturn : 8.517318725585938
Eval_MaxReturn : 959.3054809570312
Eval_MinReturn : 934.1304931640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.302001953125
Train_StdReturn : 0.0
Train_MaxReturn : 947.302001953125
Train_MinReturn : 947.302001953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 721000
TimeSinceStart : 10159.63410282135
Training Loss : 0.0002940683625638485
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 722 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.0134887695312
Eval_StdReturn : 7.573868751525879
Eval_MaxReturn : 959.3529052734375
Eval_MinReturn : 941.2100830078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.7005615234375
Train_StdReturn : 0.0
Train_MaxReturn : 954.7005615234375
Train_MinReturn : 954.7005615234375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 722000
TimeSinceStart : 10180.973195552826
Training Loss : 0.0003111025725957006
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 723 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.3951416015625
Eval_StdReturn : 17.61603355407715
Eval_MaxReturn : 963.564697265625
Eval_MinReturn : 914.6825561523438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.3075561523438
Train_StdReturn : 0.0
Train_MaxReturn : 933.3075561523438
Train_MinReturn : 933.3075561523438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 723000
TimeSinceStart : 10201.92056632042
Training Loss : 0.00014574114175047725
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 724 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.6423950195312
Eval_StdReturn : 6.7483720779418945
Eval_MaxReturn : 951.945068359375
Eval_MinReturn : 935.5081787109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.3848876953125
Train_StdReturn : 0.0
Train_MaxReturn : 940.3848876953125
Train_MinReturn : 940.3848876953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 724000
TimeSinceStart : 10222.742819786072
Training Loss : 0.000508482160512358
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 725 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 932.697265625
Eval_StdReturn : 12.940407752990723
Eval_MaxReturn : 957.3778076171875
Eval_MinReturn : 922.499755859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.8218994140625
Train_StdReturn : 0.0
Train_MaxReturn : 940.8218994140625
Train_MinReturn : 940.8218994140625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 725000
TimeSinceStart : 10243.217414140701
Training Loss : 0.00026464983238838613
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 726 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 933.6397705078125
Eval_StdReturn : 9.267107009887695
Eval_MaxReturn : 941.4354248046875
Eval_MinReturn : 915.692626953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 918.904296875
Train_StdReturn : 0.0
Train_MaxReturn : 918.904296875
Train_MinReturn : 918.904296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 726000
TimeSinceStart : 10264.086650848389
Training Loss : 0.000166710204211995
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 727 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.8054809570312
Eval_StdReturn : 3.4006567001342773
Eval_MaxReturn : 946.2010498046875
Eval_MinReturn : 936.2818603515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.5138549804688
Train_StdReturn : 0.0
Train_MaxReturn : 956.5138549804688
Train_MinReturn : 956.5138549804688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 727000
TimeSinceStart : 10285.068495988846
Training Loss : 0.0005113747320137918
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 728 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.1129150390625
Eval_StdReturn : 12.550271987915039
Eval_MaxReturn : 953.421142578125
Eval_MinReturn : 919.6527099609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.8082275390625
Train_StdReturn : 0.0
Train_MaxReturn : 936.8082275390625
Train_MinReturn : 936.8082275390625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 728000
TimeSinceStart : 10305.835575342178
Training Loss : 0.00013000100443605334
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 729 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.2401123046875
Eval_StdReturn : 10.584187507629395
Eval_MaxReturn : 956.9505615234375
Eval_MinReturn : 924.6962890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.0303344726562
Train_StdReturn : 0.0
Train_MaxReturn : 937.0303344726562
Train_MinReturn : 937.0303344726562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 729000
TimeSinceStart : 10326.74234008789
Training Loss : 8.043195703066885e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 730 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 933.1116333007812
Eval_StdReturn : 11.723918914794922
Eval_MaxReturn : 947.6236572265625
Eval_MinReturn : 915.7960205078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.7352294921875
Train_StdReturn : 0.0
Train_MaxReturn : 953.7352294921875
Train_MinReturn : 953.7352294921875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 730000
TimeSinceStart : 10346.90982222557
Training Loss : 0.00033446020097471774
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 731 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.4566650390625
Eval_StdReturn : 11.160621643066406
Eval_MaxReturn : 968.51220703125
Eval_MinReturn : 935.558837890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.2908325195312
Train_StdReturn : 0.0
Train_MaxReturn : 945.2908325195312
Train_MinReturn : 945.2908325195312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 731000
TimeSinceStart : 10367.843012094498
Training Loss : 0.0001511948648840189
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 732 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.4432373046875
Eval_StdReturn : 10.046433448791504
Eval_MaxReturn : 952.5244140625
Eval_MinReturn : 924.8843383789062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.4608154296875
Train_StdReturn : 0.0
Train_MaxReturn : 947.4608154296875
Train_MinReturn : 947.4608154296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 732000
TimeSinceStart : 10388.969831466675
Training Loss : 0.00013566525012720376
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 733 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.27880859375
Eval_StdReturn : 7.901880741119385
Eval_MaxReturn : 960.1356201171875
Eval_MinReturn : 937.1224365234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.2139892578125
Train_StdReturn : 0.0
Train_MaxReturn : 951.2139892578125
Train_MinReturn : 951.2139892578125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 733000
TimeSinceStart : 10410.080701828003
Training Loss : 0.00021310476586222649
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 734 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 932.2732543945312
Eval_StdReturn : 10.712169647216797
Eval_MaxReturn : 949.923095703125
Eval_MinReturn : 922.516845703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.9963989257812
Train_StdReturn : 0.0
Train_MaxReturn : 946.9963989257812
Train_MinReturn : 946.9963989257812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 734000
TimeSinceStart : 10430.90935254097
Training Loss : 0.00025966885732486844
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 735 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.4241943359375
Eval_StdReturn : 13.751201629638672
Eval_MaxReturn : 963.9603271484375
Eval_MinReturn : 924.0625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.1920776367188
Train_StdReturn : 0.0
Train_MaxReturn : 945.1920776367188
Train_MinReturn : 945.1920776367188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 735000
TimeSinceStart : 10452.225768089294
Training Loss : 0.0017420746153220534
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 736 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.3595581054688
Eval_StdReturn : 14.38631820678711
Eval_MaxReturn : 967.8072509765625
Eval_MinReturn : 924.0433349609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 930.333251953125
Train_StdReturn : 0.0
Train_MaxReturn : 930.333251953125
Train_MinReturn : 930.333251953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 736000
TimeSinceStart : 10473.528931379318
Training Loss : 8.379101927857846e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 737 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.78955078125
Eval_StdReturn : 8.956023216247559
Eval_MaxReturn : 954.7825317382812
Eval_MinReturn : 928.9349365234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.2884521484375
Train_StdReturn : 0.0
Train_MaxReturn : 948.2884521484375
Train_MinReturn : 948.2884521484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 737000
TimeSinceStart : 10494.832497119904
Training Loss : 1.2289598089409992e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 738 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.5900268554688
Eval_StdReturn : 13.04050064086914
Eval_MaxReturn : 962.26708984375
Eval_MinReturn : 924.6416015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.2381591796875
Train_StdReturn : 0.0
Train_MaxReturn : 947.2381591796875
Train_MinReturn : 947.2381591796875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 738000
TimeSinceStart : 10516.305191516876
Training Loss : 0.0001792612747522071
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 739 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.1736450195312
Eval_StdReturn : 7.971090316772461
Eval_MaxReturn : 950.1814575195312
Eval_MinReturn : 927.1282348632812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.6838989257812
Train_StdReturn : 0.0
Train_MaxReturn : 942.6838989257812
Train_MinReturn : 942.6838989257812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 739000
TimeSinceStart : 10537.033337593079
Training Loss : 0.0003744980494957417
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 740 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 933.70654296875
Eval_StdReturn : 13.417927742004395
Eval_MaxReturn : 952.0944213867188
Eval_MinReturn : 911.21142578125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.4708251953125
Train_StdReturn : 0.0
Train_MaxReturn : 938.4708251953125
Train_MinReturn : 938.4708251953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 740000
TimeSinceStart : 10558.280683994293
Training Loss : 4.474350134842098e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 741 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.4451293945312
Eval_StdReturn : 13.33834171295166
Eval_MaxReturn : 960.1546630859375
Eval_MinReturn : 924.5253295898438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.2063598632812
Train_StdReturn : 0.0
Train_MaxReturn : 942.2063598632812
Train_MinReturn : 942.2063598632812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 741000
TimeSinceStart : 10579.73901605606
Training Loss : 0.00013185347779653966
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 742 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 958.9202880859375
Eval_StdReturn : 9.730670928955078
Eval_MaxReturn : 969.4818725585938
Eval_MinReturn : 943.6619262695312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 929.0789794921875
Train_StdReturn : 0.0
Train_MaxReturn : 929.0789794921875
Train_MinReturn : 929.0789794921875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 742000
TimeSinceStart : 10601.37286901474
Training Loss : 7.945718243718147e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 743 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.4533081054688
Eval_StdReturn : 6.423300266265869
Eval_MaxReturn : 952.648681640625
Eval_MinReturn : 933.4039306640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.6846313476562
Train_StdReturn : 0.0
Train_MaxReturn : 941.6846313476562
Train_MinReturn : 941.6846313476562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 743000
TimeSinceStart : 10623.140695095062
Training Loss : 0.00012195778981549665
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 744 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.3001098632812
Eval_StdReturn : 9.021608352661133
Eval_MaxReturn : 955.0221557617188
Eval_MinReturn : 929.3212890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.7322998046875
Train_StdReturn : 0.0
Train_MaxReturn : 937.7322998046875
Train_MinReturn : 937.7322998046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 744000
TimeSinceStart : 10644.648616790771
Training Loss : 0.00015414202061947435
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 745 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.9661254882812
Eval_StdReturn : 12.964288711547852
Eval_MaxReturn : 954.4093017578125
Eval_MinReturn : 918.6009521484375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 959.1002197265625
Train_StdReturn : 0.0
Train_MaxReturn : 959.1002197265625
Train_MinReturn : 959.1002197265625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 745000
TimeSinceStart : 10666.488009691238
Training Loss : 0.00025538558838889003
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 746 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.34228515625
Eval_StdReturn : 5.95035457611084
Eval_MaxReturn : 948.333251953125
Eval_MinReturn : 932.70751953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.4799194335938
Train_StdReturn : 0.0
Train_MaxReturn : 944.4799194335938
Train_MinReturn : 944.4799194335938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 746000
TimeSinceStart : 10688.066770076752
Training Loss : 0.00040114313014782965
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 747 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 957.5559692382812
Eval_StdReturn : 5.321044921875
Eval_MaxReturn : 964.603515625
Eval_MinReturn : 948.9883422851562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 914.7938232421875
Train_StdReturn : 0.0
Train_MaxReturn : 914.7938232421875
Train_MinReturn : 914.7938232421875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 747000
TimeSinceStart : 10709.428842544556
Training Loss : 0.0010711081558838487
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 748 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.9279174804688
Eval_StdReturn : 4.591641426086426
Eval_MaxReturn : 956.6619873046875
Eval_MinReturn : 944.7066040039062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.9951171875
Train_StdReturn : 0.0
Train_MaxReturn : 944.9951171875
Train_MinReturn : 944.9951171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 748000
TimeSinceStart : 10730.967877864838
Training Loss : 0.0003627292753662914
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 749 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.8101806640625
Eval_StdReturn : 12.348830223083496
Eval_MaxReturn : 965.7040405273438
Eval_MinReturn : 932.0963134765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 927.3195190429688
Train_StdReturn : 0.0
Train_MaxReturn : 927.3195190429688
Train_MinReturn : 927.3195190429688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 749000
TimeSinceStart : 10752.165103912354
Training Loss : 0.00023268315999303013
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 750 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.3416748046875
Eval_StdReturn : 12.544733047485352
Eval_MaxReturn : 970.0121459960938
Eval_MinReturn : 930.80224609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.8798217773438
Train_StdReturn : 0.0
Train_MaxReturn : 945.8798217773438
Train_MinReturn : 945.8798217773438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 750000
TimeSinceStart : 10772.774938106537
Training Loss : 0.00017918122466653585
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 751 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.2262573242188
Eval_StdReturn : 6.792530059814453
Eval_MaxReturn : 963.7173461914062
Eval_MinReturn : 945.67919921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 921.5866088867188
Train_StdReturn : 0.0
Train_MaxReturn : 921.5866088867188
Train_MinReturn : 921.5866088867188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 751000
TimeSinceStart : 10793.878970384598
Training Loss : 0.00036540342262014747
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 752 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.2780151367188
Eval_StdReturn : 6.381009578704834
Eval_MaxReturn : 949.0662841796875
Eval_MinReturn : 932.9144287109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 926.833984375
Train_StdReturn : 0.0
Train_MaxReturn : 926.833984375
Train_MinReturn : 926.833984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 752000
TimeSinceStart : 10815.037081241608
Training Loss : 8.454024646198377e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 753 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.5162963867188
Eval_StdReturn : 12.410486221313477
Eval_MaxReturn : 953.436279296875
Eval_MinReturn : 918.4992065429688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.27587890625
Train_StdReturn : 0.0
Train_MaxReturn : 954.27587890625
Train_MinReturn : 954.27587890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 753000
TimeSinceStart : 10836.223007917404
Training Loss : 0.00040746285230852664
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 754 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.1145629882812
Eval_StdReturn : 6.650862216949463
Eval_MaxReturn : 957.3239135742188
Eval_MinReturn : 938.782958984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.4071044921875
Train_StdReturn : 0.0
Train_MaxReturn : 938.4071044921875
Train_MinReturn : 938.4071044921875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 754000
TimeSinceStart : 10858.24729514122
Training Loss : 0.0003584022051654756
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 755 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.8718872070312
Eval_StdReturn : 6.087678909301758
Eval_MaxReturn : 949.7302856445312
Eval_MinReturn : 931.5790405273438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.0501098632812
Train_StdReturn : 0.0
Train_MaxReturn : 956.0501098632812
Train_MinReturn : 956.0501098632812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 755000
TimeSinceStart : 10879.486221313477
Training Loss : 3.8484195101773366e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 756 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.7555541992188
Eval_StdReturn : 6.638689041137695
Eval_MaxReturn : 958.6176147460938
Eval_MinReturn : 938.490234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.324462890625
Train_StdReturn : 0.0
Train_MaxReturn : 945.324462890625
Train_MinReturn : 945.324462890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 756000
TimeSinceStart : 10901.661208868027
Training Loss : 0.00036877754610031843
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 757 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.8643798828125
Eval_StdReturn : 12.781761169433594
Eval_MaxReturn : 966.430419921875
Eval_MinReturn : 929.5970458984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.9341430664062
Train_StdReturn : 0.0
Train_MaxReturn : 955.9341430664062
Train_MinReturn : 955.9341430664062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 757000
TimeSinceStart : 10923.578790426254
Training Loss : 0.00012217361654620618
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 758 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.2342529296875
Eval_StdReturn : 7.695323467254639
Eval_MaxReturn : 951.7871704101562
Eval_MinReturn : 929.523193359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 960.2100219726562
Train_StdReturn : 0.0
Train_MaxReturn : 960.2100219726562
Train_MinReturn : 960.2100219726562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 758000
TimeSinceStart : 10945.651307344437
Training Loss : 0.00019127203267998993
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 759 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.3441162109375
Eval_StdReturn : 8.674810409545898
Eval_MaxReturn : 955.79736328125
Eval_MinReturn : 935.3687133789062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.8819580078125
Train_StdReturn : 0.0
Train_MaxReturn : 939.8819580078125
Train_MinReturn : 939.8819580078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 759000
TimeSinceStart : 10967.631325006485
Training Loss : 0.0002883497509174049
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 760 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.4949340820312
Eval_StdReturn : 11.742399215698242
Eval_MaxReturn : 957.048095703125
Eval_MinReturn : 923.5923461914062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.1629638671875
Train_StdReturn : 0.0
Train_MaxReturn : 943.1629638671875
Train_MinReturn : 943.1629638671875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 760000
TimeSinceStart : 10989.107112884521
Training Loss : 0.00017172079242300242
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 761 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 932.939453125
Eval_StdReturn : 9.6956787109375
Eval_MaxReturn : 945.4642333984375
Eval_MinReturn : 921.484619140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 930.6765747070312
Train_StdReturn : 0.0
Train_MaxReturn : 930.6765747070312
Train_MinReturn : 930.6765747070312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 761000
TimeSinceStart : 11010.142148971558
Training Loss : 9.43746927077882e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 762 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.7224731445312
Eval_StdReturn : 12.330772399902344
Eval_MaxReturn : 968.335693359375
Eval_MinReturn : 931.5888671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.0987548828125
Train_StdReturn : 0.0
Train_MaxReturn : 949.0987548828125
Train_MinReturn : 949.0987548828125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 762000
TimeSinceStart : 11031.28580546379
Training Loss : 0.0004827947122976184
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 763 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.2515869140625
Eval_StdReturn : 7.421084880828857
Eval_MaxReturn : 952.5285034179688
Eval_MinReturn : 931.040771484375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.13427734375
Train_StdReturn : 0.0
Train_MaxReturn : 940.13427734375
Train_MinReturn : 940.13427734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 763000
TimeSinceStart : 11052.873151540756
Training Loss : 0.00017261551693081856
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 764 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.0213012695312
Eval_StdReturn : 11.143282890319824
Eval_MaxReturn : 956.4150390625
Eval_MinReturn : 924.8665161132812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.7413330078125
Train_StdReturn : 0.0
Train_MaxReturn : 953.7413330078125
Train_MinReturn : 953.7413330078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 764000
TimeSinceStart : 11074.511424064636
Training Loss : 0.0004264750168658793
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 765 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.9278564453125
Eval_StdReturn : 12.715237617492676
Eval_MaxReturn : 956.7962646484375
Eval_MinReturn : 926.6555786132812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 957.56201171875
Train_StdReturn : 0.0
Train_MaxReturn : 957.56201171875
Train_MinReturn : 957.56201171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 765000
TimeSinceStart : 11096.19085240364
Training Loss : 5.07469849253539e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 766 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.8536987304688
Eval_StdReturn : 8.778617858886719
Eval_MaxReturn : 952.3516845703125
Eval_MinReturn : 932.4698486328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.111572265625
Train_StdReturn : 0.0
Train_MaxReturn : 937.111572265625
Train_MinReturn : 937.111572265625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 766000
TimeSinceStart : 11117.673461198807
Training Loss : 0.0002596704289317131
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 767 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.5521240234375
Eval_StdReturn : 3.2866225242614746
Eval_MaxReturn : 939.38134765625
Eval_MinReturn : 930.1491088867188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.2808227539062
Train_StdReturn : 0.0
Train_MaxReturn : 944.2808227539062
Train_MinReturn : 944.2808227539062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 767000
TimeSinceStart : 11139.218085765839
Training Loss : 0.00014729534450452775
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 768 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.8299560546875
Eval_StdReturn : 12.752946853637695
Eval_MaxReturn : 960.516845703125
Eval_MinReturn : 927.1793212890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.5096435546875
Train_StdReturn : 0.0
Train_MaxReturn : 941.5096435546875
Train_MinReturn : 941.5096435546875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 768000
TimeSinceStart : 11160.59793806076
Training Loss : 0.0001616724912310019
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 769 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.341796875
Eval_StdReturn : 10.730499267578125
Eval_MaxReturn : 955.731689453125
Eval_MinReturn : 926.8529663085938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.75830078125
Train_StdReturn : 0.0
Train_MaxReturn : 955.75830078125
Train_MinReturn : 955.75830078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 769000
TimeSinceStart : 11181.58764576912
Training Loss : 0.00018582097254693508
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 770 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.74267578125
Eval_StdReturn : 13.24931812286377
Eval_MaxReturn : 954.11181640625
Eval_MinReturn : 920.2051391601562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.6826171875
Train_StdReturn : 0.0
Train_MaxReturn : 949.6826171875
Train_MinReturn : 949.6826171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 770000
TimeSinceStart : 11202.912687063217
Training Loss : 0.0003435170801822096
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 771 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.8385009765625
Eval_StdReturn : 8.275138854980469
Eval_MaxReturn : 951.8009033203125
Eval_MinReturn : 930.95751953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 931.0989379882812
Train_StdReturn : 0.0
Train_MaxReturn : 931.0989379882812
Train_MinReturn : 931.0989379882812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 771000
TimeSinceStart : 11224.515340328217
Training Loss : 0.0004231926577631384
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 772 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.0543212890625
Eval_StdReturn : 8.288938522338867
Eval_MaxReturn : 948.1893920898438
Eval_MinReturn : 927.5717163085938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 932.5369873046875
Train_StdReturn : 0.0
Train_MaxReturn : 932.5369873046875
Train_MinReturn : 932.5369873046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 772000
TimeSinceStart : 11246.252028465271
Training Loss : 0.0008361138170585036
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 773 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.2449340820312
Eval_StdReturn : 7.773148536682129
Eval_MaxReturn : 949.10791015625
Eval_MinReturn : 927.249267578125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 925.6329345703125
Train_StdReturn : 0.0
Train_MaxReturn : 925.6329345703125
Train_MinReturn : 925.6329345703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 773000
TimeSinceStart : 11268.6653444767
Training Loss : 0.0003898130380548537
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 774 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.8634643554688
Eval_StdReturn : 7.027148246765137
Eval_MaxReturn : 962.3896484375
Eval_MinReturn : 943.4571533203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.5608520507812
Train_StdReturn : 0.0
Train_MaxReturn : 933.5608520507812
Train_MinReturn : 933.5608520507812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 774000
TimeSinceStart : 11289.56225681305
Training Loss : 0.0004529471625573933
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 775 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 953.2008056640625
Eval_StdReturn : 12.219066619873047
Eval_MaxReturn : 964.716064453125
Eval_MinReturn : 932.254638671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.912109375
Train_StdReturn : 0.0
Train_MaxReturn : 941.912109375
Train_MinReturn : 941.912109375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 775000
TimeSinceStart : 11311.010858774185
Training Loss : 0.0006820536800660193
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 776 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 954.2469482421875
Eval_StdReturn : 9.806280136108398
Eval_MaxReturn : 968.0093994140625
Eval_MinReturn : 941.2777099609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.3143310546875
Train_StdReturn : 0.0
Train_MaxReturn : 952.3143310546875
Train_MinReturn : 952.3143310546875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 776000
TimeSinceStart : 11332.743177890778
Training Loss : 0.0003394031373318285
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 777 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.0380859375
Eval_StdReturn : 9.865799903869629
Eval_MaxReturn : 959.9200439453125
Eval_MinReturn : 930.198486328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.8797607421875
Train_StdReturn : 0.0
Train_MaxReturn : 943.8797607421875
Train_MinReturn : 943.8797607421875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 777000
TimeSinceStart : 11354.687011957169
Training Loss : 0.00011569868365768343
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 778 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.8655395507812
Eval_StdReturn : 7.83620548248291
Eval_MaxReturn : 955.4215087890625
Eval_MinReturn : 932.43994140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.4155883789062
Train_StdReturn : 0.0
Train_MaxReturn : 947.4155883789062
Train_MinReturn : 947.4155883789062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 778000
TimeSinceStart : 11376.632107019424
Training Loss : 0.0001614138891454786
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 779 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.8106689453125
Eval_StdReturn : 19.7912654876709
Eval_MaxReturn : 971.1243896484375
Eval_MinReturn : 914.0042114257812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 964.6909790039062
Train_StdReturn : 0.0
Train_MaxReturn : 964.6909790039062
Train_MinReturn : 964.6909790039062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 779000
TimeSinceStart : 11398.673133611679
Training Loss : 0.0001846653176471591
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 780 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 956.0319213867188
Eval_StdReturn : 6.725000381469727
Eval_MaxReturn : 961.7603759765625
Eval_MinReturn : 943.447998046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.8104858398438
Train_StdReturn : 0.0
Train_MaxReturn : 941.8104858398438
Train_MinReturn : 941.8104858398438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 780000
TimeSinceStart : 11420.716814279556
Training Loss : 0.0003711738681886345
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 781 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.5089721679688
Eval_StdReturn : 15.063879013061523
Eval_MaxReturn : 967.4788818359375
Eval_MinReturn : 926.0772705078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 932.574951171875
Train_StdReturn : 0.0
Train_MaxReturn : 932.574951171875
Train_MinReturn : 932.574951171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 781000
TimeSinceStart : 11442.582618236542
Training Loss : 9.658290218794718e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 782 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.9915161132812
Eval_StdReturn : 5.297686576843262
Eval_MaxReturn : 943.8784790039062
Eval_MinReturn : 928.1631469726562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.5447998046875
Train_StdReturn : 0.0
Train_MaxReturn : 956.5447998046875
Train_MinReturn : 956.5447998046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 782000
TimeSinceStart : 11464.525140047073
Training Loss : 0.0001468737900722772
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 783 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.8572387695312
Eval_StdReturn : 9.501694679260254
Eval_MaxReturn : 964.2484130859375
Eval_MinReturn : 936.4322509765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.6329345703125
Train_StdReturn : 0.0
Train_MaxReturn : 937.6329345703125
Train_MinReturn : 937.6329345703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 783000
TimeSinceStart : 11486.502100229263
Training Loss : 9.732702892506495e-06
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 784 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 935.8427734375
Eval_StdReturn : 14.471293449401855
Eval_MaxReturn : 962.6455078125
Eval_MinReturn : 920.9932861328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.7286987304688
Train_StdReturn : 0.0
Train_MaxReturn : 934.7286987304688
Train_MinReturn : 934.7286987304688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 784000
TimeSinceStart : 11508.907401561737
Training Loss : 0.0003223542298655957
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 785 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.2349853515625
Eval_StdReturn : 9.872718811035156
Eval_MaxReturn : 954.8890380859375
Eval_MinReturn : 928.9419555664062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.0338134765625
Train_StdReturn : 0.0
Train_MaxReturn : 946.0338134765625
Train_MinReturn : 946.0338134765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 785000
TimeSinceStart : 11531.0228805542
Training Loss : 0.00023548275930806994
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 786 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.1165161132812
Eval_StdReturn : 13.537694931030273
Eval_MaxReturn : 958.5548706054688
Eval_MinReturn : 923.485107421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.2294921875
Train_StdReturn : 0.0
Train_MaxReturn : 949.2294921875
Train_MinReturn : 949.2294921875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 786000
TimeSinceStart : 11553.356341838837
Training Loss : 0.00028177202329970896
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 787 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.4080200195312
Eval_StdReturn : 12.05927848815918
Eval_MaxReturn : 955.0986328125
Eval_MinReturn : 921.8422241210938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.105224609375
Train_StdReturn : 0.0
Train_MaxReturn : 946.105224609375
Train_MinReturn : 946.105224609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 787000
TimeSinceStart : 11575.526226997375
Training Loss : 0.00021765247220173478
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 788 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.935546875
Eval_StdReturn : 3.3819053173065186
Eval_MaxReturn : 945.6370849609375
Eval_MinReturn : 935.935302734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.0562133789062
Train_StdReturn : 0.0
Train_MaxReturn : 950.0562133789062
Train_MinReturn : 950.0562133789062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 788000
TimeSinceStart : 11597.549975156784
Training Loss : 0.0002976493851747364
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 789 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.5550537109375
Eval_StdReturn : 9.806183815002441
Eval_MaxReturn : 949.2906494140625
Eval_MinReturn : 919.5723266601562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.996826171875
Train_StdReturn : 0.0
Train_MaxReturn : 936.996826171875
Train_MinReturn : 936.996826171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 789000
TimeSinceStart : 11619.454146385193
Training Loss : 0.0001906619145302102
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 790 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.7681884765625
Eval_StdReturn : 4.797225475311279
Eval_MaxReturn : 946.3482666015625
Eval_MinReturn : 932.414306640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.4951782226562
Train_StdReturn : 0.0
Train_MaxReturn : 953.4951782226562
Train_MinReturn : 953.4951782226562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 790000
TimeSinceStart : 11642.10110116005
Training Loss : 9.25757922232151e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 791 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.9600830078125
Eval_StdReturn : 8.312708854675293
Eval_MaxReturn : 956.5847778320312
Eval_MinReturn : 931.276123046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.966796875
Train_StdReturn : 0.0
Train_MaxReturn : 934.966796875
Train_MinReturn : 934.966796875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 791000
TimeSinceStart : 11664.408421039581
Training Loss : 0.00017993651272263378
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 792 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.9157104492188
Eval_StdReturn : 4.224298000335693
Eval_MaxReturn : 953.6618041992188
Eval_MinReturn : 940.7398681640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 930.7850341796875
Train_StdReturn : 0.0
Train_MaxReturn : 930.7850341796875
Train_MinReturn : 930.7850341796875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 792000
TimeSinceStart : 11686.647382497787
Training Loss : 0.0003283530822955072
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 793 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.1301879882812
Eval_StdReturn : 8.5610933303833
Eval_MaxReturn : 954.8990478515625
Eval_MinReturn : 931.94970703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 930.885009765625
Train_StdReturn : 0.0
Train_MaxReturn : 930.885009765625
Train_MinReturn : 930.885009765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 793000
TimeSinceStart : 11708.905350923538
Training Loss : 0.00011977496615145355
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 794 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.9816284179688
Eval_StdReturn : 7.680609703063965
Eval_MaxReturn : 950.2732543945312
Eval_MinReturn : 928.0166625976562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.0415649414062
Train_StdReturn : 0.0
Train_MaxReturn : 936.0415649414062
Train_MinReturn : 936.0415649414062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 794000
TimeSinceStart : 11730.906465053558
Training Loss : 9.089829109143466e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 795 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.5379638671875
Eval_StdReturn : 8.278255462646484
Eval_MaxReturn : 956.3138427734375
Eval_MinReturn : 932.283203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 913.1101684570312
Train_StdReturn : 0.0
Train_MaxReturn : 913.1101684570312
Train_MinReturn : 913.1101684570312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 795000
TimeSinceStart : 11753.471262693405
Training Loss : 6.25412430963479e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 796 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 956.6696166992188
Eval_StdReturn : 10.310070991516113
Eval_MaxReturn : 971.6051025390625
Eval_MinReturn : 942.7357177734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.6796875
Train_StdReturn : 0.0
Train_MaxReturn : 946.6796875
Train_MinReturn : 946.6796875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 796000
TimeSinceStart : 11775.723129987717
Training Loss : 0.0003480237501207739
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 797 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.7542724609375
Eval_StdReturn : 9.614723205566406
Eval_MaxReturn : 961.9727783203125
Eval_MinReturn : 937.1718139648438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.5468139648438
Train_StdReturn : 0.0
Train_MaxReturn : 954.5468139648438
Train_MinReturn : 954.5468139648438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 797000
TimeSinceStart : 11797.784060955048
Training Loss : 0.00039212044794112444
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 798 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.3524169921875
Eval_StdReturn : 14.750787734985352
Eval_MaxReturn : 955.5679931640625
Eval_MinReturn : 919.4780883789062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 960.228515625
Train_StdReturn : 0.0
Train_MaxReturn : 960.228515625
Train_MinReturn : 960.228515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 798000
TimeSinceStart : 11820.47363948822
Training Loss : 4.124157931073569e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 799 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 957.1444091796875
Eval_StdReturn : 10.570085525512695
Eval_MaxReturn : 968.4730224609375
Eval_MinReturn : 938.6936645507812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 925.9410400390625
Train_StdReturn : 0.0
Train_MaxReturn : 925.9410400390625
Train_MinReturn : 925.9410400390625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 799000
TimeSinceStart : 11843.675242185593
Training Loss : 8.244827040471137e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 800 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 935.3639526367188
Eval_StdReturn : 9.76347827911377
Eval_MaxReturn : 952.8106689453125
Eval_MinReturn : 925.5560913085938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.6723022460938
Train_StdReturn : 0.0
Train_MaxReturn : 958.6723022460938
Train_MinReturn : 958.6723022460938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 800000
TimeSinceStart : 11866.207187891006
Training Loss : 8.633700053906068e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 801 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.1741943359375
Eval_StdReturn : 8.9111909866333
Eval_MaxReturn : 956.971435546875
Eval_MinReturn : 934.688720703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.5361328125
Train_StdReturn : 0.0
Train_MaxReturn : 950.5361328125
Train_MinReturn : 950.5361328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 801000
TimeSinceStart : 11888.46637916565
Training Loss : 2.4616656446596608e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 802 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.7821044921875
Eval_StdReturn : 7.45050048828125
Eval_MaxReturn : 953.0050048828125
Eval_MinReturn : 931.1182861328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.6959228515625
Train_StdReturn : 0.0
Train_MaxReturn : 950.6959228515625
Train_MinReturn : 950.6959228515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 802000
TimeSinceStart : 11910.91441988945
Training Loss : 3.7250134482746944e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 803 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.9549560546875
Eval_StdReturn : 10.272995948791504
Eval_MaxReturn : 956.0785522460938
Eval_MinReturn : 926.897705078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.697021484375
Train_StdReturn : 0.0
Train_MaxReturn : 958.697021484375
Train_MinReturn : 958.697021484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 803000
TimeSinceStart : 11933.002666711807
Training Loss : 0.0004972548922523856
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 804 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 955.890625
Eval_StdReturn : 4.67462158203125
Eval_MaxReturn : 963.190185546875
Eval_MinReturn : 950.1524658203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.0848388671875
Train_StdReturn : 0.0
Train_MaxReturn : 944.0848388671875
Train_MinReturn : 944.0848388671875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 804000
TimeSinceStart : 11955.416400671005
Training Loss : 0.00030300836078822613
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 805 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.5772705078125
Eval_StdReturn : 2.787738800048828
Eval_MaxReturn : 942.4559936523438
Eval_MinReturn : 934.8380126953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.6062622070312
Train_StdReturn : 0.0
Train_MaxReturn : 948.6062622070312
Train_MinReturn : 948.6062622070312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 805000
TimeSinceStart : 11977.511549711227
Training Loss : 0.00037488937960006297
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 806 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.6808471679688
Eval_StdReturn : 9.074675559997559
Eval_MaxReturn : 955.0086669921875
Eval_MinReturn : 930.82177734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.0252075195312
Train_StdReturn : 0.0
Train_MaxReturn : 948.0252075195312
Train_MinReturn : 948.0252075195312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 806000
TimeSinceStart : 11999.82609987259
Training Loss : 4.1522558603901416e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 807 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.2444458007812
Eval_StdReturn : 7.3616862297058105
Eval_MaxReturn : 953.1082153320312
Eval_MinReturn : 931.1295166015625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.7318115234375
Train_StdReturn : 0.0
Train_MaxReturn : 949.7318115234375
Train_MinReturn : 949.7318115234375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 807000
TimeSinceStart : 12022.460245609283
Training Loss : 1.5296665878850035e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 808 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.9996337890625
Eval_StdReturn : 10.525087356567383
Eval_MaxReturn : 957.2503662109375
Eval_MinReturn : 929.390380859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 959.4008178710938
Train_StdReturn : 0.0
Train_MaxReturn : 959.4008178710938
Train_MinReturn : 959.4008178710938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 808000
TimeSinceStart : 12044.734038114548
Training Loss : 0.0003153079014737159
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 809 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 953.9061279296875
Eval_StdReturn : 5.152307510375977
Eval_MaxReturn : 963.875
Eval_MinReturn : 949.8929443359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.0267944335938
Train_StdReturn : 0.0
Train_MaxReturn : 956.0267944335938
Train_MinReturn : 956.0267944335938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 809000
TimeSinceStart : 12067.160942077637
Training Loss : 0.00036985406768508255
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 810 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.162109375
Eval_StdReturn : 5.0746049880981445
Eval_MaxReturn : 954.61376953125
Eval_MinReturn : 940.0787353515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.545654296875
Train_StdReturn : 0.0
Train_MaxReturn : 954.545654296875
Train_MinReturn : 954.545654296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 810000
TimeSinceStart : 12090.189162492752
Training Loss : 0.0004302695160731673
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 811 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.9281005859375
Eval_StdReturn : 7.214410305023193
Eval_MaxReturn : 954.440673828125
Eval_MinReturn : 934.33056640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 928.46630859375
Train_StdReturn : 0.0
Train_MaxReturn : 928.46630859375
Train_MinReturn : 928.46630859375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 811000
TimeSinceStart : 12112.549060821533
Training Loss : 0.00038043377571739256
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 812 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.7385864257812
Eval_StdReturn : 13.161535263061523
Eval_MaxReturn : 963.3663330078125
Eval_MinReturn : 925.31787109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.7491455078125
Train_StdReturn : 0.0
Train_MaxReturn : 934.7491455078125
Train_MinReturn : 934.7491455078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 812000
TimeSinceStart : 12134.524148702621
Training Loss : 0.0007343061151914299
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 813 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.6238403320312
Eval_StdReturn : 9.31061840057373
Eval_MaxReturn : 956.5068969726562
Eval_MinReturn : 929.74951171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 928.4948120117188
Train_StdReturn : 0.0
Train_MaxReturn : 928.4948120117188
Train_MinReturn : 928.4948120117188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 813000
TimeSinceStart : 12157.062890291214
Training Loss : 0.00030497173429466784
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 814 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.9091796875
Eval_StdReturn : 12.255871772766113
Eval_MaxReturn : 954.078369140625
Eval_MinReturn : 924.6834716796875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.9371948242188
Train_StdReturn : 0.0
Train_MaxReturn : 942.9371948242188
Train_MinReturn : 942.9371948242188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 814000
TimeSinceStart : 12179.710189342499
Training Loss : 8.4536564827431e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 815 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.5455322265625
Eval_StdReturn : 13.374306678771973
Eval_MaxReturn : 962.9154052734375
Eval_MinReturn : 925.6387939453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.2482299804688
Train_StdReturn : 0.0
Train_MaxReturn : 951.2482299804688
Train_MinReturn : 951.2482299804688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 815000
TimeSinceStart : 12202.84919309616
Training Loss : 0.0006241978844627738
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 816 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.4908447265625
Eval_StdReturn : 8.045958518981934
Eval_MaxReturn : 954.044677734375
Eval_MinReturn : 935.679443359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.77294921875
Train_StdReturn : 0.0
Train_MaxReturn : 950.77294921875
Train_MinReturn : 950.77294921875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 816000
TimeSinceStart : 12225.50050830841
Training Loss : 0.0002322803920833394
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 817 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.7927856445312
Eval_StdReturn : 10.887993812561035
Eval_MaxReturn : 952.6852416992188
Eval_MinReturn : 922.0744018554688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.282470703125
Train_StdReturn : 0.0
Train_MaxReturn : 936.282470703125
Train_MinReturn : 936.282470703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 817000
TimeSinceStart : 12248.500690460205
Training Loss : 9.861822763923556e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 818 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.6365356445312
Eval_StdReturn : 7.921445369720459
Eval_MaxReturn : 958.3195190429688
Eval_MinReturn : 934.7670288085938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.0303955078125
Train_StdReturn : 0.0
Train_MaxReturn : 937.0303955078125
Train_MinReturn : 937.0303955078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 818000
TimeSinceStart : 12271.33793926239
Training Loss : 2.6652600354282185e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 819 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 953.4075317382812
Eval_StdReturn : 5.372467517852783
Eval_MaxReturn : 964.0631103515625
Eval_MinReturn : 949.708984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.0946044921875
Train_StdReturn : 0.0
Train_MaxReturn : 939.0946044921875
Train_MinReturn : 939.0946044921875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 819000
TimeSinceStart : 12293.985978841782
Training Loss : 0.00020036534988321364
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 820 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 952.3697509765625
Eval_StdReturn : 9.843084335327148
Eval_MaxReturn : 965.24462890625
Eval_MinReturn : 941.049072265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.7783203125
Train_StdReturn : 0.0
Train_MaxReturn : 958.7783203125
Train_MinReturn : 958.7783203125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 820000
TimeSinceStart : 12316.571355104446
Training Loss : 5.135108585818671e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 821 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.66943359375
Eval_StdReturn : 7.892369747161865
Eval_MaxReturn : 947.8785400390625
Eval_MinReturn : 927.5206298828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.49072265625
Train_StdReturn : 0.0
Train_MaxReturn : 948.49072265625
Train_MinReturn : 948.49072265625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 821000
TimeSinceStart : 12339.043561935425
Training Loss : 0.00017138280963990837
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 822 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.1822509765625
Eval_StdReturn : 13.07625961303711
Eval_MaxReturn : 961.6814575195312
Eval_MinReturn : 929.986328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 957.1309814453125
Train_StdReturn : 0.0
Train_MaxReturn : 957.1309814453125
Train_MinReturn : 957.1309814453125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 822000
TimeSinceStart : 12361.808080673218
Training Loss : 0.0006029581418260932
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 823 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.6393432617188
Eval_StdReturn : 7.8312530517578125
Eval_MaxReturn : 949.77490234375
Eval_MinReturn : 929.7882080078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.0260009765625
Train_StdReturn : 0.0
Train_MaxReturn : 943.0260009765625
Train_MinReturn : 943.0260009765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 823000
TimeSinceStart : 12385.092429876328
Training Loss : 0.0001576419163029641
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 824 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.6404418945312
Eval_StdReturn : 6.061091899871826
Eval_MaxReturn : 949.4632568359375
Eval_MinReturn : 930.36572265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.7695922851562
Train_StdReturn : 0.0
Train_MaxReturn : 956.7695922851562
Train_MinReturn : 956.7695922851562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 824000
TimeSinceStart : 12407.913891792297
Training Loss : 0.00013821484753862023
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 825 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.7916870117188
Eval_StdReturn : 6.519522190093994
Eval_MaxReturn : 950.099365234375
Eval_MinReturn : 931.941650390625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 962.3316650390625
Train_StdReturn : 0.0
Train_MaxReturn : 962.3316650390625
Train_MinReturn : 962.3316650390625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 825000
TimeSinceStart : 12430.660358190536
Training Loss : 0.0003113134007435292
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 826 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.0517578125
Eval_StdReturn : 8.169599533081055
Eval_MaxReturn : 949.4093627929688
Eval_MinReturn : 924.2325439453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.400146484375
Train_StdReturn : 0.0
Train_MaxReturn : 947.400146484375
Train_MinReturn : 947.400146484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 826000
TimeSinceStart : 12453.275833129883
Training Loss : 0.00025530997663736343
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 827 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.5443115234375
Eval_StdReturn : 4.8642354011535645
Eval_MaxReturn : 953.922119140625
Eval_MinReturn : 940.7687377929688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.6796875
Train_StdReturn : 0.0
Train_MaxReturn : 946.6796875
Train_MinReturn : 946.6796875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 827000
TimeSinceStart : 12476.434005022049
Training Loss : 0.00013718903937842697
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 828 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.1962890625
Eval_StdReturn : 10.791013717651367
Eval_MaxReturn : 959.4915771484375
Eval_MinReturn : 929.32177734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 925.1535034179688
Train_StdReturn : 0.0
Train_MaxReturn : 925.1535034179688
Train_MinReturn : 925.1535034179688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 828000
TimeSinceStart : 12498.805489778519
Training Loss : 0.0007244449807330966
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 829 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.5531005859375
Eval_StdReturn : 10.783791542053223
Eval_MaxReturn : 960.3544311523438
Eval_MinReturn : 932.1954345703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.0755615234375
Train_StdReturn : 0.0
Train_MaxReturn : 941.0755615234375
Train_MinReturn : 941.0755615234375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 829000
TimeSinceStart : 12521.61645770073
Training Loss : 0.00021289159485604614
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 830 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.92529296875
Eval_StdReturn : 6.869593143463135
Eval_MaxReturn : 956.5498046875
Eval_MinReturn : 935.738525390625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 931.454833984375
Train_StdReturn : 0.0
Train_MaxReturn : 931.454833984375
Train_MinReturn : 931.454833984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 830000
TimeSinceStart : 12544.021942615509
Training Loss : 8.02609501988627e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 831 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 954.7335205078125
Eval_StdReturn : 10.4111328125
Eval_MaxReturn : 967.599609375
Eval_MinReturn : 940.9319458007812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 928.4317016601562
Train_StdReturn : 0.0
Train_MaxReturn : 928.4317016601562
Train_MinReturn : 928.4317016601562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 831000
TimeSinceStart : 12566.723778009415
Training Loss : 0.001208431669510901
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 832 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.5499877929688
Eval_StdReturn : 4.377078533172607
Eval_MaxReturn : 952.4443969726562
Eval_MinReturn : 939.638427734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.7449340820312
Train_StdReturn : 0.0
Train_MaxReturn : 958.7449340820312
Train_MinReturn : 958.7449340820312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 832000
TimeSinceStart : 12589.611265182495
Training Loss : 0.00012736032658722252
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 833 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.0798950195312
Eval_StdReturn : 8.04648494720459
Eval_MaxReturn : 950.0147094726562
Eval_MinReturn : 929.0247192382812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 932.5111083984375
Train_StdReturn : 0.0
Train_MaxReturn : 932.5111083984375
Train_MinReturn : 932.5111083984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 833000
TimeSinceStart : 12612.337339878082
Training Loss : 0.0007518161437474191
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 834 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.2966918945312
Eval_StdReturn : 8.873581886291504
Eval_MaxReturn : 963.896484375
Eval_MinReturn : 939.6536254882812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.9609375
Train_StdReturn : 0.0
Train_MaxReturn : 943.9609375
Train_MinReturn : 943.9609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 834000
TimeSinceStart : 12635.29945397377
Training Loss : 0.00018279846699442714
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 835 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.8785400390625
Eval_StdReturn : 11.37988567352295
Eval_MaxReturn : 959.3104858398438
Eval_MinReturn : 929.7982788085938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.0712890625
Train_StdReturn : 0.0
Train_MaxReturn : 938.0712890625
Train_MinReturn : 938.0712890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 835000
TimeSinceStart : 12658.121070861816
Training Loss : 0.00028297840617597103
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 836 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.7432861328125
Eval_StdReturn : 12.669882774353027
Eval_MaxReturn : 958.6885986328125
Eval_MinReturn : 929.14306640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.2318115234375
Train_StdReturn : 0.0
Train_MaxReturn : 941.2318115234375
Train_MinReturn : 941.2318115234375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 836000
TimeSinceStart : 12681.589821577072
Training Loss : 0.0001902869698824361
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 837 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.2576904296875
Eval_StdReturn : 10.109715461730957
Eval_MaxReturn : 956.259765625
Eval_MinReturn : 928.532958984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.8713989257812
Train_StdReturn : 0.0
Train_MaxReturn : 955.8713989257812
Train_MinReturn : 955.8713989257812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 837000
TimeSinceStart : 12704.222627878189
Training Loss : 0.0002680400793906301
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 838 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.2081298828125
Eval_StdReturn : 13.324801445007324
Eval_MaxReturn : 964.04296875
Eval_MinReturn : 923.7559204101562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.929443359375
Train_StdReturn : 0.0
Train_MaxReturn : 958.929443359375
Train_MinReturn : 958.929443359375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 838000
TimeSinceStart : 12727.59088420868
Training Loss : 0.0003373733488842845
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 839 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.5305786132812
Eval_StdReturn : 9.03869915008545
Eval_MaxReturn : 961.5020751953125
Eval_MinReturn : 933.1043090820312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.7199096679688
Train_StdReturn : 0.0
Train_MaxReturn : 949.7199096679688
Train_MinReturn : 949.7199096679688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 839000
TimeSinceStart : 12750.558433055878
Training Loss : 0.00021374998323153704
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 840 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.3401489257812
Eval_StdReturn : 7.54908561706543
Eval_MaxReturn : 956.380615234375
Eval_MinReturn : 934.5572509765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 917.1688232421875
Train_StdReturn : 0.0
Train_MaxReturn : 917.1688232421875
Train_MinReturn : 917.1688232421875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 840000
TimeSinceStart : 12773.876684904099
Training Loss : 0.00041666324250400066
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 841 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.4928588867188
Eval_StdReturn : 14.03458023071289
Eval_MaxReturn : 956.4820556640625
Eval_MinReturn : 923.016845703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.3048095703125
Train_StdReturn : 0.0
Train_MaxReturn : 942.3048095703125
Train_MinReturn : 942.3048095703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 841000
TimeSinceStart : 12796.878654956818
Training Loss : 0.0006192710134200752
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 842 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.6853637695312
Eval_StdReturn : 6.234903812408447
Eval_MaxReturn : 959.2987060546875
Eval_MinReturn : 940.2965698242188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.5398559570312
Train_StdReturn : 0.0
Train_MaxReturn : 948.5398559570312
Train_MinReturn : 948.5398559570312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 842000
TimeSinceStart : 12820.139955759048
Training Loss : 0.0002988574269693345
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 843 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.400390625
Eval_StdReturn : 7.014567852020264
Eval_MaxReturn : 957.7472534179688
Eval_MinReturn : 939.53857421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.67822265625
Train_StdReturn : 0.0
Train_MaxReturn : 946.67822265625
Train_MinReturn : 946.67822265625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 843000
TimeSinceStart : 12843.260072231293
Training Loss : 0.0001611274783499539
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 844 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 929.5559692382812
Eval_StdReturn : 12.450528144836426
Eval_MaxReturn : 947.6309204101562
Eval_MinReturn : 918.0938720703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.3720703125
Train_StdReturn : 0.0
Train_MaxReturn : 956.3720703125
Train_MinReturn : 956.3720703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 844000
TimeSinceStart : 12865.614456176758
Training Loss : 0.00032074470072984695
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 845 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.7747802734375
Eval_StdReturn : 10.436373710632324
Eval_MaxReturn : 962.1339111328125
Eval_MinReturn : 933.5849609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.0126953125
Train_StdReturn : 0.0
Train_MaxReturn : 940.0126953125
Train_MinReturn : 940.0126953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 845000
TimeSinceStart : 12888.669525146484
Training Loss : 0.0003246694977860898
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 846 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 934.9039916992188
Eval_StdReturn : 9.053115844726562
Eval_MaxReturn : 950.2691040039062
Eval_MinReturn : 924.0684814453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 969.8739013671875
Train_StdReturn : 0.0
Train_MaxReturn : 969.8739013671875
Train_MinReturn : 969.8739013671875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 846000
TimeSinceStart : 12911.217884540558
Training Loss : 9.876610420178622e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 847 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.130859375
Eval_StdReturn : 11.448952674865723
Eval_MaxReturn : 955.836181640625
Eval_MinReturn : 923.3605346679688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.8742065429688
Train_StdReturn : 0.0
Train_MaxReturn : 934.8742065429688
Train_MinReturn : 934.8742065429688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 847000
TimeSinceStart : 12933.273193120956
Training Loss : 5.7215987908421084e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 848 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.7044677734375
Eval_StdReturn : 5.408536911010742
Eval_MaxReturn : 956.8226318359375
Eval_MinReturn : 940.41845703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.5963134765625
Train_StdReturn : 0.0
Train_MaxReturn : 934.5963134765625
Train_MinReturn : 934.5963134765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 848000
TimeSinceStart : 12956.262485265732
Training Loss : 0.0004550972953438759
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 849 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.1240234375
Eval_StdReturn : 5.289253234863281
Eval_MaxReturn : 952.733642578125
Eval_MinReturn : 937.00537109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.794677734375
Train_StdReturn : 0.0
Train_MaxReturn : 947.794677734375
Train_MinReturn : 947.794677734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 849000
TimeSinceStart : 12979.415778875351
Training Loss : 0.00013775558909401298
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 850 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.1231689453125
Eval_StdReturn : 5.334903717041016
Eval_MaxReturn : 954.3109130859375
Eval_MinReturn : 941.9564208984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.055419921875
Train_StdReturn : 0.0
Train_MaxReturn : 941.055419921875
Train_MinReturn : 941.055419921875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 850000
TimeSinceStart : 13001.988856554031
Training Loss : 5.48952812096104e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 851 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.2391357421875
Eval_StdReturn : 13.595865249633789
Eval_MaxReturn : 965.5408935546875
Eval_MinReturn : 928.6808471679688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.5311279296875
Train_StdReturn : 0.0
Train_MaxReturn : 951.5311279296875
Train_MinReturn : 951.5311279296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 851000
TimeSinceStart : 13025.330188512802
Training Loss : 0.00016314417007379234
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 852 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.8572998046875
Eval_StdReturn : 10.136706352233887
Eval_MaxReturn : 957.8516845703125
Eval_MinReturn : 926.7870483398438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.986328125
Train_StdReturn : 0.0
Train_MaxReturn : 935.986328125
Train_MinReturn : 935.986328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 852000
TimeSinceStart : 13048.797320604324
Training Loss : 4.93821753480006e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 853 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.7931518554688
Eval_StdReturn : 5.734574317932129
Eval_MaxReturn : 955.1697387695312
Eval_MinReturn : 938.62939453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.38525390625
Train_StdReturn : 0.0
Train_MaxReturn : 954.38525390625
Train_MinReturn : 954.38525390625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 853000
TimeSinceStart : 13072.128007411957
Training Loss : 0.0005693254643119872
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 854 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.40185546875
Eval_StdReturn : 5.572780132293701
Eval_MaxReturn : 954.8179931640625
Eval_MinReturn : 939.5814208984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.5299682617188
Train_StdReturn : 0.0
Train_MaxReturn : 947.5299682617188
Train_MinReturn : 947.5299682617188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 854000
TimeSinceStart : 13095.953217506409
Training Loss : 0.0005424544215202332
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 855 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.029296875
Eval_StdReturn : 15.66238784790039
Eval_MaxReturn : 962.5318603515625
Eval_MinReturn : 915.2884521484375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.98779296875
Train_StdReturn : 0.0
Train_MaxReturn : 949.98779296875
Train_MinReturn : 949.98779296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 855000
TimeSinceStart : 13118.81510424614
Training Loss : 0.00020374011364765465
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 856 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.0104370117188
Eval_StdReturn : 8.97260570526123
Eval_MaxReturn : 957.9405517578125
Eval_MinReturn : 933.3912353515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 930.7194213867188
Train_StdReturn : 0.0
Train_MaxReturn : 930.7194213867188
Train_MinReturn : 930.7194213867188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 856000
TimeSinceStart : 13141.66718673706
Training Loss : 0.0003037324349861592
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 857 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.3697509765625
Eval_StdReturn : 13.038623809814453
Eval_MaxReturn : 961.813720703125
Eval_MinReturn : 924.2166748046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 927.905517578125
Train_StdReturn : 0.0
Train_MaxReturn : 927.905517578125
Train_MinReturn : 927.905517578125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 857000
TimeSinceStart : 13165.111967086792
Training Loss : 0.00016066571697592735
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 858 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.9552612304688
Eval_StdReturn : 4.488722801208496
Eval_MaxReturn : 940.689453125
Eval_MinReturn : 928.373779296875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.28173828125
Train_StdReturn : 0.0
Train_MaxReturn : 943.28173828125
Train_MinReturn : 943.28173828125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 858000
TimeSinceStart : 13188.723357915878
Training Loss : 1.8832670320989564e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 859 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.7189331054688
Eval_StdReturn : 9.183417320251465
Eval_MaxReturn : 953.5299072265625
Eval_MinReturn : 926.6761474609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.988037109375
Train_StdReturn : 0.0
Train_MaxReturn : 942.988037109375
Train_MinReturn : 942.988037109375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 859000
TimeSinceStart : 13212.1251745224
Training Loss : 7.467903924407437e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 860 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.8734130859375
Eval_StdReturn : 12.818094253540039
Eval_MaxReturn : 959.9197998046875
Eval_MinReturn : 926.0223388671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 927.2789306640625
Train_StdReturn : 0.0
Train_MaxReturn : 927.2789306640625
Train_MinReturn : 927.2789306640625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 860000
TimeSinceStart : 13235.724729776382
Training Loss : 0.00011029131565010175
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 861 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.3255004882812
Eval_StdReturn : 9.817096710205078
Eval_MaxReturn : 957.4080810546875
Eval_MinReturn : 931.9829711914062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.9332275390625
Train_StdReturn : 0.0
Train_MaxReturn : 951.9332275390625
Train_MinReturn : 951.9332275390625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 861000
TimeSinceStart : 13259.43699336052
Training Loss : 0.00023972033523023129
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 862 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.4483642578125
Eval_StdReturn : 3.278757333755493
Eval_MaxReturn : 953.9445190429688
Eval_MinReturn : 944.9864501953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.1583251953125
Train_StdReturn : 0.0
Train_MaxReturn : 945.1583251953125
Train_MinReturn : 945.1583251953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 862000
TimeSinceStart : 13282.24179816246
Training Loss : 3.144302172586322e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 863 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 956.3223876953125
Eval_StdReturn : 7.162271499633789
Eval_MaxReturn : 970.39990234375
Eval_MinReturn : 951.1567993164062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 932.56396484375
Train_StdReturn : 0.0
Train_MaxReturn : 932.56396484375
Train_MinReturn : 932.56396484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 863000
TimeSinceStart : 13305.181878328323
Training Loss : 0.0002629406226333231
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 864 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 954.5433349609375
Eval_StdReturn : 8.736586570739746
Eval_MaxReturn : 962.5432739257812
Eval_MinReturn : 937.566162109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 959.6862182617188
Train_StdReturn : 0.0
Train_MaxReturn : 959.6862182617188
Train_MinReturn : 959.6862182617188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 864000
TimeSinceStart : 13327.470288276672
Training Loss : 0.00024907008628360927
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 865 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.5404052734375
Eval_StdReturn : 7.926698207855225
Eval_MaxReturn : 958.90576171875
Eval_MinReturn : 937.64794921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.1729736328125
Train_StdReturn : 0.0
Train_MaxReturn : 953.1729736328125
Train_MinReturn : 953.1729736328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 865000
TimeSinceStart : 13350.65196108818
Training Loss : 0.0002348539128433913
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 866 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.7982177734375
Eval_StdReturn : 9.969114303588867
Eval_MaxReturn : 954.3564453125
Eval_MinReturn : 925.912109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.4249267578125
Train_StdReturn : 0.0
Train_MaxReturn : 947.4249267578125
Train_MinReturn : 947.4249267578125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 866000
TimeSinceStart : 13373.761675596237
Training Loss : 0.00025900956825353205
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 867 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.0390625
Eval_StdReturn : 7.758059024810791
Eval_MaxReturn : 958.4264526367188
Eval_MinReturn : 934.87109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.876953125
Train_StdReturn : 0.0
Train_MaxReturn : 958.876953125
Train_MinReturn : 958.876953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 867000
TimeSinceStart : 13396.844154834747
Training Loss : 2.361491533520166e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 868 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.2931518554688
Eval_StdReturn : 12.716466903686523
Eval_MaxReturn : 957.155029296875
Eval_MinReturn : 920.84130859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.9727783203125
Train_StdReturn : 0.0
Train_MaxReturn : 950.9727783203125
Train_MinReturn : 950.9727783203125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 868000
TimeSinceStart : 13419.623466730118
Training Loss : 0.0008603640599176288
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 869 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.0853271484375
Eval_StdReturn : 7.746709823608398
Eval_MaxReturn : 955.2774658203125
Eval_MinReturn : 935.0308837890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.2713623046875
Train_StdReturn : 0.0
Train_MaxReturn : 942.2713623046875
Train_MinReturn : 942.2713623046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 869000
TimeSinceStart : 13443.073447465897
Training Loss : 0.0001719720457913354
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 870 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.9342041015625
Eval_StdReturn : 4.643944263458252
Eval_MaxReturn : 958.309814453125
Eval_MinReturn : 944.3572998046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.3560180664062
Train_StdReturn : 0.0
Train_MaxReturn : 948.3560180664062
Train_MinReturn : 948.3560180664062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 870000
TimeSinceStart : 13466.013276338577
Training Loss : 0.00044385853107087314
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 871 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.3172607421875
Eval_StdReturn : 5.791299343109131
Eval_MaxReturn : 952.7919311523438
Eval_MinReturn : 936.3192138671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.9979858398438
Train_StdReturn : 0.0
Train_MaxReturn : 940.9979858398438
Train_MinReturn : 940.9979858398438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 871000
TimeSinceStart : 13488.459934711456
Training Loss : 0.00021178742463234812
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 872 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 934.7918090820312
Eval_StdReturn : 12.078449249267578
Eval_MaxReturn : 948.2442626953125
Eval_MinReturn : 919.267578125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.2608032226562
Train_StdReturn : 0.0
Train_MaxReturn : 956.2608032226562
Train_MinReturn : 956.2608032226562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 872000
TimeSinceStart : 13511.898522138596
Training Loss : 0.0002498026005923748
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 873 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.4666137695312
Eval_StdReturn : 14.713199615478516
Eval_MaxReturn : 956.8402099609375
Eval_MinReturn : 918.0311279296875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.841796875
Train_StdReturn : 0.0
Train_MaxReturn : 939.841796875
Train_MinReturn : 939.841796875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 873000
TimeSinceStart : 13535.99578499794
Training Loss : 5.7363118685316294e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 874 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.3995971679688
Eval_StdReturn : 3.117985248565674
Eval_MaxReturn : 950.6361083984375
Eval_MinReturn : 942.612548828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.2086181640625
Train_StdReturn : 0.0
Train_MaxReturn : 933.2086181640625
Train_MinReturn : 933.2086181640625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 874000
TimeSinceStart : 13559.762067317963
Training Loss : 0.00013453928113449365
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 875 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.2424926757812
Eval_StdReturn : 11.879570007324219
Eval_MaxReturn : 958.8719482421875
Eval_MinReturn : 929.4439697265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 920.8511352539062
Train_StdReturn : 0.0
Train_MaxReturn : 920.8511352539062
Train_MinReturn : 920.8511352539062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 875000
TimeSinceStart : 13583.373140335083
Training Loss : 0.0002864566631615162
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 876 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.9752197265625
Eval_StdReturn : 7.571000099182129
Eval_MaxReturn : 960.6558227539062
Eval_MinReturn : 938.809326171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.47216796875
Train_StdReturn : 0.0
Train_MaxReturn : 955.47216796875
Train_MinReturn : 955.47216796875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 876000
TimeSinceStart : 13606.028069496155
Training Loss : 0.00011625641491264105
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 877 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.8396606445312
Eval_StdReturn : 10.612589836120605
Eval_MaxReturn : 956.69287109375
Eval_MinReturn : 926.12548828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 960.5888671875
Train_StdReturn : 0.0
Train_MaxReturn : 960.5888671875
Train_MinReturn : 960.5888671875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 877000
TimeSinceStart : 13629.55674958229
Training Loss : 0.00044402561616152525
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 878 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 933.37353515625
Eval_StdReturn : 10.629324913024902
Eval_MaxReturn : 951.9254150390625
Eval_MinReturn : 923.3239135742188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 931.132568359375
Train_StdReturn : 0.0
Train_MaxReturn : 931.132568359375
Train_MinReturn : 931.132568359375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 878000
TimeSinceStart : 13653.140071630478
Training Loss : 0.00027450433117337525
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 879 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.3883056640625
Eval_StdReturn : 6.81972074508667
Eval_MaxReturn : 951.7882080078125
Eval_MinReturn : 930.9724731445312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.8626708984375
Train_StdReturn : 0.0
Train_MaxReturn : 935.8626708984375
Train_MinReturn : 935.8626708984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 879000
TimeSinceStart : 13676.981950759888
Training Loss : 0.0002034599892795086
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 880 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 930.6121826171875
Eval_StdReturn : 10.940666198730469
Eval_MaxReturn : 946.6006469726562
Eval_MinReturn : 913.622314453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.70068359375
Train_StdReturn : 0.0
Train_MaxReturn : 933.70068359375
Train_MinReturn : 933.70068359375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 880000
TimeSinceStart : 13700.63653755188
Training Loss : 0.0005263772909529507
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 881 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 927.0101318359375
Eval_StdReturn : 5.831406593322754
Eval_MaxReturn : 934.4741821289062
Eval_MinReturn : 919.8721923828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 919.8139038085938
Train_StdReturn : 0.0
Train_MaxReturn : 919.8139038085938
Train_MinReturn : 919.8139038085938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 881000
TimeSinceStart : 13723.867447376251
Training Loss : 0.00044008344411849976
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 882 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.1484375
Eval_StdReturn : 16.07122039794922
Eval_MaxReturn : 971.8565673828125
Eval_MinReturn : 925.0135498046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.747314453125
Train_StdReturn : 0.0
Train_MaxReturn : 937.747314453125
Train_MinReturn : 937.747314453125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 882000
TimeSinceStart : 13747.832357645035
Training Loss : 4.683919542003423e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 883 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.7960815429688
Eval_StdReturn : 11.120524406433105
Eval_MaxReturn : 957.0669555664062
Eval_MinReturn : 925.6590576171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.9199829101562
Train_StdReturn : 0.0
Train_MaxReturn : 949.9199829101562
Train_MinReturn : 949.9199829101562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 883000
TimeSinceStart : 13771.31024312973
Training Loss : 0.0001524786202935502
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 884 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 953.1671142578125
Eval_StdReturn : 6.908904552459717
Eval_MaxReturn : 960.9918212890625
Eval_MinReturn : 944.009033203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.022705078125
Train_StdReturn : 0.0
Train_MaxReturn : 936.022705078125
Train_MinReturn : 936.022705078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 884000
TimeSinceStart : 13795.531089305878
Training Loss : 0.00015200188499875367
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 885 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.861328125
Eval_StdReturn : 8.558664321899414
Eval_MaxReturn : 949.12841796875
Eval_MinReturn : 925.1611938476562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.76953125
Train_StdReturn : 0.0
Train_MaxReturn : 942.76953125
Train_MinReturn : 942.76953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 885000
TimeSinceStart : 13819.001609325409
Training Loss : 0.00023274107661563903
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 886 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.0673828125
Eval_StdReturn : 5.260885715484619
Eval_MaxReturn : 953.2839965820312
Eval_MinReturn : 939.5071411132812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.9893798828125
Train_StdReturn : 0.0
Train_MaxReturn : 946.9893798828125
Train_MinReturn : 946.9893798828125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 886000
TimeSinceStart : 13841.869724988937
Training Loss : 3.6309331335360184e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 887 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 952.5621337890625
Eval_StdReturn : 11.027164459228516
Eval_MaxReturn : 970.0001220703125
Eval_MinReturn : 936.5999755859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.0859985351562
Train_StdReturn : 0.0
Train_MaxReturn : 947.0859985351562
Train_MinReturn : 947.0859985351562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 887000
TimeSinceStart : 13865.174979925156
Training Loss : 0.0001921438379213214
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 888 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.5777587890625
Eval_StdReturn : 13.756990432739258
Eval_MaxReturn : 959.494140625
Eval_MinReturn : 924.8131103515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.0460205078125
Train_StdReturn : 0.0
Train_MaxReturn : 958.0460205078125
Train_MinReturn : 958.0460205078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 888000
TimeSinceStart : 13888.705355644226
Training Loss : 0.00012168461398687214
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 889 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.154296875
Eval_StdReturn : 7.569047451019287
Eval_MaxReturn : 958.7967529296875
Eval_MinReturn : 940.3868408203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.6553955078125
Train_StdReturn : 0.0
Train_MaxReturn : 937.6553955078125
Train_MinReturn : 937.6553955078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 889000
TimeSinceStart : 13911.57012295723
Training Loss : 0.00013705523451790214
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 890 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.2572021484375
Eval_StdReturn : 15.17647647857666
Eval_MaxReturn : 970.9522705078125
Eval_MinReturn : 927.587890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.2191772460938
Train_StdReturn : 0.0
Train_MaxReturn : 941.2191772460938
Train_MinReturn : 941.2191772460938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 890000
TimeSinceStart : 13935.537568330765
Training Loss : 0.00014547085447702557
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 891 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.1687622070312
Eval_StdReturn : 8.427891731262207
Eval_MaxReturn : 955.658447265625
Eval_MinReturn : 930.4119873046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.81640625
Train_StdReturn : 0.0
Train_MaxReturn : 936.81640625
Train_MinReturn : 936.81640625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 891000
TimeSinceStart : 13959.244644880295
Training Loss : 0.0001825889921747148
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 892 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.9407958984375
Eval_StdReturn : 9.801054954528809
Eval_MaxReturn : 961.2828369140625
Eval_MinReturn : 936.7034912109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 926.8253173828125
Train_StdReturn : 0.0
Train_MaxReturn : 926.8253173828125
Train_MinReturn : 926.8253173828125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 892000
TimeSinceStart : 13982.902741670609
Training Loss : 1.7006908819894306e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 893 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 930.2229614257812
Eval_StdReturn : 9.829436302185059
Eval_MaxReturn : 941.5347290039062
Eval_MinReturn : 914.0756225585938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.339111328125
Train_StdReturn : 0.0
Train_MaxReturn : 943.339111328125
Train_MinReturn : 943.339111328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 893000
TimeSinceStart : 14005.800613880157
Training Loss : 0.0005287927342578769
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 894 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.3538818359375
Eval_StdReturn : 5.422230243682861
Eval_MaxReturn : 955.4862060546875
Eval_MinReturn : 940.2448120117188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 962.5382080078125
Train_StdReturn : 0.0
Train_MaxReturn : 962.5382080078125
Train_MinReturn : 962.5382080078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 894000
TimeSinceStart : 14029.859064102173
Training Loss : 0.00013695030065719038
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 895 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.8880004882812
Eval_StdReturn : 8.981367111206055
Eval_MaxReturn : 964.6329956054688
Eval_MinReturn : 938.40478515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.0770263671875
Train_StdReturn : 0.0
Train_MaxReturn : 940.0770263671875
Train_MinReturn : 940.0770263671875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 895000
TimeSinceStart : 14053.629796743393
Training Loss : 0.0003180301864631474
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 896 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.6107177734375
Eval_StdReturn : 2.1782097816467285
Eval_MaxReturn : 947.2197265625
Eval_MinReturn : 941.0746459960938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.874267578125
Train_StdReturn : 0.0
Train_MaxReturn : 945.874267578125
Train_MinReturn : 945.874267578125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 896000
TimeSinceStart : 14077.32001543045
Training Loss : 0.0013561116065829992
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 897 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.5709228515625
Eval_StdReturn : 7.427058219909668
Eval_MaxReturn : 951.570068359375
Eval_MinReturn : 929.85498046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 929.1466674804688
Train_StdReturn : 0.0
Train_MaxReturn : 929.1466674804688
Train_MinReturn : 929.1466674804688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 897000
TimeSinceStart : 14101.341329813004
Training Loss : 0.00012162794155301526
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 898 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.1983642578125
Eval_StdReturn : 12.635374069213867
Eval_MaxReturn : 956.7730712890625
Eval_MinReturn : 922.0158081054688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.7528076171875
Train_StdReturn : 0.0
Train_MaxReturn : 942.7528076171875
Train_MinReturn : 942.7528076171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 898000
TimeSinceStart : 14125.252566814423
Training Loss : 0.0001550566521473229
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 899 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.8917236328125
Eval_StdReturn : 6.553605079650879
Eval_MaxReturn : 955.7998046875
Eval_MinReturn : 938.4031372070312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 927.9400024414062
Train_StdReturn : 0.0
Train_MaxReturn : 927.9400024414062
Train_MinReturn : 927.9400024414062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 899000
TimeSinceStart : 14149.060972929
Training Loss : 0.0002784908574540168
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 900 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.3146362304688
Eval_StdReturn : 9.553481101989746
Eval_MaxReturn : 955.40478515625
Eval_MinReturn : 925.9530639648438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 963.8008422851562
Train_StdReturn : 0.0
Train_MaxReturn : 963.8008422851562
Train_MinReturn : 963.8008422851562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 900000
TimeSinceStart : 14172.683063030243
Training Loss : 9.274842159356922e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 901 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.8499755859375
Eval_StdReturn : 8.01937484741211
Eval_MaxReturn : 951.9329833984375
Eval_MinReturn : 928.5975341796875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.7003784179688
Train_StdReturn : 0.0
Train_MaxReturn : 947.7003784179688
Train_MinReturn : 947.7003784179688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 901000
TimeSinceStart : 14196.373158454895
Training Loss : 0.00010159294470213354
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 902 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 935.2095947265625
Eval_StdReturn : 6.235290050506592
Eval_MaxReturn : 942.697021484375
Eval_MinReturn : 925.961669921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.86572265625
Train_StdReturn : 0.0
Train_MaxReturn : 949.86572265625
Train_MinReturn : 949.86572265625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 902000
TimeSinceStart : 14219.877745389938
Training Loss : 0.00010226092854281887
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 903 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.2824096679688
Eval_StdReturn : 11.9071683883667
Eval_MaxReturn : 964.7018432617188
Eval_MinReturn : 930.5922241210938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.7662353515625
Train_StdReturn : 0.0
Train_MaxReturn : 949.7662353515625
Train_MinReturn : 949.7662353515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 903000
TimeSinceStart : 14242.97706246376
Training Loss : 0.0006112423725426197
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 904 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.3939208984375
Eval_StdReturn : 14.574379920959473
Eval_MaxReturn : 953.496337890625
Eval_MinReturn : 914.8829345703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 914.515380859375
Train_StdReturn : 0.0
Train_MaxReturn : 914.515380859375
Train_MinReturn : 914.515380859375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 904000
TimeSinceStart : 14267.004754304886
Training Loss : 0.00016359439177904278
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 905 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.1931762695312
Eval_StdReturn : 11.935309410095215
Eval_MaxReturn : 959.7211303710938
Eval_MinReturn : 927.3863525390625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.26171875
Train_StdReturn : 0.0
Train_MaxReturn : 942.26171875
Train_MinReturn : 942.26171875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 905000
TimeSinceStart : 14290.990757226944
Training Loss : 0.00039796752389520407
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 906 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.7410888671875
Eval_StdReturn : 10.35146427154541
Eval_MaxReturn : 957.8355102539062
Eval_MinReturn : 928.998046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.2095947265625
Train_StdReturn : 0.0
Train_MaxReturn : 934.2095947265625
Train_MinReturn : 934.2095947265625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 906000
TimeSinceStart : 14314.874270677567
Training Loss : 4.37178932770621e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 907 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.0792846679688
Eval_StdReturn : 10.444329261779785
Eval_MaxReturn : 962.4013671875
Eval_MinReturn : 934.9788818359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.0728759765625
Train_StdReturn : 0.0
Train_MaxReturn : 953.0728759765625
Train_MinReturn : 953.0728759765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 907000
TimeSinceStart : 14338.206054925919
Training Loss : 0.00015231111319735646
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 908 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 954.4529418945312
Eval_StdReturn : 3.9241600036621094
Eval_MaxReturn : 958.9332885742188
Eval_MinReturn : 949.209228515625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.2720947265625
Train_StdReturn : 0.0
Train_MaxReturn : 952.2720947265625
Train_MinReturn : 952.2720947265625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 908000
TimeSinceStart : 14362.528674602509
Training Loss : 0.0005632861866615713
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 909 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.6369018554688
Eval_StdReturn : 14.020890235900879
Eval_MaxReturn : 970.2227783203125
Eval_MinReturn : 928.5724487304688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.4822998046875
Train_StdReturn : 0.0
Train_MaxReturn : 947.4822998046875
Train_MinReturn : 947.4822998046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 909000
TimeSinceStart : 14387.027740716934
Training Loss : 0.0006171966670081019
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 910 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.2396240234375
Eval_StdReturn : 13.049588203430176
Eval_MaxReturn : 958.5231323242188
Eval_MinReturn : 922.6973876953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.4072265625
Train_StdReturn : 0.0
Train_MaxReturn : 943.4072265625
Train_MinReturn : 943.4072265625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 910000
TimeSinceStart : 14410.450903654099
Training Loss : 0.00041567793232388794
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 911 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.6126098632812
Eval_StdReturn : 6.324155807495117
Eval_MaxReturn : 960.135986328125
Eval_MinReturn : 942.80908203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.9571533203125
Train_StdReturn : 0.0
Train_MaxReturn : 942.9571533203125
Train_MinReturn : 942.9571533203125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 911000
TimeSinceStart : 14434.113193273544
Training Loss : 0.00020800594938918948
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 912 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.451171875
Eval_StdReturn : 4.854779243469238
Eval_MaxReturn : 941.9559326171875
Eval_MinReturn : 928.5782470703125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.1876831054688
Train_StdReturn : 0.0
Train_MaxReturn : 944.1876831054688
Train_MinReturn : 944.1876831054688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 912000
TimeSinceStart : 14458.261901378632
Training Loss : 0.00016180609236471355
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 913 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.3250732421875
Eval_StdReturn : 16.162750244140625
Eval_MaxReturn : 966.039306640625
Eval_MinReturn : 920.4805908203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.83251953125
Train_StdReturn : 0.0
Train_MaxReturn : 946.83251953125
Train_MinReturn : 946.83251953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 913000
TimeSinceStart : 14482.53100514412
Training Loss : 0.00016720639541745186
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 914 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.5382690429688
Eval_StdReturn : 8.462005615234375
Eval_MaxReturn : 959.5177001953125
Eval_MinReturn : 935.956787109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.5426025390625
Train_StdReturn : 0.0
Train_MaxReturn : 939.5426025390625
Train_MinReturn : 939.5426025390625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 914000
TimeSinceStart : 14505.993485450745
Training Loss : 0.00037646896089427173
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 915 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.50146484375
Eval_StdReturn : 2.111323833465576
Eval_MaxReturn : 949.3695068359375
Eval_MinReturn : 943.4926147460938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.4976196289062
Train_StdReturn : 0.0
Train_MaxReturn : 942.4976196289062
Train_MinReturn : 942.4976196289062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 915000
TimeSinceStart : 14529.933992862701
Training Loss : 0.00039851924520917237
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 916 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.310546875
Eval_StdReturn : 16.935302734375
Eval_MaxReturn : 959.0407104492188
Eval_MinReturn : 912.93017578125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 951.0150756835938
Train_StdReturn : 0.0
Train_MaxReturn : 951.0150756835938
Train_MinReturn : 951.0150756835938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 916000
TimeSinceStart : 14553.827791690826
Training Loss : 2.87101083813468e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 917 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.3284912109375
Eval_StdReturn : 19.606433868408203
Eval_MaxReturn : 969.3983154296875
Eval_MinReturn : 915.16455078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.283203125
Train_StdReturn : 0.0
Train_MaxReturn : 958.283203125
Train_MinReturn : 958.283203125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 917000
TimeSinceStart : 14577.701753616333
Training Loss : 0.0008577635744586587
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 918 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.4080200195312
Eval_StdReturn : 7.4508795738220215
Eval_MaxReturn : 962.886474609375
Eval_MinReturn : 943.6673583984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 961.2562255859375
Train_StdReturn : 0.0
Train_MaxReturn : 961.2562255859375
Train_MinReturn : 961.2562255859375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 918000
TimeSinceStart : 14602.198959112167
Training Loss : 0.00015847280155867338
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 919 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.29150390625
Eval_StdReturn : 8.383155822753906
Eval_MaxReturn : 954.5252685546875
Eval_MinReturn : 928.352294921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 931.2296752929688
Train_StdReturn : 0.0
Train_MaxReturn : 931.2296752929688
Train_MinReturn : 931.2296752929688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 919000
TimeSinceStart : 14626.37173485756
Training Loss : 0.00025543468655087054
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 920 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.7131958007812
Eval_StdReturn : 9.659411430358887
Eval_MaxReturn : 947.191162109375
Eval_MinReturn : 922.187744140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.7660522460938
Train_StdReturn : 0.0
Train_MaxReturn : 949.7660522460938
Train_MinReturn : 949.7660522460938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 920000
TimeSinceStart : 14650.820248126984
Training Loss : 7.923781959107146e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 921 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.7688598632812
Eval_StdReturn : 9.639152526855469
Eval_MaxReturn : 956.6922607421875
Eval_MinReturn : 932.166748046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 946.539794921875
Train_StdReturn : 0.0
Train_MaxReturn : 946.539794921875
Train_MinReturn : 946.539794921875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 921000
TimeSinceStart : 14675.064422130585
Training Loss : 0.0001495605829404667
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 922 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.3111572265625
Eval_StdReturn : 6.581929683685303
Eval_MaxReturn : 954.26953125
Eval_MinReturn : 934.8619384765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 958.86474609375
Train_StdReturn : 0.0
Train_MaxReturn : 958.86474609375
Train_MinReturn : 958.86474609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 922000
TimeSinceStart : 14698.872883796692
Training Loss : 0.00037945626536384225
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 923 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.6910400390625
Eval_StdReturn : 5.943310260772705
Eval_MaxReturn : 949.1641845703125
Eval_MinReturn : 931.08837890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 943.3281860351562
Train_StdReturn : 0.0
Train_MaxReturn : 943.3281860351562
Train_MinReturn : 943.3281860351562
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 923000
TimeSinceStart : 14722.895929574966
Training Loss : 0.00010661911073839292
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 924 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.2537841796875
Eval_StdReturn : 6.58442497253418
Eval_MaxReturn : 947.7236328125
Eval_MinReturn : 930.2567749023438
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.2962646484375
Train_StdReturn : 0.0
Train_MaxReturn : 944.2962646484375
Train_MinReturn : 944.2962646484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 924000
TimeSinceStart : 14747.1936647892
Training Loss : 0.00011091119085904211
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 925 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 935.6773681640625
Eval_StdReturn : 6.681155681610107
Eval_MaxReturn : 944.5676879882812
Eval_MinReturn : 924.915283203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.9112548828125
Train_StdReturn : 0.0
Train_MaxReturn : 935.9112548828125
Train_MinReturn : 935.9112548828125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 925000
TimeSinceStart : 14771.28183221817
Training Loss : 0.00014634884428232908
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 926 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 932.087890625
Eval_StdReturn : 15.728017807006836
Eval_MaxReturn : 960.7557373046875
Eval_MinReturn : 912.7774047851562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.043212890625
Train_StdReturn : 0.0
Train_MaxReturn : 945.043212890625
Train_MinReturn : 945.043212890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 926000
TimeSinceStart : 14795.619545698166
Training Loss : 0.0001336966670351103
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 927 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 935.4539184570312
Eval_StdReturn : 4.410195350646973
Eval_MaxReturn : 940.9207763671875
Eval_MinReturn : 927.4334106445312
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 957.3614501953125
Train_StdReturn : 0.0
Train_MaxReturn : 957.3614501953125
Train_MinReturn : 957.3614501953125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 927000
TimeSinceStart : 14819.68148469925
Training Loss : 6.507364014396444e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 928 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.5700073242188
Eval_StdReturn : 10.41331958770752
Eval_MaxReturn : 960.872314453125
Eval_MinReturn : 935.54638671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 932.3626708984375
Train_StdReturn : 0.0
Train_MaxReturn : 932.3626708984375
Train_MinReturn : 932.3626708984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 928000
TimeSinceStart : 14843.856612920761
Training Loss : 0.00020707215298898518
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 929 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.48095703125
Eval_StdReturn : 15.515603065490723
Eval_MaxReturn : 964.05078125
Eval_MinReturn : 918.439208984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.580322265625
Train_StdReturn : 0.0
Train_MaxReturn : 947.580322265625
Train_MinReturn : 947.580322265625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 929000
TimeSinceStart : 14868.275584220886
Training Loss : 0.00020983419381082058
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 930 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.2027587890625
Eval_StdReturn : 17.73937225341797
Eval_MaxReturn : 963.775634765625
Eval_MinReturn : 913.0791625976562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.4052124023438
Train_StdReturn : 0.0
Train_MaxReturn : 940.4052124023438
Train_MinReturn : 940.4052124023438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 930000
TimeSinceStart : 14892.509298086166
Training Loss : 0.0005291104898788035
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 931 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 932.7531127929688
Eval_StdReturn : 9.596267700195312
Eval_MaxReturn : 943.3936767578125
Eval_MinReturn : 914.79833984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.8158569335938
Train_StdReturn : 0.0
Train_MaxReturn : 942.8158569335938
Train_MinReturn : 942.8158569335938
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 931000
TimeSinceStart : 14916.717059612274
Training Loss : 0.00023395138850901276
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 932 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.3818359375
Eval_StdReturn : 14.485678672790527
Eval_MaxReturn : 958.9547729492188
Eval_MinReturn : 918.1421508789062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.04345703125
Train_StdReturn : 0.0
Train_MaxReturn : 934.04345703125
Train_MinReturn : 934.04345703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 932000
TimeSinceStart : 14940.618631601334
Training Loss : 3.6009401810588315e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 933 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.0437622070312
Eval_StdReturn : 5.147451400756836
Eval_MaxReturn : 953.269775390625
Eval_MinReturn : 938.5360107421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 933.1019287109375
Train_StdReturn : 0.0
Train_MaxReturn : 933.1019287109375
Train_MinReturn : 933.1019287109375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 933000
TimeSinceStart : 14965.167918205261
Training Loss : 7.703858136665076e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 934 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.2615966796875
Eval_StdReturn : 7.510580539703369
Eval_MaxReturn : 951.64208984375
Eval_MinReturn : 932.9176635742188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 934.995849609375
Train_StdReturn : 0.0
Train_MaxReturn : 934.995849609375
Train_MinReturn : 934.995849609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 934000
TimeSinceStart : 14989.84658575058
Training Loss : 0.00027249145205132663
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 935 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.9684448242188
Eval_StdReturn : 12.404056549072266
Eval_MaxReturn : 970.7357788085938
Eval_MinReturn : 936.72265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 930.40478515625
Train_StdReturn : 0.0
Train_MaxReturn : 930.40478515625
Train_MinReturn : 930.40478515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 935000
TimeSinceStart : 15014.143026828766
Training Loss : 0.00033874245127663016
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 936 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.6456298828125
Eval_StdReturn : 9.747594833374023
Eval_MaxReturn : 963.514892578125
Eval_MinReturn : 939.2417602539062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.697021484375
Train_StdReturn : 0.0
Train_MaxReturn : 937.697021484375
Train_MinReturn : 937.697021484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 936000
TimeSinceStart : 15037.928813934326
Training Loss : 0.0002412933827145025
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 937 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.0330810546875
Eval_StdReturn : 12.217971801757812
Eval_MaxReturn : 955.9473876953125
Eval_MinReturn : 922.643310546875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.2513427734375
Train_StdReturn : 0.0
Train_MaxReturn : 936.2513427734375
Train_MinReturn : 936.2513427734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 937000
TimeSinceStart : 15062.265717029572
Training Loss : 0.0006165645318105817
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 938 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.5423583984375
Eval_StdReturn : 5.371987819671631
Eval_MaxReturn : 951.55810546875
Eval_MinReturn : 936.3805541992188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 955.909423828125
Train_StdReturn : 0.0
Train_MaxReturn : 955.909423828125
Train_MinReturn : 955.909423828125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 938000
TimeSinceStart : 15086.641126871109
Training Loss : 0.0002462185802869499
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 939 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.6671752929688
Eval_StdReturn : 4.8740692138671875
Eval_MaxReturn : 950.5757446289062
Eval_MinReturn : 936.3092651367188
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.4183349609375
Train_StdReturn : 0.0
Train_MaxReturn : 948.4183349609375
Train_MinReturn : 948.4183349609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 939000
TimeSinceStart : 15110.798069477081
Training Loss : 6.199086055858061e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 940 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.0261840820312
Eval_StdReturn : 9.334174156188965
Eval_MaxReturn : 958.1548461914062
Eval_MinReturn : 931.9368896484375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.226806640625
Train_StdReturn : 0.0
Train_MaxReturn : 939.226806640625
Train_MinReturn : 939.226806640625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 940000
TimeSinceStart : 15134.935457706451
Training Loss : 0.0001153701450675726
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 941 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.6007690429688
Eval_StdReturn : 9.704262733459473
Eval_MaxReturn : 949.8333129882812
Eval_MinReturn : 927.4886474609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.4234619140625
Train_StdReturn : 0.0
Train_MaxReturn : 953.4234619140625
Train_MinReturn : 953.4234619140625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 941000
TimeSinceStart : 15158.831029891968
Training Loss : 4.667259781854227e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 942 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.8685302734375
Eval_StdReturn : 9.312658309936523
Eval_MaxReturn : 957.582275390625
Eval_MinReturn : 937.4310302734375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 932.100830078125
Train_StdReturn : 0.0
Train_MaxReturn : 932.100830078125
Train_MinReturn : 932.100830078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 942000
TimeSinceStart : 15183.202068328857
Training Loss : 0.00013986858539283276
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 943 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.0992431640625
Eval_StdReturn : 11.91318416595459
Eval_MaxReturn : 961.265625
Eval_MinReturn : 927.6602172851562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.8829345703125
Train_StdReturn : 0.0
Train_MaxReturn : 936.8829345703125
Train_MinReturn : 936.8829345703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 943000
TimeSinceStart : 15208.216621398926
Training Loss : 0.00024721052614040673
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 944 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.8796997070312
Eval_StdReturn : 3.623213291168213
Eval_MaxReturn : 949.8258056640625
Eval_MinReturn : 939.2354125976562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.6204833984375
Train_StdReturn : 0.0
Train_MaxReturn : 953.6204833984375
Train_MinReturn : 953.6204833984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 944000
TimeSinceStart : 15233.116135120392
Training Loss : 0.00047720223665237427
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 945 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.9320068359375
Eval_StdReturn : 13.853157043457031
Eval_MaxReturn : 966.8817138671875
Eval_MinReturn : 924.590576171875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.7777099609375
Train_StdReturn : 0.0
Train_MaxReturn : 939.7777099609375
Train_MinReturn : 939.7777099609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 945000
TimeSinceStart : 15256.928354740143
Training Loss : 0.0002012596232816577
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 946 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.4373779296875
Eval_StdReturn : 11.596811294555664
Eval_MaxReturn : 963.6837768554688
Eval_MinReturn : 929.9260864257812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 922.7965698242188
Train_StdReturn : 0.0
Train_MaxReturn : 922.7965698242188
Train_MinReturn : 922.7965698242188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 946000
TimeSinceStart : 15280.563268899918
Training Loss : 6.988004315644503e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 947 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.5606689453125
Eval_StdReturn : 6.933874130249023
Eval_MaxReturn : 957.7533569335938
Eval_MinReturn : 937.4130859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.8425903320312
Train_StdReturn : 0.0
Train_MaxReturn : 956.8425903320312
Train_MinReturn : 956.8425903320312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 947000
TimeSinceStart : 15304.793235063553
Training Loss : 2.1882546207052656e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 948 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.2520751953125
Eval_StdReturn : 12.445693969726562
Eval_MaxReturn : 965.6528930664062
Eval_MinReturn : 930.653564453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.2127685546875
Train_StdReturn : 0.0
Train_MaxReturn : 935.2127685546875
Train_MinReturn : 935.2127685546875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 948000
TimeSinceStart : 15329.415671110153
Training Loss : 0.00036529466160573065
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 949 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.5469970703125
Eval_StdReturn : 10.083280563354492
Eval_MaxReturn : 955.1735229492188
Eval_MinReturn : 928.8746337890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 925.345458984375
Train_StdReturn : 0.0
Train_MaxReturn : 925.345458984375
Train_MinReturn : 925.345458984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 949000
TimeSinceStart : 15353.824662446976
Training Loss : 0.00012274943583179265
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 950 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.5294799804688
Eval_StdReturn : 5.645577907562256
Eval_MaxReturn : 953.9659423828125
Eval_MinReturn : 937.598388671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 945.665771484375
Train_StdReturn : 0.0
Train_MaxReturn : 945.665771484375
Train_MinReturn : 945.665771484375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 950000
TimeSinceStart : 15378.348688602448
Training Loss : 6.672921153949574e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 951 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 933.5964965820312
Eval_StdReturn : 13.600665092468262
Eval_MaxReturn : 952.8603515625
Eval_MinReturn : 913.7225341796875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.5741577148438
Train_StdReturn : 0.0
Train_MaxReturn : 944.5741577148438
Train_MinReturn : 944.5741577148438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 951000
TimeSinceStart : 15403.088443279266
Training Loss : 0.00019897421589121222
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 952 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 950.3359375
Eval_StdReturn : 4.209351062774658
Eval_MaxReturn : 956.0924072265625
Eval_MinReturn : 944.623779296875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.156005859375
Train_StdReturn : 0.0
Train_MaxReturn : 942.156005859375
Train_MinReturn : 942.156005859375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 952000
TimeSinceStart : 15428.096856832504
Training Loss : 0.00019083678489550948
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 953 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 954.0826416015625
Eval_StdReturn : 5.758849620819092
Eval_MaxReturn : 963.7967529296875
Eval_MinReturn : 947.2060546875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.0526123046875
Train_StdReturn : 0.0
Train_MaxReturn : 941.0526123046875
Train_MinReturn : 941.0526123046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 953000
TimeSinceStart : 15453.231205940247
Training Loss : 0.00015017828263808042
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 954 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.0808715820312
Eval_StdReturn : 10.874174118041992
Eval_MaxReturn : 965.48095703125
Eval_MinReturn : 935.432861328125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 929.6072998046875
Train_StdReturn : 0.0
Train_MaxReturn : 929.6072998046875
Train_MinReturn : 929.6072998046875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 954000
TimeSinceStart : 15478.615677595139
Training Loss : 0.0002988195337820798
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 955 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.3258666992188
Eval_StdReturn : 11.192048072814941
Eval_MaxReturn : 949.7342529296875
Eval_MinReturn : 919.35205078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.46240234375
Train_StdReturn : 0.0
Train_MaxReturn : 939.46240234375
Train_MinReturn : 939.46240234375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 955000
TimeSinceStart : 15503.665840625763
Training Loss : 0.0001796790602384135
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 956 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 952.0048828125
Eval_StdReturn : 5.149224281311035
Eval_MaxReturn : 957.528564453125
Eval_MinReturn : 945.147705078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.3378295898438
Train_StdReturn : 0.0
Train_MaxReturn : 956.3378295898438
Train_MinReturn : 956.3378295898438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 956000
TimeSinceStart : 15528.587662696838
Training Loss : 7.461032510036603e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 957 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.6375122070312
Eval_StdReturn : 14.715259552001953
Eval_MaxReturn : 958.1904907226562
Eval_MinReturn : 920.3363037109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.3233642578125
Train_StdReturn : 0.0
Train_MaxReturn : 944.3233642578125
Train_MinReturn : 944.3233642578125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 957000
TimeSinceStart : 15553.386478424072
Training Loss : 0.00010077658225782216
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 958 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 939.3416137695312
Eval_StdReturn : 10.87607479095459
Eval_MaxReturn : 956.65966796875
Eval_MinReturn : 924.7716064453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.009033203125
Train_StdReturn : 0.0
Train_MaxReturn : 940.009033203125
Train_MinReturn : 940.009033203125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 958000
TimeSinceStart : 15578.00202012062
Training Loss : 5.6102398957591504e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 959 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 945.3902587890625
Eval_StdReturn : 7.169956684112549
Eval_MaxReturn : 953.0419311523438
Eval_MinReturn : 935.71923828125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.185302734375
Train_StdReturn : 0.0
Train_MaxReturn : 949.185302734375
Train_MinReturn : 949.185302734375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 959000
TimeSinceStart : 15603.170241594315
Training Loss : 0.0002264705253764987
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 960 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 932.7049560546875
Eval_StdReturn : 12.997932434082031
Eval_MaxReturn : 950.5599975585938
Eval_MinReturn : 915.4995727539062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.6965942382812
Train_StdReturn : 0.0
Train_MaxReturn : 940.6965942382812
Train_MinReturn : 940.6965942382812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 960000
TimeSinceStart : 15627.873290538788
Training Loss : 0.00022180459927767515
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 961 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 932.5477294921875
Eval_StdReturn : 11.315317153930664
Eval_MaxReturn : 950.0574951171875
Eval_MinReturn : 916.9290771484375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 932.6842041015625
Train_StdReturn : 0.0
Train_MaxReturn : 932.6842041015625
Train_MinReturn : 932.6842041015625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 961000
TimeSinceStart : 15652.454993724823
Training Loss : 0.0004146834253333509
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 962 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.7376708984375
Eval_StdReturn : 7.70032262802124
Eval_MaxReturn : 959.9563598632812
Eval_MinReturn : 936.4132080078125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.1265258789062
Train_StdReturn : 0.0
Train_MaxReturn : 944.1265258789062
Train_MinReturn : 944.1265258789062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 962000
TimeSinceStart : 15677.282470226288
Training Loss : 0.00011091514170402661
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 963 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.8592529296875
Eval_StdReturn : 10.094869613647461
Eval_MaxReturn : 952.0230712890625
Eval_MinReturn : 921.5430297851562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.985107421875
Train_StdReturn : 0.0
Train_MaxReturn : 947.985107421875
Train_MinReturn : 947.985107421875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 963000
TimeSinceStart : 15702.221116542816
Training Loss : 0.0007382341427728534
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 964 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.2635498046875
Eval_StdReturn : 15.535738945007324
Eval_MaxReturn : 961.738525390625
Eval_MinReturn : 919.64990234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 944.5206909179688
Train_StdReturn : 0.0
Train_MaxReturn : 944.5206909179688
Train_MinReturn : 944.5206909179688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 964000
TimeSinceStart : 15727.209863424301
Training Loss : 0.00019587954739108682
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 965 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.4664306640625
Eval_StdReturn : 12.741108894348145
Eval_MaxReturn : 961.3245849609375
Eval_MinReturn : 931.3526000976562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.8438720703125
Train_StdReturn : 0.0
Train_MaxReturn : 956.8438720703125
Train_MinReturn : 956.8438720703125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 965000
TimeSinceStart : 15752.380633592606
Training Loss : 0.0001814387069316581
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 966 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.62841796875
Eval_StdReturn : 10.394757270812988
Eval_MaxReturn : 952.7080078125
Eval_MinReturn : 923.9031982421875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.869384765625
Train_StdReturn : 0.0
Train_MaxReturn : 941.869384765625
Train_MinReturn : 941.869384765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 966000
TimeSinceStart : 15777.096653699875
Training Loss : 0.00022160052321851254
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 967 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.3516845703125
Eval_StdReturn : 14.311041831970215
Eval_MaxReturn : 970.6928100585938
Eval_MinReturn : 928.0321044921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 937.965087890625
Train_StdReturn : 0.0
Train_MaxReturn : 937.965087890625
Train_MinReturn : 937.965087890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 967000
TimeSinceStart : 15802.560308218002
Training Loss : 6.62365710013546e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 968 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 934.1976318359375
Eval_StdReturn : 15.271044731140137
Eval_MaxReturn : 951.0000610351562
Eval_MinReturn : 916.6539306640625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.1677856445312
Train_StdReturn : 0.0
Train_MaxReturn : 935.1677856445312
Train_MinReturn : 935.1677856445312
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 968000
TimeSinceStart : 15827.900540590286
Training Loss : 0.0006943107000552118
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 969 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 947.0115356445312
Eval_StdReturn : 7.652751445770264
Eval_MaxReturn : 960.1390380859375
Eval_MinReturn : 936.939453125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 927.3284301757812
Train_StdReturn : 0.0
Train_MaxReturn : 927.3284301757812
Train_MinReturn : 927.3284301757812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 969000
TimeSinceStart : 15853.074809551239
Training Loss : 0.0002496225934009999
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 970 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.7689208984375
Eval_StdReturn : 12.016324996948242
Eval_MaxReturn : 956.472900390625
Eval_MinReturn : 922.8291625976562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 925.8014526367188
Train_StdReturn : 0.0
Train_MaxReturn : 925.8014526367188
Train_MinReturn : 925.8014526367188
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 970000
TimeSinceStart : 15877.375166893005
Training Loss : 0.0010800643358379602
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 971 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.8359375
Eval_StdReturn : 9.834598541259766
Eval_MaxReturn : 955.1644897460938
Eval_MinReturn : 924.2338256835938
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.353759765625
Train_StdReturn : 0.0
Train_MaxReturn : 953.353759765625
Train_MinReturn : 953.353759765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 971000
TimeSinceStart : 15902.603189468384
Training Loss : 0.0003874023968819529
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 972 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.8264770507812
Eval_StdReturn : 4.392938613891602
Eval_MaxReturn : 948.7074584960938
Eval_MinReturn : 937.002685546875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.5643920898438
Train_StdReturn : 0.0
Train_MaxReturn : 938.5643920898438
Train_MinReturn : 938.5643920898438
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 972000
TimeSinceStart : 15927.481459856033
Training Loss : 0.00010889196710195392
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 973 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 944.8922729492188
Eval_StdReturn : 11.413607597351074
Eval_MaxReturn : 957.7862548828125
Eval_MinReturn : 930.8829956054688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.4373779296875
Train_StdReturn : 0.0
Train_MaxReturn : 948.4373779296875
Train_MinReturn : 948.4373779296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 973000
TimeSinceStart : 15952.282511472702
Training Loss : 0.000261322216829285
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 974 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.47509765625
Eval_StdReturn : 4.515983581542969
Eval_MaxReturn : 942.7603149414062
Eval_MinReturn : 931.033203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 924.0145263671875
Train_StdReturn : 0.0
Train_MaxReturn : 924.0145263671875
Train_MinReturn : 924.0145263671875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 974000
TimeSinceStart : 15976.87698507309
Training Loss : 0.00022010320390108973
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 975 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.58740234375
Eval_StdReturn : 14.958788871765137
Eval_MaxReturn : 946.64794921875
Eval_MinReturn : 906.9783935546875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 960.8819580078125
Train_StdReturn : 0.0
Train_MaxReturn : 960.8819580078125
Train_MinReturn : 960.8819580078125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 975000
TimeSinceStart : 16002.085517168045
Training Loss : 0.0004366361245047301
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 976 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.7425537109375
Eval_StdReturn : 11.886816024780273
Eval_MaxReturn : 970.405029296875
Eval_MinReturn : 937.18212890625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 939.8243408203125
Train_StdReturn : 0.0
Train_MaxReturn : 939.8243408203125
Train_MinReturn : 939.8243408203125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 976000
TimeSinceStart : 16026.998678445816
Training Loss : 0.000513458508066833
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 977 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.8392333984375
Eval_StdReturn : 4.537837982177734
Eval_MaxReturn : 951.85302734375
Eval_MinReturn : 937.7705688476562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.2638549804688
Train_StdReturn : 0.0
Train_MaxReturn : 942.2638549804688
Train_MinReturn : 942.2638549804688
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 977000
TimeSinceStart : 16052.182618379593
Training Loss : 0.0006867125630378723
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 978 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 937.3884887695312
Eval_StdReturn : 10.037347793579102
Eval_MaxReturn : 950.613525390625
Eval_MinReturn : 923.2752685546875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 941.30419921875
Train_StdReturn : 0.0
Train_MaxReturn : 941.30419921875
Train_MinReturn : 941.30419921875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 978000
TimeSinceStart : 16077.692908525467
Training Loss : 2.0394159946590662e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 979 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 940.8680419921875
Eval_StdReturn : 9.441899299621582
Eval_MaxReturn : 956.448974609375
Eval_MinReturn : 927.7102661132812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 963.75634765625
Train_StdReturn : 0.0
Train_MaxReturn : 963.75634765625
Train_MinReturn : 963.75634765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 979000
TimeSinceStart : 16101.968465328217
Training Loss : 0.0001536946219857782
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 980 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.9937744140625
Eval_StdReturn : 13.090723991394043
Eval_MaxReturn : 960.1175537109375
Eval_MinReturn : 926.156494140625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.6760864257812
Train_StdReturn : 0.0
Train_MaxReturn : 950.6760864257812
Train_MinReturn : 950.6760864257812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 980000
TimeSinceStart : 16126.724482059479
Training Loss : 0.0004249987250659615
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 981 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.5924072265625
Eval_StdReturn : 6.428170680999756
Eval_MaxReturn : 951.3994140625
Eval_MinReturn : 935.2664794921875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 925.1949462890625
Train_StdReturn : 0.0
Train_MaxReturn : 925.1949462890625
Train_MinReturn : 925.1949462890625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 981000
TimeSinceStart : 16152.052701473236
Training Loss : 0.00022353108215611428
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 982 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 935.2205200195312
Eval_StdReturn : 8.04306697845459
Eval_MaxReturn : 947.6971435546875
Eval_MinReturn : 923.7687377929688
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.792724609375
Train_StdReturn : 0.0
Train_MaxReturn : 952.792724609375
Train_MinReturn : 952.792724609375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 982000
TimeSinceStart : 16177.05127286911
Training Loss : 0.00035296648275107145
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 983 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.5997924804688
Eval_StdReturn : 1.9956715106964111
Eval_MaxReturn : 945.532470703125
Eval_MinReturn : 939.598876953125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 947.4642333984375
Train_StdReturn : 0.0
Train_MaxReturn : 947.4642333984375
Train_MinReturn : 947.4642333984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 983000
TimeSinceStart : 16202.462203264236
Training Loss : 0.0001783460465958342
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 984 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 936.69140625
Eval_StdReturn : 10.17333698272705
Eval_MaxReturn : 950.5439453125
Eval_MinReturn : 924.533447265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 938.3931274414062
Train_StdReturn : 0.0
Train_MaxReturn : 938.3931274414062
Train_MinReturn : 938.3931274414062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 984000
TimeSinceStart : 16227.46509027481
Training Loss : 5.221696483204141e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 985 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.3193359375
Eval_StdReturn : 11.200225830078125
Eval_MaxReturn : 959.4909057617188
Eval_MinReturn : 929.509033203125
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 940.6160888671875
Train_StdReturn : 0.0
Train_MaxReturn : 940.6160888671875
Train_MinReturn : 940.6160888671875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 985000
TimeSinceStart : 16253.037698507309
Training Loss : 0.00047589847235940397
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 986 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 934.18603515625
Eval_StdReturn : 13.504417419433594
Eval_MaxReturn : 957.3818359375
Eval_MinReturn : 917.10009765625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.629150390625
Train_StdReturn : 0.0
Train_MaxReturn : 936.629150390625
Train_MinReturn : 936.629150390625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 986000
TimeSinceStart : 16277.459608078003
Training Loss : 0.00018379767425358295
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 987 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 949.3336791992188
Eval_StdReturn : 5.616939544677734
Eval_MaxReturn : 953.8761596679688
Eval_MinReturn : 938.573974609375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 936.4381103515625
Train_StdReturn : 0.0
Train_MaxReturn : 936.4381103515625
Train_MinReturn : 936.4381103515625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 987000
TimeSinceStart : 16303.272181749344
Training Loss : 0.000191719809663482
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 988 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 938.9869995117188
Eval_StdReturn : 11.300042152404785
Eval_MaxReturn : 952.508544921875
Eval_MinReturn : 919.6690063476562
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 956.759765625
Train_StdReturn : 0.0
Train_MaxReturn : 956.759765625
Train_MinReturn : 956.759765625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 988000
TimeSinceStart : 16328.686777591705
Training Loss : 0.00015864787565078586
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 989 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.1217651367188
Eval_StdReturn : 6.018014430999756
Eval_MaxReturn : 962.9700317382812
Eval_MinReturn : 946.9833984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 942.2327880859375
Train_StdReturn : 0.0
Train_MaxReturn : 942.2327880859375
Train_MinReturn : 942.2327880859375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 989000
TimeSinceStart : 16353.341891527176
Training Loss : 0.00033934443490579724
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 990 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 951.52197265625
Eval_StdReturn : 12.17994213104248
Eval_MaxReturn : 970.4583129882812
Eval_MinReturn : 937.7219848632812
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 949.629150390625
Train_StdReturn : 0.0
Train_MaxReturn : 949.629150390625
Train_MinReturn : 949.629150390625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 990000
TimeSinceStart : 16378.578558206558
Training Loss : 0.00024268895504064858
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 991 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.0218505859375
Eval_StdReturn : 6.371493816375732
Eval_MaxReturn : 949.1340942382812
Eval_MinReturn : 931.726318359375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 952.5390625
Train_StdReturn : 0.0
Train_MaxReturn : 952.5390625
Train_MinReturn : 952.5390625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 991000
TimeSinceStart : 16403.95371365547
Training Loss : 0.0002883761771954596
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 992 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.2044677734375
Eval_StdReturn : 11.145462989807129
Eval_MaxReturn : 964.1858520507812
Eval_MinReturn : 930.4769287109375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 922.354736328125
Train_StdReturn : 0.0
Train_MaxReturn : 922.354736328125
Train_MinReturn : 922.354736328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 992000
TimeSinceStart : 16430.310550928116
Training Loss : 4.2318020859966055e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 993 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 948.2986450195312
Eval_StdReturn : 11.376983642578125
Eval_MaxReturn : 961.5206298828125
Eval_MinReturn : 929.9285888671875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 954.504638671875
Train_StdReturn : 0.0
Train_MaxReturn : 954.504638671875
Train_MinReturn : 954.504638671875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 993000
TimeSinceStart : 16455.72803711891
Training Loss : 0.0001619851536815986
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 994 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 943.4373168945312
Eval_StdReturn : 6.32639217376709
Eval_MaxReturn : 950.9990234375
Eval_MinReturn : 933.5859375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 950.0726318359375
Train_StdReturn : 0.0
Train_MaxReturn : 950.0726318359375
Train_MinReturn : 950.0726318359375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 994000
TimeSinceStart : 16481.65706205368
Training Loss : 0.00029578665271401405
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 995 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 946.8180541992188
Eval_StdReturn : 10.951459884643555
Eval_MaxReturn : 960.3765869140625
Eval_MinReturn : 927.5032958984375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 948.940673828125
Train_StdReturn : 0.0
Train_MaxReturn : 948.940673828125
Train_MinReturn : 948.940673828125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 995000
TimeSinceStart : 16507.760888814926
Training Loss : 9.423745359526947e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 996 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 935.6243286132812
Eval_StdReturn : 12.065089225769043
Eval_MaxReturn : 952.0791015625
Eval_MinReturn : 918.2791748046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.0982666015625
Train_StdReturn : 0.0
Train_MaxReturn : 935.0982666015625
Train_MinReturn : 935.0982666015625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 996000
TimeSinceStart : 16534.315434217453
Training Loss : 0.00010162161197513342
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 997 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 942.77685546875
Eval_StdReturn : 12.411934852600098
Eval_MaxReturn : 958.711181640625
Eval_MinReturn : 925.108154296875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 926.4602661132812
Train_StdReturn : 0.0
Train_MaxReturn : 926.4602661132812
Train_MinReturn : 926.4602661132812
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 997000
TimeSinceStart : 16561.577043056488
Training Loss : 0.0004366444773040712
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 998 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 935.5948486328125
Eval_StdReturn : 4.610881328582764
Eval_MaxReturn : 942.6525268554688
Eval_MinReturn : 930.9800415039062
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 953.7431640625
Train_StdReturn : 0.0
Train_MaxReturn : 953.7431640625
Train_MinReturn : 953.7431640625
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 998000
TimeSinceStart : 16587.784564971924
Training Loss : 0.0002955900563392788
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...




********** Iteration 999 ************

Collecting data to be used for training...

Relabelling collected observations with labels from an expert policy...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 941.2572021484375
Eval_StdReturn : 8.285603523254395
Eval_MaxReturn : 955.9541625976562
Eval_MinReturn : 931.2630615234375
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 935.7622680664062
Train_StdReturn : 0.0
Train_MaxReturn : 935.7622680664062
Train_MinReturn : 935.7622680664062
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 999000
TimeSinceStart : 16613.997481822968
Training Loss : 7.841410115361214e-05
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...


